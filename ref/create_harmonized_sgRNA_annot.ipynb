{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create harmonized sgRNA guide annotation file for use with the CRISPR pipeline (2025)\n",
    "This notebook describes the creation of a unified annotation file from the guide annotation files provided by the Hon, Huangfu, and Gersbach labs, according to the specification described in: https://github.com/pinellolab/CRISPR_Pipeline/blob/main/example_data/guide_metadata.tsv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install matplotlib\n",
    "#%pip install numpy\n",
    "#%pip install seaborn\n",
    "#%pip install biomart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths: TODO update if necessary\n",
    "#local_path = \"/cellar/users/aklie/data/datasets/tf_perturb_seq/ref/\"\n",
    "local_path = \"C:/Users/seg95/Documents/tf_perturb_seq/\"\n",
    "#local_path = \"/hpc/group/gersbachlab/seg95/tf_perturb_seq/ref/\"\n",
    "#local_path = \"D:/tf_perturb_seq/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import merged guide reference file, along with guide index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id_hon           protospacer       type  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1  GCACAGGACGGCCGAGCTGA  targeting   \n",
      "1     EN2_-_155251011.23-P1P2-1  GCTCCGTGTGCGCCGCGGGA  targeting   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2  GCTCCGTTGCAACCACACAG  targeting   \n",
      "3      KLF6_-_3827130.23-P1P2-2  GCTGGAGGATCGATCGGCGG  targeting   \n",
      "4     ELF1_+_41593362.23-P1P2-2  GTGAGCTGATAAACAGAGGG  targeting   \n",
      "\n",
      "  intended_target_name_hon    reverse_compliment genomic_element  \\\n",
      "0                    FOXN1  TCAGCTCGGCCGTCCTGTGC        promoter   \n",
      "1                      EN2  TCCCGCGGCGCACACGGAGC        promoter   \n",
      "2                   BCLAF1  CTGTGTGGTTGCAACGGAGC        promoter   \n",
      "3                     KLF6  CCGCCGATCGATCCTCCAGC        promoter   \n",
      "4                     ELF1  CCCTCTGTTTATCAGCTCAC        promoter   \n",
      "\n",
      "                    id_gersbach intended_target_name_gersbach id_huangfu  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1                         FOXN1    FOXN1_1   \n",
      "1     EN2_-_155251011.23-P1P2-1                           EN2      EN2_5   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2                        BCLAF1   BCLAF1_6   \n",
      "3      KLF6_-_3827130.23-P1P2-2                          KLF6     KLF6_2   \n",
      "4     ELF1_+_41593362.23-P1P2-2                          ELF1     ELF1_6   \n",
      "\n",
      "  intended_target_name_huangfu   id_engreitz intended_target_name_engreitz  \n",
      "0                        FOXN1     FOXN1_765                         FOXN1  \n",
      "1                          EN2      EN2_9056                           EN2  \n",
      "2                       BCLAF1  BCLAF1_11125                        BCLAF1  \n",
      "3                         KLF6     KLF6_1362                          KLF6  \n",
      "4                         ELF1    ELF1_11255                          ELF1  \n"
     ]
    }
   ],
   "source": [
    "# Merged guide ref file\n",
    "merged_guide_file = pd.read_csv(local_path + \"outer_merged_file.csv\")\n",
    "print(merged_guide_file.head())\n",
    "\n",
    "merged_guide_file_poolabcd = pd.read_csv(local_path + \"outer_merged_file_poolabcd.csv\")\n",
    "merged_guide_file_poolf = pd.read_csv(local_path + \"outer_merged_file_poolf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13188\n"
     ]
    }
   ],
   "source": [
    "# sgRNA index files\n",
    "sgrna_index_poolabcd = pd.read_csv(local_path + \"sgRNA_index_v0.csv\", sep = \"\\t\")\n",
    "sgrna_index_poolf = pd.read_csv(local_path + \"igvf_poolF_annotation.csv\", sep = \"\\t\")\n",
    "\n",
    "sgrna_index_dacc_annot = pd.read_csv(local_path + \"sgRNA_index_dacc_annot_reference.csv\", sep = \"\\t\")\n",
    "print(len(set(sgrna_index_dacc_annot['protospacer']).intersection(set(merged_guide_file_poolabcd['protospacer']))))\n",
    "\n",
    "def adjust_index_file(sgrna_index, name_sgrna_seq = 'sgRNA_seq', add_leading_G = True):\n",
    "    if(name_sgrna_seq == \"sgRNA_seq\"):\n",
    "        sgrna_index['strand'] = sgrna_index['target_loc'].str.extract(r'\\((\\+|\\-)\\)')\n",
    "        sgrna_index['oligo'] = sgrna_index['oligo'].str.upper()\n",
    "    else:\n",
    "        sgrna_index['oligo_sequence'] = sgrna_index['oligo_sequence'].str.upper()\n",
    "    sgrna_index[name_sgrna_seq] = sgrna_index[name_sgrna_seq].str.upper()\n",
    "    # Adjust the index file to add leading Gs if needed\n",
    "    if(add_leading_G):\n",
    "        sgrna_index[name_sgrna_seq] = 'G' + sgrna_index[name_sgrna_seq]\n",
    "    return sgrna_index\n",
    "\n",
    "sgrna_index_poolabcd = adjust_index_file(sgrna_index_poolabcd)\n",
    "sgrna_index_poolf = adjust_index_file(sgrna_index_poolf, name_sgrna_seq= 'protospacer', add_leading_G = False)\n",
    "\n",
    "sgrna_index_dacc_annot['protospacer'] = sgrna_index_dacc_annot['protospacer'].str.upper()\n",
    "sgrna_index_poolf['protospacer'] = sgrna_index_poolf['protospacer'].str.upper()\n",
    "#sgrna_index_dacc_annot['protospacer'] = [s[1:] if len(s) > 0 else s for s in sgrna_index_dacc_annot['protospacer']]\n",
    "#sgrna_index_dacc_annot['reverse_compliment'] = sgrna_index_dacc_annot['reverse_compliment'].str.rstrip('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:\n",
      "                   target_loc              element_seq     target source  \\\n",
      "0  chr17:36948966-36948984(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "1  chr17:36949026-36949044(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "2  chr17:36949013-36949031(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "3  chr17:36949070-36949088(-)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "4  chr17:36949031-36949049(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "\n",
      "              sgRNA_seq                                              oligo  \\\n",
      "0  GAGTGGCCGGTCCAGAGCTG  GTGGAAAGGACGAAACACCGAGTGGCCGGTCCAGAGCTGGTTTAAG...   \n",
      "1  GGGATCAAGGCGAGAGGATC  GTGGAAAGGACGAAACACCGGGATCAAGGCGAGAGGATCGTTTAAG...   \n",
      "2  GGAGTCGGGGAATCGGATCA  GTGGAAAGGACGAAACACCGGAGTCGGGGAATCGGATCAGTTTAAG...   \n",
      "3  GAAATGTGCGGCCCAACCCC  GTGGAAAGGACGAAACACCGAAATGTGCGGCCCAACCCCGTTTAAG...   \n",
      "4  GAAGGCGAGAGGATCCGGCA  GTGGAAAGGACGAAACACCGAAGGCGAGAGGATCCGGCAGTTTAAG...   \n",
      "\n",
      "  gene_target chr_target  chr_start_target  chr_end_target chr_element  \\\n",
      "0        AATF      chr17          36948966        36948984       chr17   \n",
      "1        AATF      chr17          36949026        36949044       chr17   \n",
      "2        AATF      chr17          36949013        36949031       chr17   \n",
      "3        AATF      chr17          36949070        36949088       chr17   \n",
      "4        AATF      chr17          36949031        36949049       chr17   \n",
      "\n",
      "   chr_start_element  chr_end_element strand    reverse_compliment  \n",
      "0           36948966         36949088      +  CAGCTCTGGACCGGCCACTC  \n",
      "1           36948966         36949088      +  GATCCTCTCGCCTTGATCCC  \n",
      "2           36948966         36949088      +  TGATCCGATTCCCCGACTCC  \n",
      "3           36948966         36949088      -  GGGGTTGGGCCGCACATTTC  \n",
      "4           36948966         36949088      +  TGCCGGATCCTCTCGCCTTC  \n",
      "                     target_loc                element_seq intended_target  \\\n",
      "0  chr10:102055949-102055968(-)  chr10:102055925-102056425        C10orf76   \n",
      "1  chr10:102056011-102056030(-)  chr10:102055925-102056425        C10orf76   \n",
      "2  chr10:102056104-102056123(+)  chr10:102055925-102056425        C10orf76   \n",
      "3  chr10:102056211-102056230(-)  chr10:102055925-102056425        C10orf76   \n",
      "4  chr10:102056276-102056295(-)  chr10:102055925-102056425        C10orf76   \n",
      "\n",
      "  intended_target.1         source          protospacer  \\\n",
      "0          C10orf76  TFPerturbSeq+  GGGACGACGAGGACGCGAG   \n",
      "1          C10orf76  TFPerturbSeq+  GTCCTGCCATACTAGGCCT   \n",
      "2          C10orf76  TFPerturbSeq+  TACCACCCGCGCCGTTCCC   \n",
      "3          C10orf76  TFPerturbSeq+  TAGGACCCGGCGGGGCGCG   \n",
      "4          C10orf76  TFPerturbSeq+  TGGGAATCGTGGTCTGAGC   \n",
      "\n",
      "                                      oligo_sequence   antisense_sequence  \\\n",
      "0  GTGGAAAGGACGAAACACCGGGGACGACGAGGACGCGAGGTTTAAG...  CTCGCGTCCTCGTCGTCCC   \n",
      "1  GTGGAAAGGACGAAACACCGGTCCTGCCATACTAGGCCTGTTTAAG...  AGGCCTAGTATGGCAGGAC   \n",
      "2  GTGGAAAGGACGAAACACCGTACCACCCGCGCCGTTCCCGTTTAAG...  GGGAACGGCGCGGGTGGTA   \n",
      "3  GTGGAAAGGACGAAACACCGTAGGACCCGGCGGGGCGCGGTTTAAG...  CGCGCCCCGCCGGGTCCTA   \n",
      "4  GTGGAAAGGACGAAACACCGTGGGAATCGTGGTCTGAGCGTTTAAG...  GCTCAGACCACGATTCCCA   \n",
      "\n",
      "  intended_target.2 intended_target.3  intended_target_start  \\\n",
      "0          C10orf76          C10orf76              102055925   \n",
      "1          C10orf76          C10orf76              102055925   \n",
      "2          C10orf76          C10orf76              102055925   \n",
      "3          C10orf76          C10orf76              102055925   \n",
      "4          C10orf76          C10orf76              102055925   \n",
      "\n",
      "   intended_target_end intended_target_chr strand  PAM guide_chr  guide_start  \\\n",
      "0            102056425               chr10      -  NGG     chr10    102055949   \n",
      "1            102056425               chr10      -  NGG     chr10    102056011   \n",
      "2            102056425               chr10      +  NGG     chr10    102056104   \n",
      "3            102056425               chr10      -  NGG     chr10    102056211   \n",
      "4            102056425               chr10      -  NGG     chr10    102056276   \n",
      "\n",
      "   guide_end  \n",
      "0  102055968  \n",
      "1  102056030  \n",
      "2  102056123  \n",
      "3  102056230  \n",
      "4  102056295  \n",
      "Annot:\n",
      "             protospacer_ID           protospacer intended_target_name  \\\n",
      "0                DNAJC19_ B  GGGAACTCCTGTAAGGTCAG              DNAJC19   \n",
      "1                 POLR1D_ B  GGGAAGCAAGGACCGACCGA               POLR1D   \n",
      "2                   OR5K2-2  GAAAAAATTGTAGAGGAATA                OR5K2   \n",
      "3  SP1_+_53773993.23-P1P2-1  GAAAAACGCGGACGCTGACG                  SP1   \n",
      "4  SP8_-_20826141.23-P1P2-2  GAAAAAGATCCTCTGAGAGG                  SP8   \n",
      "\n",
      "        type genomic_element    reverse_compliment  \n",
      "0  targeting        promoter  CTGACCTTACAGGAGTTCCC  \n",
      "1  targeting        promoter  TCGGTCGGTCCTTGCTTCCC  \n",
      "2  targeting        promoter  TATTCCTCTACAATTTTTTC  \n",
      "3  targeting        promoter  CGTCAGCGTCCGCGTTTTTC  \n",
      "4  targeting        promoter  CCTCTCAGAGGATCTTTTTC  \n"
     ]
    }
   ],
   "source": [
    "# Add a reverse compliment if needed\n",
    "def reverse_compliment(sequence):\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
    "    return \"\".join(complement.get(base, base) for base in reversed(sequence.upper()))\n",
    "\n",
    "sgrna_index_poolabcd['reverse_compliment'] = sgrna_index_poolabcd['sgRNA_seq'].apply(reverse_compliment)\n",
    "sgrna_index_poolf.rename(columns={\"antisense_sequence\": \"reverse_compliment\"})\n",
    "\n",
    "print(\"Index:\")\n",
    "print(sgrna_index_poolabcd.head())\n",
    "print(sgrna_index_poolf.head())\n",
    "print(\"Annot:\")\n",
    "print(sgrna_index_dacc_annot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13470\n"
     ]
    }
   ],
   "source": [
    "sgrna_index_dacc_annot[\"protospacer_upper\"] = sgrna_index_dacc_annot[\"protospacer\"].str.upper() \n",
    "\n",
    "print(len(set(sgrna_index_poolabcd['sgRNA_seq']).intersection(sgrna_index_dacc_annot['protospacer_upper'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading 'G' from the DACC annot file\n",
    "def harmonize_leading_G(df_left, df_right, left_col, right_col, debug=True):\n",
    "    \"\"\"\n",
    "    Compare sequence lengths between two DataFrames.\n",
    "    If all (non‑NaN) sequences in one DataFrame start with 'G' and are one base\n",
    "    longer than the other, remove the leading 'G' to harmonize lengths.\n",
    "    If both DataFrames contain a 'reverse_compliment' column, remove one trailing\n",
    "    'C' from that column as well when trimming Gs.\n",
    "\n",
    "    Returns (left_fixed, right_fixed)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    left = df_left.copy()\n",
    "    right = df_right.copy()\n",
    "\n",
    "    # Normalize sequence text\n",
    "    left[left_col] = left[left_col].astype(str).str.strip().str.upper()\n",
    "    right[right_col] = right[right_col].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Compute basic stats\n",
    "    left_lens = left[left_col].dropna().str.len()\n",
    "    right_lens = right[right_col].dropna().str.len()\n",
    "    avg_left, avg_right = left_lens.mean(), right_lens.mean()\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Average seq length: left={avg_left:.1f}, right={avg_right:.1f}\")\n",
    "        print(\"Value_counts of left lengths:\", left_lens.value_counts().head().to_dict())\n",
    "        print(\"Value_counts of right lengths:\", right_lens.value_counts().head().to_dict())\n",
    "\n",
    "    # Decide which side to trim \n",
    "    trimmed = None\n",
    "    if np.nanmedian(left_lens) == np.nanmedian(right_lens) + 1:\n",
    "        starts_with_G = left[left_col].dropna().str.startswith(\"G\").all()\n",
    "        if starts_with_G:\n",
    "            left[left_col] = left[left_col].str.replace(r\"^G\", \"\", regex=True)\n",
    "            trimmed = \"left\"\n",
    "            if debug:\n",
    "                print(f\"Removed leading 'G' from all non‑NaN sequences in '{left_col}'.\")\n",
    "        else:\n",
    "            if debug:\n",
    "                mism = left.loc[~left[left_col].dropna().str.startswith(\"G\"), left_col].head(10).tolist()\n",
    "                print(f\"Not all left sequences start with 'G'. Examples: {mism}\")\n",
    "\n",
    "    elif np.nanmedian(right_lens) == np.nanmedian(left_lens) + 1:\n",
    "        starts_with_G = right[right_col].dropna().str.startswith(\"G\").all()\n",
    "        if starts_with_G:\n",
    "            right[right_col] = right[right_col].str.replace(r\"^G\", \"\", regex=True)\n",
    "            trimmed = \"right\"\n",
    "            if debug:\n",
    "                print(f\"Removed leading 'G' from all non‑NaN sequences in '{right_col}'.\")\n",
    "        else:\n",
    "            if debug:\n",
    "                mism = right.loc[~right[right_col].dropna().str.startswith(\"G\"), right_col].head(10).tolist()\n",
    "                print(f\"Not all right sequences start with 'G'. Examples: {mism}\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"No consistent 19 / 20 bp offset found; no trimming performed.\")\n",
    "\n",
    "    # --- If both have reverse_compliment, trim trailing C accordingly ---\n",
    "    if \"reverse_compliment\" in left.columns and \"reverse_compliment\" in right.columns:\n",
    "        if trimmed == \"left\":\n",
    "            left[\"reverse_compliment\"] = left[\"reverse_compliment\"].astype(str).str.replace(r\"C$\", \"\", regex=True)\n",
    "            if debug:\n",
    "                print(\"Trimmed trailing 'C' from left.reverse_compliment.\")\n",
    "        elif trimmed == \"right\":\n",
    "            right[\"reverse_compliment\"] = right[\"reverse_compliment\"].astype(str).str.replace(r\"C$\", \"\", regex=True)\n",
    "            if debug:\n",
    "                print(\"Trimmed trailing 'C' from right.reverse_compliment.\")\n",
    "\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average seq length: left=20.0, right=20.0\n",
      "Value_counts of left lengths: {20: 14358}\n",
      "Value_counts of right lengths: {20: 13563, 21: 18}\n",
      "No consistent 19 / 20 bp offset found; no trimming performed.\n"
     ]
    }
   ],
   "source": [
    "sgrna_index_dacc_annot, sgrna_index_poolabcd = harmonize_leading_G(\n",
    "    df_left=sgrna_index_dacc_annot,\n",
    "    df_right=sgrna_index_poolabcd,\n",
    "    left_col=\"protospacer_upper\",\n",
    "    right_col=\"sgRNA_seq\",\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "13563    GGGAGAGCCAGCGCGCAACGG\n",
      "13564    GGCCGGACTCGGACGCGTGGT\n",
      "13565    GGCCGCTCGGCCGAGCTGTCG\n",
      "13566    GGCTGCGACTCGGCGGAGTCC\n",
      "13567    GGAGAGGCCCAGCGGGAGTCG\n",
      "Name: sgRNA_seq, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Investigate the 18 with 21 bp\n",
    "extra_long = sgrna_index_poolabcd[sgrna_index_poolabcd[\"sgRNA_seq\"].str.len() == 21]\n",
    "print(len(extra_long))\n",
    "print(extra_long[\"sgRNA_seq\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgRNA_seq\n",
      "20    13581\n",
      "Name: count, dtype: int64\n",
      "Also removed trailing base from reverse_compliment for those rows.\n"
     ]
    }
   ],
   "source": [
    "# Trim the leading 'G' from those 18\n",
    "mask = sgrna_index_poolabcd[\"sgRNA_seq\"].str.len() > 20\n",
    "sgrna_index_poolabcd.loc[mask, \"sgRNA_seq\"] = (\n",
    "    sgrna_index_poolabcd.loc[mask, \"sgRNA_seq\"].str[1:]\n",
    ")\n",
    "print(sgrna_index_poolabcd[\"sgRNA_seq\"].str.len().value_counts().head())\n",
    "\n",
    "if \"reverse_compliment\" in sgrna_index_poolabcd.columns:\n",
    "    sgrna_index_poolabcd.loc[mask, \"reverse_compliment\"] = (\n",
    "        sgrna_index_poolabcd.loc[mask, \"reverse_compliment\"].astype(str).str[:-1]\n",
    "    )\n",
    "    print(\"Also removed trailing base from reverse_compliment for those rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               protospacer_ID           protospacer intended_target_name  \\\n",
      "0                     OR5K2-2  GAAAAAATTGTAGAGGAATA                OR5K2   \n",
      "1    SP1_+_53773993.23-P1P2-1  GAAAAACGCGGACGCTGACG                  SP1   \n",
      "2    SP8_-_20826141.23-P1P2-2  GAAAAAGATCCTCTGAGAGG                  SP8   \n",
      "3    FOXN3_-_89883583.23-P2-1  GAAAAAGGCGACACATGACC                FOXN3   \n",
      "4  ZNF85_+_21106076.23-P1P2-1  GAAAACAAGACCTAGAGCTC                ZNF85   \n",
      "\n",
      "        type genomic_element    reverse_compliment     protospacer_upper  \\\n",
      "0  targeting        promoter  TATTCCTCTACAATTTTTTC  GAAAAAATTGTAGAGGAATA   \n",
      "1  targeting        promoter  CGTCAGCGTCCGCGTTTTTC  GAAAAACGCGGACGCTGACG   \n",
      "2  targeting        promoter  CCTCTCAGAGGATCTTTTTC  GAAAAAGATCCTCTGAGAGG   \n",
      "3  targeting        promoter  GGTCATGTGTCGCCTTTTTC  GAAAAAGGCGACACATGACC   \n",
      "4  targeting        promoter  GAGCTCTAGGTCTTGTTTTC  GAAAACAAGACCTAGAGCTC   \n",
      "\n",
      "                   target_loc              element_seq      target  ...  \\\n",
      "0                         NaN                      NaN         NaN  ...   \n",
      "1  chr12:53380213-53380231(-)  chr12:53380184-53380609    SP1_P1P2  ...   \n",
      "2   chr7:20786818-20786836(-)   chr7:20786502-20786925    SP8_P1P2  ...   \n",
      "3  chr14:89417219-89417237(+)  chr14:89416760-89417237    FOXN3_P2  ...   \n",
      "4  chr19:20923274-20923292(-)  chr19:20923274-20923584  ZNF85_P1P2  ...   \n",
      "\n",
      "              sgRNA_seq                                              oligo  \\\n",
      "0                   NaN                                                NaN   \n",
      "1  GAAAAACGCGGACGCTGACG  GTGGAAAGGACGAAACACCGAAAAACGCGGACGCTGACGGTTTAAG...   \n",
      "2  GAAAAAGATCCTCTGAGAGG  GTGGAAAGGACGAAACACCGAAAAAGATCCTCTGAGAGGGTTTAAG...   \n",
      "3  GAAAAAGGCGACACATGACC  GTGGAAAGGACGAAACACCGAAAAAGGCGACACATGACCGTTTAAG...   \n",
      "4  GAAAACAAGACCTAGAGCTC  GTGGAAAGGACGAAACACCGAAAACAAGACCTAGAGCTCGTTTAAG...   \n",
      "\n",
      "  gene_target chr_target chr_start_target  chr_end_target  chr_element  \\\n",
      "0         NaN        NaN              NaN             NaN          NaN   \n",
      "1         SP1      chr12       53380213.0      53380231.0        chr12   \n",
      "2         SP8       chr7       20786818.0      20786836.0         chr7   \n",
      "3       FOXN3      chr14       89417219.0      89417237.0        chr14   \n",
      "4       ZNF85      chr19       20923274.0      20923292.0        chr19   \n",
      "\n",
      "  chr_start_element  chr_end_element  strand  \n",
      "0               NaN              NaN     NaN  \n",
      "1        53380184.0       53380609.0       -  \n",
      "2        20786502.0       20786925.0       -  \n",
      "3        89416760.0       89417237.0       +  \n",
      "4        20923274.0       20923584.0       -  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(14451, 21)\n"
     ]
    }
   ],
   "source": [
    "# Merge pool A-D index and DACC files into one; pool F file has sufficient info for matching\n",
    "sgrna_index_merged = pd.merge(\n",
    "    sgrna_index_dacc_annot,\n",
    "    sgrna_index_poolabcd,\n",
    "    left_on=['protospacer_upper', 'reverse_compliment'],\n",
    "    right_on=['sgRNA_seq', 'reverse_compliment'],\n",
    "    how=\"outer\"\n",
    ")\n",
    "print(sgrna_index_merged.head())\n",
    "print(sgrna_index_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out positive/ negative controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0 Photospacer (same for all 3 sets)\n",
      "0  non-targeting_00642              GGAGTTAAGGCCTCGTCTAG\n",
      "1  non-targeting_00718              GTCCCAGGCTCTCCACTATG\n",
      "2  non-targeting_03631              GGACGCGTCTGCAAGAACGT\n",
      "3  non-targeting_03705              GGGCATGGACCCGCGGCACG\n",
      "4  non-targeting_01469              GCGTCCGAGGTACTGAATAA\n",
      "           Gene Photospacer (represent 10 times)  \\\n",
      "0   CD81 strong             GGAGAGCGAGCGCGCAACGG   \n",
      "1     CD81 weak             GGAGAGCCAGCGCGCAACGG   \n",
      "2  CD151 strong             GCCGGACTCGGACGCGTGGT   \n",
      "3    CD151 weak             GCCGCTCGGCCGAGCTGTCG   \n",
      "4   CD55 strong             GCTGCGACTCGGCGGAGTCC   \n",
      "\n",
      "                                           Reference  \n",
      "0  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "1  Jost et al. 2020 \"Titrating gene expression us...  \n",
      "2  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "3  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "4  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "     Gene         Photospacer 1         Photospacer 2         Photospacer 3  \\\n",
      "0   OR1J4  GAGGAGGAGAGTGTGAGACA  GGAAGACTGTCAGCATGAAG  GGATAGTGGTGTAGCGGAGG   \n",
      "1  OR10K1  GCTTCTATAAAGGAGAGTCA  GAGGGACAGAGGTAGAAACC  GAGGGCTCTGTCCAGCACAA   \n",
      "2   OR5L2  GCTGCATAAATTGGAGACAT  GTGGTCACCATGTACAGCAG  GTGCACATGTGGAGTCACTG   \n",
      "3  OR52W1  GCTCCTGACAGGGAAGATAA  GACAACTTGAGGGCTCATGG  GTGTGGTGGGCACAACTTGA   \n",
      "4   OR8K1  GTCACAGTGATAGGCAATCT  GTGTGACCAGATATATGATG  GTGAGGAAGAGTCCAAACAG   \n",
      "\n",
      "          Photospacer 4         Photospacer 5         Photospacer 6  \n",
      "0  GCAGGGCATTGGTACAGGAG  GACACACCCTGCATAAAGAA  GTGAGACAGGGCATTGGTAC  \n",
      "1  GAAGTACATGGGAGTATGAA  GATGGAGAGCACTTCTATAA  GGTCTTATTGACTTGCTCCA  \n",
      "2  GAGTGCAGTCATGCCCAGAT  GATGTCTCAGAAGCTGCGTG  GCTCTTGCTGCTACTTCTGT  \n",
      "3  GACCAGTGTCAGCCAAGTCT  GAGTTGTGCCCACCACAGAA  GGCTAGGAAGTGCCCAGACT  \n",
      "4  GGGCTGCAGGCTCCACTGTT  GAATCACACGGCAGTGACCA  GTTTGATGTATGAGCAATAG  \n"
     ]
    }
   ],
   "source": [
    "neg_controls = pd.read_csv(local_path + \"negative_controls.tsv\", sep = \"\\t\")\n",
    "pos_controls = pd.read_csv(local_path + \"positive_controls.tsv\", sep = \"\\t\")\n",
    "non_targeting = pd.read_csv(local_path + \"non_targeting.tsv\", sep = \"\\t\")\n",
    "\n",
    "print(non_targeting.head())\n",
    "print(pos_controls.head())\n",
    "print(neg_controls.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 1278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(set(sgrna_index_merged['protospacer_upper']).intersection(set(non_targeting['Photospacer (same for all 3 sets)']))))\n",
    "print(len(set(sgrna_index_merged['protospacer_upper']).intersection(set(pos_controls['Photospacer (represent 10 times)']))))  \n",
    "cols = [c for c in neg_controls.columns if c.startswith('Photospacer')]\n",
    "neg_spacers = pd.concat([neg_controls[c] for c in cols]).dropna().astype(str)\n",
    "\n",
    "len(set(sgrna_index_merged['protospacer_upper']).intersection(set(neg_spacers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     guide_id   intended_target_region gene_target source  \\\n",
      "0  chr16:70289419-70289437(-)  chr16:70289409-70289495   AARS_P1P2     PC   \n",
      "1  chr16:70289477-70289495(-)  chr16:70289409-70289495   AARS_P1P2     PC   \n",
      "2  chr16:70289454-70289472(-)  chr16:70289409-70289495   AARS_P1P2     PC   \n",
      "3  chr16:70289423-70289441(-)  chr16:70289409-70289495   AARS_P1P2     PC   \n",
      "4  chr16:70289463-70289481(-)  chr16:70289409-70289495   AARS_P1P2     PC   \n",
      "\n",
      "                spacer                                     oligo_sequence  \\\n",
      "0  CGGCGACCCTAGGAGAGGT  GTGGAAAGGACGAAACACCGcggcgaccctaggagaggtGTTTAAG...   \n",
      "1  TCTGCGGGAATAGGTGCAG  GTGGAAAGGACGAAACACCGtctgcgggaataggtgcagGTTTAAG...   \n",
      "2  CCCTTGGCGGGGGACTCTG  GTGGAAAGGACGAAACACCGcccttggcgggggactctgGTTTAAG...   \n",
      "3  GGGACGGCGACCCTAGGAG  GTGGAAAGGACGAAACACCGgggacggcgaccctaggagGTTTAAG...   \n",
      "4  TGCAGCGGGCCCTTGGCGG  GTGGAAAGGACGAAACACCGtgcagcgggcccttggcggGTTTAAG...   \n",
      "\n",
      "    reverse_compliment intended_target  intended_target_start  \\\n",
      "0  ACCTCTCCTAGGGTCGCCG            AARS               70289409   \n",
      "1  CTGCACCTATTCCCGCAGA            AARS               70289409   \n",
      "2  CAGAGTCCCCCGCCAAGGG            AARS               70289409   \n",
      "3  CTCCTAGGGTCGCCGTCCC            AARS               70289409   \n",
      "4  CCGCCAAGGGCCCGCTGCA            AARS               70289409   \n",
      "\n",
      "   intended_target_end intended_target_chr strand  PAM guide_chr  guide_start  \\\n",
      "0             70289495               chr16      -  NGG     chr16     70289419   \n",
      "1             70289495               chr16      -  NGG     chr16     70289477   \n",
      "2             70289495               chr16      -  NGG     chr16     70289454   \n",
      "3             70289495               chr16      -  NGG     chr16     70289423   \n",
      "4             70289495               chr16      -  NGG     chr16     70289463   \n",
      "\n",
      "   guide_end  \n",
      "0   70289437  \n",
      "1   70289495  \n",
      "2   70289472  \n",
      "3   70289441  \n",
      "4   70289481  \n"
     ]
    }
   ],
   "source": [
    "# Import additional file to add missing coordinates\n",
    "poolD_coords = pd.read_csv(local_path + \"pool_D_controls.csv\", sep = \"\\t\")\n",
    "print(poolD_coords.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average seq length: left=20.0, right=19.0\n",
      "Value_counts of left lengths: {20: 14451}\n",
      "Value_counts of right lengths: {19: 570}\n",
      "Removed leading 'G' from all non‑NaN sequences in 'protospacer_upper'.\n",
      "Trimmed trailing 'C' from left.reverse_compliment.\n",
      "protospacer_upper\n",
      "19    14451\n",
      "Name: count, dtype: int64\n",
      "spacer\n",
      "19    570\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sgrna_index_merged, poolD_coords = harmonize_leading_G(\n",
    "    df_left=sgrna_index_merged,\n",
    "    df_right=poolD_coords,\n",
    "    left_col=\"protospacer_upper\",\n",
    "    right_col=\"spacer\",\n",
    "    debug=True\n",
    ")\n",
    "print(sgrna_index_merged[\"protospacer_upper\"].str.len().value_counts().head())\n",
    "print(poolD_coords[\"spacer\"].str.len().value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with placeholder coordinates: 888\n",
      "Of those, 13 have a matching spacer in Pool D\n",
      "\n",
      "Example matched spacers:\n",
      "        protospacer_upper chr_target protospacer_ID target_loc\n",
      "1360  AGAGGCCCAGCGGGAGTCG      chrPC           CD29  chrPC:0-0\n",
      "4412  CCGCTCGGCCGAGCTGTCG      chrPC     CD151_weak  chrPC:0-0\n",
      "4437  CCGGACTCGGACGCGTGGT      chrPC   CD151_strong  chrPC:0-0\n",
      "5657  CGGCGACCCTAGGAGAGGT      chrPC         AARS_B  chrPC:0-0\n",
      "6268  CTCAGAGCGTCGGGATATC      chrPC           TFRC  chrPC:0-0\n",
      "      protospacer_ID\n",
      "1360            CD29\n",
      "4412      CD151_weak\n",
      "4437    CD151_strong\n",
      "5657          AARS_B\n",
      "6268            TFRC\n",
      "6639            CD55\n",
      "7566     CD81_strong\n",
      "9026             B2M\n",
      "9907      DNAJC19_ B\n",
      "9920       POLR1D_ B\n",
      "10289      DNAJC19_C\n",
      "13185      AARS_main\n",
      "13970    POLR1D_main\n",
      "\n",
      "Example unmatched spacers:\n",
      "      protospacer_upper chr_target             protospacer_ID target_loc\n",
      "0   AAAAAATTGTAGAGGAATA        NaN                    OR5K2-2        NaN\n",
      "15  AAAAGCGGCGCAGTATTTG        NaN        non-targeting_01976        NaN\n",
      "20  AAAATACAGATGCTTGTGT        NaN                   OR51A4-1        NaN\n",
      "77  AAAGCCCGAGATGGCGAAG        NaN  UBTF_-_42298236.23-P1P2-1        NaN\n",
      "80  AAAGCGACCGAGTCGCTGA        NaN        non-targeting_02803        NaN\n"
     ]
    }
   ],
   "source": [
    "def debug_poolD_matches(sgrna_df, poolD_df):\n",
    "    sgrna_df = sgrna_df.copy()\n",
    "    poolD_df = poolD_df.copy()\n",
    "\n",
    "    # Normalize spacers\n",
    "    sgrna_df[\"spacer_norm\"] = sgrna_df[\"protospacer_upper\"].astype(str).str.strip().str.upper()\n",
    "    poolD_df[\"spacer_norm\"] = poolD_df[\"spacer\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Define \"broken\" or placeholder coordinates\n",
    "    placeholder_vals = [\"chrPC\", \"chrPC:0-0\", \"0\", \"chrNA\", \"NA\", \"nan\", \"\"]\n",
    "\n",
    "    broken_mask = (\n",
    "        sgrna_df[\"chr_target\"].astype(str).isin(placeholder_vals)\n",
    "        | sgrna_df[\"chr_start_target\"].astype(str).isin(placeholder_vals)\n",
    "        | sgrna_df[\"chr_end_target\"].astype(str).isin(placeholder_vals)\n",
    "    )\n",
    "    broken_rows = sgrna_df[broken_mask]\n",
    "\n",
    "    print(f\"Total rows with placeholder coordinates: {broken_rows.shape[0]}\")\n",
    "\n",
    "    # How many of these have a matching Pool D spacer?\n",
    "    matched = broken_rows[\"spacer_norm\"].isin(poolD_df[\"spacer_norm\"])\n",
    "    print(f\"Of those, {matched.sum()} have a matching spacer in Pool D\")\n",
    "\n",
    "    # Inspect a few examples of matched vs unmatched\n",
    "    print(\"\\nExample matched spacers:\")\n",
    "    print(broken_rows.loc[matched, [\"protospacer_upper\", \"chr_target\", \"protospacer_ID\", \"target_loc\"]].head())\n",
    "    print(broken_rows.loc[matched, [\"protospacer_ID\"]])\n",
    "\n",
    "    print(\"\\nExample unmatched spacers:\")\n",
    "    print(broken_rows.loc[~matched, [\"protospacer_upper\", \"chr_target\", \"protospacer_ID\", \"target_loc\"]].head())\n",
    "\n",
    "    return broken_rows.loc[matched]\n",
    "\n",
    "broken_with_matches = debug_poolD_matches(sgrna_index_merged, poolD_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows missing before: 888\n",
      "Total broken rows: 888\n",
      "Broken rows with Pool D match: 13\n",
      "Rows missing after: 875\n",
      "Rows newly filled (13):\n",
      "      protospacer_ID           protospacer intended_target_name       type  \\\n",
      "9920       POLR1D_ B  GGGAAGCAAGGACCGACCGA               POLR1D  targeting   \n",
      "13185      AARS_main  GTCTGCGGGAATAGGTGCAG                 AARS  targeting   \n",
      "9026             B2M  GGCGAGCACAGCTAAGGCCA                  B2M  targeting   \n",
      "7566     CD81_strong  GGAGAGCGAGCGCGCAACGG                 CD81  targeting   \n",
      "6639            CD55  GCTGCGACTCGGCGGAGTCC                 CD55  targeting   \n",
      "1360            CD29  GAGAGGCCCAGCGGGAGTCG                 CD29  targeting   \n",
      "10289      DNAJC19_C  GGGATGAGCCGTGCTCCCGG              DNAJC19  targeting   \n",
      "13970    POLR1D_main  GTGTCCCATAGCGCGAGGCG               POLR1D  targeting   \n",
      "9907      DNAJC19_ B  GGGAACTCCTGTAAGGTCAG              DNAJC19  targeting   \n",
      "4437    CD151_strong  GCCGGACTCGGACGCGTGGT                CD151  targeting   \n",
      "4412      CD151_weak  GCCGCTCGGCCGAGCTGTCG                CD151  targeting   \n",
      "5657          AARS_B  GCGGCGACCCTAGGAGAGGT                 AARS  targeting   \n",
      "6268            TFRC  GCTCAGAGCGTCGGGATATC                 TFRC  targeting   \n",
      "\n",
      "      genomic_element   reverse_compliment    protospacer_upper  \\\n",
      "9920         promoter  TCGGTCGGTCCTTGCTTCC  GGAAGCAAGGACCGACCGA   \n",
      "13185        promoter  CTGCACCTATTCCCGCAGA  TCTGCGGGAATAGGTGCAG   \n",
      "9026         promoter  TGGCCTTAGCTGTGCTCGC  GCGAGCACAGCTAAGGCCA   \n",
      "7566         promoter  CCGTTGCGCGCTCGCTCTC  GAGAGCGAGCGCGCAACGG   \n",
      "6639         promoter  GGACTCCGCCGAGTCGCAG  CTGCGACTCGGCGGAGTCC   \n",
      "1360         promoter  CGACTCCCGCTGGGCCTCT  AGAGGCCCAGCGGGAGTCG   \n",
      "10289        promoter  CCGGGAGCACGGCTCATCC  GGATGAGCCGTGCTCCCGG   \n",
      "13970        promoter  CGCCTCGCGCTATGGGACA  TGTCCCATAGCGCGAGGCG   \n",
      "9907         promoter  CTGACCTTACAGGAGTTCC  GGAACTCCTGTAAGGTCAG   \n",
      "4437         promoter  ACCACGCGTCCGAGTCCGG  CCGGACTCGGACGCGTGGT   \n",
      "4412         promoter  CGACAGCTCGGCCGAGCGG  CCGCTCGGCCGAGCTGTCG   \n",
      "5657         promoter  ACCTCTCCTAGGGTCGCCG  CGGCGACCCTAGGAGAGGT   \n",
      "6268         promoter  GATATCCCGACGCTCTGAG  CTCAGAGCGTCGGGATATC   \n",
      "\n",
      "                         target_loc                   element_seq  \\\n",
      "9920    chr13:27621883.0-27621901.0   chr13:27621865.0-27621958.0   \n",
      "13185   chr16:70289477.0-70289495.0   chr16:70289409.0-70289495.0   \n",
      "9026    chr15:44711560.0-44711578.0   chr15:44711545.0-44711959.0   \n",
      "7566      chr11:2377315.0-2377333.0     chr11:2377312.0-2377521.0   \n",
      "6639   chr1:207321714.0-207321732.0  chr1:207321700.0-207322397.0   \n",
      "1360    chr10:32958199.0-32958217.0   chr10:32957937.0-32958259.0   \n",
      "10289  chr3:180989630.0-180989648.0  chr3:180989327.0-180989725.0   \n",
      "13970   chr13:27621915.0-27621933.0   chr13:27621865.0-27621958.0   \n",
      "9907   chr3:180989327.0-180989345.0  chr3:180989327.0-180989725.0   \n",
      "4437        chr11:833006.0-833024.0       chr11:832818.0-833060.0   \n",
      "4412        chr11:833042.0-833060.0       chr11:832818.0-833060.0   \n",
      "5657    chr16:70289419.0-70289437.0   chr16:70289409.0-70289495.0   \n",
      "6268   chr3:196082075.0-196082093.0  chr3:196081657.0-196082093.0   \n",
      "\n",
      "                  target  ...             sgRNA_seq  \\\n",
      "9920      POLR1D_sgRNA.B  ...  GGGAAGCAAGGACCGACCGA   \n",
      "13185    AARS_sgRNA.main  ...  GTCTGCGGGAATAGGTGCAG   \n",
      "9026                 B2M  ...  GGCGAGCACAGCTAAGGCCA   \n",
      "7566                 NaN  ...                   NaN   \n",
      "6639         CD55_strong  ...  GCTGCGACTCGGCGGAGTCC   \n",
      "1360        CD29_(ITGB1)  ...  GAGAGGCCCAGCGGGAGTCG   \n",
      "10289    DNAJC19_sgRNA.C  ...  GGGATGAGCCGTGCTCCCGG   \n",
      "13970  POLR1D_sgRNA.main  ...  GTGTCCCATAGCGCGAGGCG   \n",
      "9907     DNAJC19_sgRNA.B  ...  GGGAACTCCTGTAAGGTCAG   \n",
      "4437        CD151_strong  ...  GCCGGACTCGGACGCGTGGT   \n",
      "4412          CD151_weak  ...  GCCGCTCGGCCGAGCTGTCG   \n",
      "5657        AARS_sgRNA.B  ...  GCGGCGACCCTAGGAGAGGT   \n",
      "6268                TFRC  ...  GCTCAGAGCGTCGGGATATC   \n",
      "\n",
      "                                                   oligo gene_target  \\\n",
      "9920   GTGGAAAGGACGAAACACCGGGAAGCAAGGACCGACCGAGTTTAAG...      POLR1D   \n",
      "13185  GTGGAAAGGACGAAACACCGTCTGCGGGAATAGGTGCAGGTTTAAG...        AARS   \n",
      "9026   GTGGAAAGGACGAAACACCGGCGAGCACAGCTAAGGCCAGTTTAAG...         B2M   \n",
      "7566                                                 NaN         NaN   \n",
      "6639   GTGGAAAGGACGAAACACCGCTGCGACTCGGCGGAGTCCGTTTAAG...        CD55   \n",
      "1360   GTGGAAAGGACGAAACACCGAGAGGCCCAGCGGGAGTCGGTTTAAG...        CD29   \n",
      "10289  GTGGAAAGGACGAAACACCGGGATGAGCCGTGCTCCCGGGTTTAAG...     DNAJC19   \n",
      "13970  GTGGAAAGGACGAAACACCGTGTCCCATAGCGCGAGGCGGTTTAAG...      POLR1D   \n",
      "9907   GTGGAAAGGACGAAACACCGGGAACTCCTGTAAGGTCAGGTTTAAG...     DNAJC19   \n",
      "4437   GTGGAAAGGACGAAACACCGCCGGACTCGGACGCGTGGTGTTTAAG...       CD151   \n",
      "4412   GTGGAAAGGACGAAACACCGCCGCTCGGCCGAGCTGTCGGTTTAAG...       CD151   \n",
      "5657   GTGGAAAGGACGAAACACCGCGGCGACCCTAGGAGAGGTGTTTAAG...        AARS   \n",
      "6268   GTGGAAAGGACGAAACACCGCTCAGAGCGTCGGGATATCGTTTAAG...        TFRC   \n",
      "\n",
      "      chr_target chr_start_target  chr_end_target  chr_element  \\\n",
      "9920       chr13       27621883.0      27621901.0        chr13   \n",
      "13185      chr16       70289477.0      70289495.0        chr16   \n",
      "9026       chr15       44711560.0      44711578.0        chr15   \n",
      "7566       chr11        2377315.0       2377333.0        chr11   \n",
      "6639        chr1      207321714.0     207321732.0         chr1   \n",
      "1360       chr10       32958199.0      32958217.0        chr10   \n",
      "10289       chr3      180989630.0     180989648.0         chr3   \n",
      "13970      chr13       27621915.0      27621933.0        chr13   \n",
      "9907        chr3      180989327.0     180989345.0         chr3   \n",
      "4437       chr11         833006.0        833024.0        chr11   \n",
      "4412       chr11         833042.0        833060.0        chr11   \n",
      "5657       chr16       70289419.0      70289437.0        chr16   \n",
      "6268        chr3      196082075.0     196082093.0         chr3   \n",
      "\n",
      "      chr_start_element  chr_end_element  strand  \n",
      "9920         27621865.0       27621958.0       -  \n",
      "13185        70289409.0       70289495.0       -  \n",
      "9026         44711545.0       44711959.0       -  \n",
      "7566          2377312.0        2377521.0       +  \n",
      "6639        207321700.0      207322397.0       +  \n",
      "1360         32957937.0       32958259.0       -  \n",
      "10289       180989327.0      180989725.0       -  \n",
      "13970        27621865.0       27621958.0       -  \n",
      "9907        180989327.0      180989725.0       -  \n",
      "4437           832818.0         833060.0       +  \n",
      "4412           832818.0         833060.0       -  \n",
      "5657         70289409.0       70289495.0       -  \n",
      "6268        196081657.0      196082093.0       -  \n",
      "\n",
      "[13 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "def fill_from_poolD(sgrna_df, poolD_df):\n",
    "    sgrna_df = sgrna_df.copy()\n",
    "    poolD_df = poolD_df.copy()\n",
    "\n",
    "    # Normalize spacers\n",
    "    sgrna_df[\"spacer_norm\"] = sgrna_df[\"protospacer_upper\"].astype(str).str.strip().str.upper()\n",
    "    poolD_df[\"spacer_norm\"] = poolD_df[\"spacer\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Columns to fill and their mapping from Pool D\n",
    "    column_mapping = {\n",
    "        \"guide_chr\"             : \"chr_target\",\n",
    "        \"guide_start\"           : \"chr_start_target\",\n",
    "        \"guide_end\"             : \"chr_end_target\",\n",
    "        \"strand_pd\"             : \"strand\",\n",
    "        \"intended_target_chr\"   : \"chr_element\",\n",
    "        \"intended_target_start\" : \"chr_start_element\",\n",
    "        \"intended_target_end\"   : \"chr_end_element\",\n",
    "    }\n",
    "\n",
    "    # Keep only relevant columns from Pool D\n",
    "    pool_lookup = poolD_df[[\"spacer_norm\"] + list(column_mapping.keys())]\n",
    "\n",
    "    # Merge Pool D into sgrna_df\n",
    "    merged = pd.merge(sgrna_df, pool_lookup, on=\"spacer_norm\", how=\"left\", suffixes=('', '_poolD'))\n",
    "\n",
    "    # Identify rows with placeholders / missing data\n",
    "    invalid_vals = [\"chrPC\", \"chrPC:0-0\", \"0\", \"chrNA\", \"NA\", \"nan\", \"\"]\n",
    "    broken_mask = (\n",
    "        merged[\"chr_target\"].isna() |\n",
    "        merged[\"chr_target\"].astype(str).isin(invalid_vals) |\n",
    "        merged[\"chr_start_target\"].isna() |\n",
    "        merged[\"chr_start_target\"].astype(str).isin(invalid_vals) |\n",
    "        merged[\"chr_end_target\"].isna() |\n",
    "        merged[\"chr_end_target\"].astype(str).isin(invalid_vals) \n",
    "    )\n",
    "\n",
    "    total_broken = broken_mask.sum()\n",
    "    print(f\"Total broken rows: {total_broken}\")\n",
    "\n",
    "    # Rows that have a matching Pool D spacer\n",
    "    poolD_matches = broken_mask & merged[\"guide_chr\"].notna()\n",
    "    print(f\"Broken rows with Pool D match: {poolD_matches.sum()}\")\n",
    "\n",
    "    # Fill all columns at once using mapping\n",
    "    for pool_col, sgrna_col in column_mapping.items():\n",
    "        if pool_col in merged.columns and sgrna_col in merged.columns:\n",
    "            merged.loc[poolD_matches, sgrna_col] = merged.loc[poolD_matches, pool_col]\n",
    "\n",
    "    merged[\"target_loc\"] = merged[\"chr_target\"].combine_first(pd.Series(invalid_vals)) + \":\" + \\\n",
    "                       merged[\"chr_start_target\"].astype(str) + \"-\" + merged[\"chr_end_target\"].astype(str)\n",
    "\n",
    "    merged[\"element_seq\"] = merged[\"chr_element\"].combine_first(pd.Series(invalid_vals)) + \":\" + \\\n",
    "                        merged[\"chr_start_element\"].astype(str) + \"-\" + merged[\"chr_end_element\"].astype(str)\n",
    "\n",
    "    # Drop temporary columns\n",
    "    merged.drop(columns=[\"spacer_norm\"] + list(column_mapping.keys()), inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return merged\n",
    "\n",
    "invalid_vals = [\"chrPC\", \"chrPC:0-0\", \"0\", \"chrNA\", \"NA\", \"nan\", \"\"]\n",
    "missing_before = sgrna_index_merged[\n",
    "    sgrna_index_merged[\"chr_target\"].isna() |\n",
    "    sgrna_index_merged[\"chr_target\"].astype(str).isin(invalid_vals) |\n",
    "    sgrna_index_merged[\"chr_start_target\"].isna() |\n",
    "    sgrna_index_merged[\"chr_start_target\"].astype(str).isin(invalid_vals) |\n",
    "    sgrna_index_merged[\"chr_end_target\"].isna() |\n",
    "    sgrna_index_merged[\"chr_end_target\"].astype(str).isin(invalid_vals)\n",
    "]\n",
    "print(\"Rows missing before:\", missing_before.shape[0])\n",
    "broken_indices = set(missing_before.index)\n",
    "\n",
    "poolD_coords = poolD_coords.rename(columns={\"strand\": \"strand_pd\"})\n",
    "sgrna_index_merged = fill_from_poolD(sgrna_index_merged, poolD_coords)\n",
    "\n",
    "missing_after = sgrna_index_merged[\n",
    "    sgrna_index_merged[\"chr_target\"].isna() |\n",
    "    sgrna_index_merged[\"chr_target\"].astype(str).isin(invalid_vals) |\n",
    "    sgrna_index_merged[\"chr_start_target\"].isna() |\n",
    "    sgrna_index_merged[\"chr_start_target\"].astype(str).isin(invalid_vals) |\n",
    "    sgrna_index_merged[\"chr_end_target\"].isna() |\n",
    "    sgrna_index_merged[\"chr_end_target\"].astype(str).isin(invalid_vals)\n",
    "]\n",
    "\n",
    "print(\"Rows missing after:\", missing_after.shape[0])\n",
    "fixed_indices = list(broken_indices - set(missing_after.index))\n",
    "print(f\"Rows newly filled ({len(fixed_indices)}):\")\n",
    "print(sgrna_index_merged.loc[fixed_indices])\n",
    "\n",
    "sgrna_index_merged.to_csv(local_path + \"sgRNA_index_v0_dacc_merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat to resemble input to the CRISPR pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import example file for the CRISPR pipeline\n",
    "example_crispr_file = pd.read_csv(local_path + \"crispr_annot_sample.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guide_id</th>\n",
       "      <th>spacer</th>\n",
       "      <th>targeting</th>\n",
       "      <th>type</th>\n",
       "      <th>guide_chr</th>\n",
       "      <th>guide_start</th>\n",
       "      <th>guide_end</th>\n",
       "      <th>strand</th>\n",
       "      <th>pam</th>\n",
       "      <th>intended_target_name</th>\n",
       "      <th>intended_target_chr</th>\n",
       "      <th>intended_target_start</th>\n",
       "      <th>intended_target_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFF4_sg1</td>\n",
       "      <td>CCAGCGGACGGGGCGGGGAC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299282.0</td>\n",
       "      <td>132299302.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFF4_sg2</td>\n",
       "      <td>CCGCCAGCGGACGGGGCGGC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299282.0</td>\n",
       "      <td>132299302.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFF4_sg3</td>\n",
       "      <td>CGTCCGCTGGCGGCGGCGAC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299252.0</td>\n",
       "      <td>132299272.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFF4_sg4</td>\n",
       "      <td>CTGCGTCAGTCACAGCCCTC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299279.0</td>\n",
       "      <td>132299299.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFF4_sg5</td>\n",
       "      <td>GCGGACGGGGCGGGGATCCC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299279.0</td>\n",
       "      <td>132299299.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   guide_id                spacer  targeting       type guide_chr  \\\n",
       "0  AFF4_sg1  CCAGCGGACGGGGCGGGGAC       True  targeting      chr5   \n",
       "1  AFF4_sg2  CCGCCAGCGGACGGGGCGGC       True  targeting      chr5   \n",
       "2  AFF4_sg3  CGTCCGCTGGCGGCGGCGAC       True  targeting      chr5   \n",
       "3  AFF4_sg4  CTGCGTCAGTCACAGCCCTC       True  targeting      chr5   \n",
       "4  AFF4_sg5  GCGGACGGGGCGGGGATCCC       True  targeting      chr5   \n",
       "\n",
       "   guide_start    guide_end strand  pam intended_target_name  \\\n",
       "0  132299282.0  132299302.0      -  NGG                 AFF4   \n",
       "1  132299282.0  132299302.0      -  NGG                 AFF4   \n",
       "2  132299252.0  132299272.0      -  NGG                 AFF4   \n",
       "3  132299279.0  132299299.0      -  NGG                 AFF4   \n",
       "4  132299279.0  132299299.0      -  NGG                 AFF4   \n",
       "\n",
       "  intended_target_chr  intended_target_start  intended_target_end  \n",
       "0                chr5            132875395.0          132963634.0  \n",
       "1                chr5            132875395.0          132963634.0  \n",
       "2                chr5            132875395.0          132963634.0  \n",
       "3                chr5            132875395.0          132963634.0  \n",
       "4                chr5            132875395.0          132963634.0  "
      ]
     },
     "execution_count": 1284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_crispr_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained rows: 19956\n",
      "Retained rows: 17364\n",
      "Retained rows: 2592\n"
     ]
    }
   ],
   "source": [
    "# Keep only necessary columns and reorder them to match \n",
    "def prune_and_rename_cols(merged_guide_file, is_pool_f=False):\n",
    "    # start from full table so you don't drop rows prematurely\n",
    "    df = merged_guide_file.copy()\n",
    "\n",
    "    if is_pool_f:\n",
    "        df[\"guide_id\"] = (\n",
    "            df.get(\"id_gersbach\").combine_first(df.get(\"id_engreitz\"))\n",
    "        )\n",
    "        df[\"intended_target_name\"] = (\n",
    "            df.get(\"intended_target_name_gersbach\")\n",
    "            .combine_first(df.get(\"intended_target_name_engreitz\"))\n",
    "        )\n",
    "    else:\n",
    "        df[\"guide_id\"] = (\n",
    "            df.get(\"id_hon\")\n",
    "            .combine_first(df.get(\"id_gersbach\"))\n",
    "            .combine_first(df.get(\"id_engreitz\"))\n",
    "            .combine_first(df.get(\"id_huangfu\"))\n",
    "        )\n",
    "        df[\"intended_target_name\"] = (\n",
    "            df.get(\"intended_target_name_hon\")\n",
    "            .combine_first(df.get(\"intended_target_name_gersbach\"))\n",
    "            .combine_first(df.get(\"intended_target_name_engreitz\"))\n",
    "            .combine_first(df.get(\"intended_target_name_huangfu\"))\n",
    "        )\n",
    "\n",
    "    # Fallbacks for control / non‑targeting rows.\n",
    "    #df[\"guide_id\"] = df[\"guide_id\"].fillna(df.get(\"id\", df.get(\"protospacer\")))\n",
    "    \n",
    "    # if 'intended_target_name' is NA, set explicitly to np.nan; otherwise fill from 'type' if available\n",
    "    df[\"intended_target_name\"] = np.where(\n",
    "        df[\"intended_target_name\"].isna(),\n",
    "        df.get(\"type\", np.nan),\n",
    "        df[\"intended_target_name\"]\n",
    "    )\n",
    "\n",
    "    # Rename after all adjustments\n",
    "    if \"protospacer\" in df.columns:\n",
    "        df = df.rename(columns={\"protospacer\": \"spacer\"})\n",
    "\n",
    "    keep_cols = [c for c in [\"guide_id\", \"spacer\", \"type\", \"intended_target_name\", \"reverse_compliment\"] if c in df.columns]\n",
    "    ref_clean_sub = df[keep_cols].copy()\n",
    "\n",
    "    print(f\"Retained rows: {ref_clean_sub.shape[0]}\")\n",
    "    return ref_clean_sub\n",
    "\n",
    "# Call function\n",
    "ref_clean_sub = prune_and_rename_cols(merged_guide_file)\n",
    "ref_clean_sub_poolabcd = prune_and_rename_cols(merged_guide_file_poolabcd)\n",
    "ref_clean_sub_poolf = prune_and_rename_cols(merged_guide_file_poolf, is_pool_f=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17250 sequences with ≥20 nt and 2706 sequences with <20.\n",
      "All ≥20‑nt sequences start with 'G' - removed leading 'G' from every spacer.\n",
      "Found 17250 sequences with ≥20 nt and 114 sequences with <20.\n",
      "All ≥20‑nt sequences start with 'G' - removed leading 'G' from every spacer.\n",
      "Found 0 sequences with ≥20 nt and 2592 sequences with <20.\n",
      "No sequences ≥20 nt — nothing to test.\n"
     ]
    }
   ],
   "source": [
    "# Remove leading 'G' if all spacers have one\n",
    "def strip_leading_G(df, column=\"spacer\"):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Normalize to uppercase strings for checking\n",
    "    seqs = df[column].astype(str).str.strip().str.upper()\n",
    "    non_empty = seqs[seqs != \"\"]\n",
    "\n",
    "    # Split by length\n",
    "    lens = non_empty.str.len()\n",
    "    long_seqs = non_empty[lens >= 20]\n",
    "    short_seqs = non_empty[lens < 20]\n",
    "\n",
    "    print(f\"Found {len(long_seqs)} sequences with ≥20 nt and {len(short_seqs)} sequences with <20.\")\n",
    "\n",
    "    if long_seqs.empty:\n",
    "        print(\"No sequences ≥20 nt — nothing to test.\")\n",
    "        return df\n",
    "    # For 20 bp sequences, check if they all start with G\n",
    "    starts_with_G = long_seqs.str.startswith(\"G\").all()\n",
    "\n",
    "    if starts_with_G:\n",
    "        df[column] = seqs.str.replace(r\"^G\", \"\", regex=True)\n",
    "        print(f\"All ≥20‑nt sequences start with 'G' - removed leading 'G' from every {column}.\")\n",
    "    else:\n",
    "        print(\"Not all ≥20‑nt sequences start with 'G' - leaving data unchanged.\")\n",
    "        non_g = long_seqs[~long_seqs.str.startswith(\"G\")]\n",
    "        if not non_g.empty:\n",
    "            show_n = min(10, len(non_g))\n",
    "            print(f\"{len(non_g)} long sequences lack leading 'G'; examples:\")\n",
    "            for s in non_g.head(show_n):\n",
    "                print(\" \", s)\n",
    "\n",
    "    return df\n",
    "\n",
    "ref_clean_sub = strip_leading_G(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = strip_leading_G(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = strip_leading_G(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'type' column to targeting/ non-targeting (optional), and then add a 'label' column containing information about positive/ negative controls\n",
    "def simplify_type_column(df):\n",
    "    df = df.copy()\n",
    "    # Copy original type values into 'label'\n",
    "    # Simplify 'type' values, if needed\n",
    "    #df[\"type\"] = np.where(df[\"type\"] == \"non_targeting\", \"non_targeting\", \"targeting\")\n",
    "\n",
    "    df[\"label\"] = df[\"type\"].replace({\n",
    "        \"targeting\": \"tf_targeting\"\n",
    "    })\n",
    "\n",
    "        # Map to human-readable versions for 'type'\n",
    "    type_map = {\n",
    "        \"non_targeting\": \"non-targeting\",\n",
    "        \"negative_control\": \"negative control\",\n",
    "        \"positive_control\": \"positive control\",\n",
    "        \"tf_targeting\": \"targeting\",\n",
    "    }\n",
    "    \n",
    "    df[\"type\"] = df[\"type\"].map(type_map).fillna(df[\"type\"])\n",
    "\n",
    "    return df\n",
    "    \n",
    "ref_clean_sub = simplify_type_column(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = simplify_type_column(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = simplify_type_column(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       guide_id               spacer  targeting       type  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1  CACAGGACGGCCGAGCTGA       True  targeting   \n",
      "1     EN2_-_155251011.23-P1P2-1  CTCCGTGTGCGCCGCGGGA       True  targeting   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2  CTCCGTTGCAACCACACAG       True  targeting   \n",
      "3      KLF6_-_3827130.23-P1P2-2  CTGGAGGATCGATCGGCGG       True  targeting   \n",
      "4     ELF1_+_41593362.23-P1P2-2  TGAGCTGATAAACAGAGGG       True  targeting   \n",
      "\n",
      "  intended_target_name         label  \n",
      "0                FOXN1  tf_targeting  \n",
      "1                  EN2  tf_targeting  \n",
      "2               BCLAF1  tf_targeting  \n",
      "3                 KLF6  tf_targeting  \n",
      "4                 ELF1  tf_targeting  \n",
      "                     guide_id               spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  CATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  TTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  TTTTTGTCTTCAAAAATCT       True   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  CTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name             label  \n",
      "0         targeting                 TFEC      tf_targeting  \n",
      "1         targeting                NR2C1      tf_targeting  \n",
      "2         targeting                NANOG      tf_targeting  \n",
      "3  negative control                OR8B3  negative_control  \n",
      "4         targeting                ZNF48      tf_targeting  \n",
      "       guide_id               spacer  targeting       type  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting   \n",
      "\n",
      "  intended_target_name         label  \n",
      "0                NR2F2  tf_targeting  \n",
      "1                IL6ST  tf_targeting  \n",
      "2               YEATS4  tf_targeting  \n",
      "3                 EPC2  tf_targeting  \n",
      "4                GPR78  tf_targeting  \n"
     ]
    }
   ],
   "source": [
    "# Add 'targeting' column; if type == targeting, set to True, otherwise False\n",
    "def check_targeting(value):\n",
    "    return value.lower() in {\"tf_targeting\", \"negative_control\", \"positive_control\"}\n",
    "\n",
    "def add_targeting_col(ref_clean_sub):\n",
    "    ref_clean_sub['targeting'] = ref_clean_sub['label'].apply(check_targeting)\n",
    "    order = ['guide_id', 'spacer', 'targeting', 'type', 'intended_target_name', 'label']\n",
    "    ref_clean_sub = ref_clean_sub[order]\n",
    "    print(ref_clean_sub.head())\n",
    "    return ref_clean_sub\n",
    "\n",
    "ref_clean_sub = add_targeting_col(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = add_targeting_col(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = add_targeting_col(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified gene names:\n",
      "['OR2C3-6', 'OR1N2-5', 'OR9Q1-1', 'OR2C3-2', 'OR2H1-1', 'OR11H6-5', 'OR9Q1-2', 'OR2W1-1', 'OR2C3-3', 'OR56A4-2', 'OR2W1-2', 'OR9Q1-6', 'OR2C3-4', 'OR2C3-1', 'OR56A4-4', 'OR11H6-1', 'OR2W1-5', 'OR56A4-3', 'OR9Q1-3', 'OR9Q1-5', 'OR2C3-5']\n",
      "Modified gene names:\n",
      "['OR2C3-6', 'OR56A4-4', 'OR11H6-1', 'OR2W1-5', 'OR9Q1-5', 'OR1N2-5', 'OR9Q1-1', 'OR2C3-2', 'OR2H1-1', 'OR2C3-3', 'OR56A4-3', 'OR2W1-2', 'OR9Q1-6', 'OR9Q1-3', 'OR2C3-5', 'OR11H6-5', 'OR9Q1-2', 'OR2W1-1', 'OR2C3-4', 'OR56A4-2', 'OR2C3-1']\n",
      "Modified gene names:\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\571448728.py:10: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df[col].str.contains(pattern, regex=True, na=False)\n",
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\571448728.py:10: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df[col].str.contains(pattern, regex=True, na=False)\n",
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\571448728.py:10: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df[col].str.contains(pattern, regex=True, na=False)\n"
     ]
    }
   ],
   "source": [
    "# Remove \"-\" and appendix from intended target name\n",
    "def clean_gene_names(df, col='intended_target_name'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Regex pattern: dash followed by a single digit at the end\n",
    "    # Exclude NKX family genes\n",
    "    pattern = r'^(?!NKX)[A-Za-z0-9]+-(\\d)$'\n",
    "    \n",
    "    # Boolean mask for rows that match the pattern\n",
    "    mask = df[col].str.contains(pattern, regex=True, na=False)\n",
    "    \n",
    "    # Print the original values that will be modified\n",
    "    print(\"Modified gene names:\")\n",
    "    print(df.loc[mask, col].tolist())\n",
    "    \n",
    "    # Remove the dash and the single digit\n",
    "    df.loc[mask, col] = df.loc[mask, col].str.replace(\n",
    "        r'-(\\d)$', '', regex=True\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "ref_clean_sub = clean_gene_names(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = clean_gene_names(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = clean_gene_names(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       guide_id               spacer  targeting       type  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1  CACAGGACGGCCGAGCTGA       True  targeting   \n",
      "1     EN2_-_155251011.23-P1P2-1  CTCCGTGTGCGCCGCGGGA       True  targeting   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2  CTCCGTTGCAACCACACAG       True  targeting   \n",
      "3      KLF6_-_3827130.23-P1P2-2  CTGGAGGATCGATCGGCGG       True  targeting   \n",
      "4     ELF1_+_41593362.23-P1P2-2  TGAGCTGATAAACAGAGGG       True  targeting   \n",
      "\n",
      "  intended_target_name         label  pam  \n",
      "0                FOXN1  tf_targeting  NGG  \n",
      "1                  EN2  tf_targeting  NGG  \n",
      "2               BCLAF1  tf_targeting  NGG  \n",
      "3                 KLF6  tf_targeting  NGG  \n",
      "4                 ELF1  tf_targeting  NGG  \n",
      "(19956, 7)\n",
      "                     guide_id               spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  CATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  TTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  TTTTTGTCTTCAAAAATCT       True   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  CTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name             label  pam  \n",
      "0         targeting                 TFEC      tf_targeting  NGG  \n",
      "1         targeting                NR2C1      tf_targeting  NGG  \n",
      "2         targeting                NANOG      tf_targeting  NGG  \n",
      "3  negative control                OR8B3  negative_control  NGG  \n",
      "4         targeting                ZNF48      tf_targeting  NGG  \n",
      "(17364, 7)\n",
      "       guide_id               spacer  targeting       type  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting   \n",
      "\n",
      "  intended_target_name         label  pam  \n",
      "0                NR2F2  tf_targeting  NGG  \n",
      "1                IL6ST  tf_targeting  NGG  \n",
      "2               YEATS4  tf_targeting  NGG  \n",
      "3                 EPC2  tf_targeting  NGG  \n",
      "4                GPR78  tf_targeting  NGG  \n",
      "(2592, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\3009873540.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NGG' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  ref_clean_sub.loc[ref_clean_sub[\"targeting\"] == True, \"pam\"] = \"NGG\"\n",
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\3009873540.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NGG' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  ref_clean_sub.loc[ref_clean_sub[\"targeting\"] == True, \"pam\"] = \"NGG\"\n",
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\3009873540.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'NGG' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  ref_clean_sub.loc[ref_clean_sub[\"targeting\"] == True, \"pam\"] = \"NGG\"\n"
     ]
    }
   ],
   "source": [
    "# Add PAM\n",
    "def add_pam(ref_clean_sub):\n",
    "    ref_clean_sub['pam'] = np.nan\n",
    "     # Assign 'NGG' only to targeting rows \n",
    "    ref_clean_sub.loc[ref_clean_sub[\"targeting\"] == True, \"pam\"] = \"NGG\"\n",
    "    print(ref_clean_sub.head())\n",
    "    print(ref_clean_sub.shape)\n",
    "    return ref_clean_sub\n",
    "\n",
    "ref_clean_sub = add_pam(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = add_pam(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = add_pam(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add genomic element column (promoters for everything by non-targeting)\n",
    "def add_genomic_element(ref_clean_sub):\n",
    "    ref_clean_sub['genomic_element'] = pd.Series(\n",
    "        ['promoter' if x != 'non_targeting' else pd.NA for x in ref_clean_sub['label']],\n",
    "        dtype=\"object\"\n",
    "    )\n",
    "    return ref_clean_sub\n",
    "\n",
    "ref_clean_sub = add_genomic_element(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = add_genomic_element(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = add_genomic_element(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protospacer_upper\n",
      "CAGCCACGCGAGAGTAGAA    3\n",
      "ATTGTCACGGCACATTCCA    2\n",
      "CCTGCGGGCGGGACAGAGG    2\n",
      "CAATGGTTAGGCTCTTACA    2\n",
      "AACACCGGATGTGGGGGAG    2\n",
      "                      ..\n",
      "TGGGGAGGAAGCGGTTCTA    2\n",
      "TGGTGCGACCACCACACCC    2\n",
      "TGTCGGAGGACGAGGACCG    2\n",
      "TTCCCGGTTCGCTCGGCCG    2\n",
      "TTCCGCTCCAGGGAAGAGG    2\n",
      "Name: count, Length: 92, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for repeated spacer sequences in index file\n",
    "print(sgrna_index_merged['protospacer_upper'].value_counts().loc[lambda x: x > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple mappings from sgrna_index_merged\n",
    "def deduplicate_index_file(df):\n",
    "    def chrom_rank(chrom):\n",
    "        if pd.isna(chrom):\n",
    "            return 100\n",
    "        if isinstance(chrom, str) and chrom.startswith(\"chr\"):\n",
    "            c = chrom[3:]\n",
    "            if c.isdigit():\n",
    "                return int(c)\n",
    "            elif c == \"X\":\n",
    "                return 23\n",
    "            elif c == \"Y\":\n",
    "                return 24\n",
    "        return 100  # fallback\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Rank and sorting\n",
    "    df[\"chrom_rank\"] = df[\"chr_target\"].map(chrom_rank)\n",
    "    df[\"sort_key\"] = (\n",
    "        df[\"chrom_rank\"].fillna(100) * 1e12 +\n",
    "        df[\"chr_start_target\"].fillna(0) * 1e6 +\n",
    "        (df[\"chr_end_target\"].fillna(0) - df[\"chr_start_target\"].fillna(0))\n",
    "    )\n",
    "    \n",
    "    # Group by spacer sequence\n",
    "    grouped = df.groupby(\"protospacer_upper\", group_keys=False)\n",
    "    \n",
    "    # Keep only groups where all key columns are the same across rows\n",
    "    key_cols = [\n",
    "        \"chr_target\", \"chr_start_target\", \"chr_end_target\",\n",
    "        \"chr_element\", \"chr_start_element\", \"chr_end_element\"\n",
    "    ]\n",
    "    \n",
    "    def is_consistent(group):\n",
    "        return all(group[col].nunique(dropna=False) == 1 for col in key_cols)\n",
    "    \n",
    "    consistent_df = grouped.filter(is_consistent)\n",
    "    \n",
    "    # Deduplicate remaining consistent rows by keeping best ranked\n",
    "    deduped_df = (\n",
    "        consistent_df.sort_values(\"sort_key\")\n",
    "                     .drop_duplicates(subset=\"protospacer_upper\", keep=\"first\")\n",
    "                     .drop(columns=[\"chrom_rank\", \"sort_key\"])\n",
    "    )\n",
    "    \n",
    "    return deduped_df\n",
    "\n",
    "# Apply deduplication before merging\n",
    "sgrna_index_merged = deduplicate_index_file(sgrna_index_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     guide_id               spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  CATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  TTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  TTTTTGTCTTCAAAAATCT       True   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  CTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name             label  pam  \\\n",
      "0         targeting                 TFEC      tf_targeting  NGG   \n",
      "1         targeting                NR2C1      tf_targeting  NGG   \n",
      "2         targeting                NANOG      tf_targeting  NGG   \n",
      "3  negative control                OR8B3  negative_control  NGG   \n",
      "4         targeting                ZNF48      tf_targeting  NGG   \n",
      "\n",
      "  genomic_element guide_chr  guide_start    guide_end strand  \n",
      "0        promoter      chr7  116030705.0  116030723.0      +  \n",
      "1        promoter     chr12   95073493.0   95073511.0      +  \n",
      "2        promoter     chr12    7789912.0    7789930.0      +  \n",
      "3        promoter       NaN          NaN          NaN    NaN  \n",
      "4        promoter     chr16   30395465.0   30395483.0      -  \n",
      "       guide_id               spacer  targeting       type  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting   \n",
      "\n",
      "  intended_target_name         label  pam genomic_element  \\\n",
      "0                NR2F2  tf_targeting  NGG        promoter   \n",
      "1                IL6ST  tf_targeting  NGG        promoter   \n",
      "2               YEATS4  tf_targeting  NGG        promoter   \n",
      "3                 EPC2  tf_targeting  NGG        promoter   \n",
      "4                GPR78  tf_targeting  NGG        promoter   \n",
      "\n",
      "           protospacer guide_chr  guide_start  guide_end strand  \n",
      "0  GAAAACCGCCAACAACTAT     chr15     96325764   96325783      -  \n",
      "1  GAAGGATCTGACAGTGTTC      chr5     55994948   55994966      -  \n",
      "2  GAAGGAGGGCGAGTTACTT     chr12     69359838   69359856      -  \n",
      "3  GAAGGAGGAGGAATCGGTA      chr2    148645155  148645173      +  \n",
      "4  GAAGGAAAGATACAGTGTT      chr4      8580609    8580627      +  \n"
     ]
    }
   ],
   "source": [
    "# Add the 'guide_chr', 'guide_start', and 'guide_end' values, which are given as 'chr_target', 'chr_start_target', 'chr_end_target', and 'strand'\n",
    "def add_guide_coords(ref_clean_sub, sgrna_index_merged):\n",
    "    ref_clean_sub = pd.merge(\n",
    "        ref_clean_sub,\n",
    "        sgrna_index_merged[['protospacer_upper', 'chr_target', 'chr_start_target', 'chr_end_target', 'strand']],\n",
    "        left_on='spacer',\n",
    "        right_on='protospacer_upper',\n",
    "        how='left'\n",
    "    )\n",
    "    # Remove protospacer_upper column\n",
    "    ref_clean_sub = ref_clean_sub.drop(columns=['protospacer_upper'])\n",
    "    # Rename intended guide names\n",
    "    ref_clean_sub.rename(columns={'chr_target': 'guide_chr', \n",
    "                                  'chr_start_target': 'guide_start',\n",
    "                                  'chr_end_target': 'guide_end'},\n",
    "                                  inplace=True)\n",
    "\n",
    "\n",
    "    #print(ref_clean_sub.head())\n",
    "    return ref_clean_sub\n",
    "\n",
    "\n",
    "ref_clean_sub_poolabcd = add_guide_coords(ref_clean_sub_poolabcd, sgrna_index_merged)\n",
    "print(ref_clean_sub_poolabcd.head())\n",
    "#print(sgrna_index_merged[sgrna_index_merged['protospacer_upper'] == 'CGGCGACCCTAGGAGAGGT'])\n",
    "#print(ref_clean_sub_poolabcd[ref_clean_sub_poolabcd['spacer'] == 'CGGCGACCCTAGGAGAGGT'])\n",
    "\n",
    "# Columns are already correctly labeled for pool F\n",
    "ref_clean_sub_poolf = pd.merge(\n",
    "    ref_clean_sub_poolf,\n",
    "    sgrna_index_poolf[['protospacer', 'guide_chr', 'guide_start', 'guide_end', 'strand']],\n",
    "    left_on='spacer',\n",
    "    right_on='protospacer',\n",
    "    how='left'\n",
    ")\n",
    "print(ref_clean_sub_poolf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     guide_id               spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  CATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  TTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  TTTTTGTCTTCAAAAATCT       True   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  CTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name             label  pam  \\\n",
      "0         targeting                 TFEC      tf_targeting  NGG   \n",
      "1         targeting                NR2C1      tf_targeting  NGG   \n",
      "2         targeting                NANOG      tf_targeting  NGG   \n",
      "3  negative control                OR8B3  negative_control  NGG   \n",
      "4         targeting                ZNF48      tf_targeting  NGG   \n",
      "\n",
      "  genomic_element guide_chr  guide_start    guide_end strand  \\\n",
      "0        promoter      chr7  116030705.0  116030723.0      +   \n",
      "1        promoter     chr12   95073493.0   95073511.0      +   \n",
      "2        promoter     chr12    7789912.0    7789930.0      +   \n",
      "3        promoter       NaN          NaN          NaN    NaN   \n",
      "4        promoter     chr16   30395465.0   30395483.0      -   \n",
      "\n",
      "  intended_target_chr  intended_target_start  intended_target_end  \n",
      "0                chr7            116030682.0          116030770.0  \n",
      "1               chr12             95073472.0           95073659.0  \n",
      "2               chr12              7789786.0            7789930.0  \n",
      "3                 NaN                    NaN                  NaN  \n",
      "4               chr16             30395465.0           30395994.0  \n"
     ]
    }
   ],
   "source": [
    "# Add the intended_target_chr/intended_target_start/intended_target_end values, which are given as 'chr_element', 'chr_start_element', 'chr_end_element'\n",
    "# Note that this refers to the element being targeted, not the gene itself\n",
    "def add_element_coords(ref_clean_sub, sgrna_index_merged):\n",
    "    ref_clean_sub = pd.merge(\n",
    "        ref_clean_sub,\n",
    "        sgrna_index_merged[['protospacer_upper', 'chr_element', 'chr_start_element', 'chr_end_element']],\n",
    "        left_on='spacer',\n",
    "        right_on='protospacer_upper',\n",
    "        how='left'\n",
    "    )\n",
    "    # Remove protospacer_upper column\n",
    "    ref_clean_sub = ref_clean_sub.drop(columns=['protospacer_upper'])\n",
    "    # Rename intended target names\n",
    "    ref_clean_sub.rename(columns={'chr_element': 'intended_target_chr', \n",
    "                                  'chr_start_element': 'intended_target_start',\n",
    "                                  'chr_end_element': 'intended_target_end'},\n",
    "                                  inplace=True)\n",
    "    print(ref_clean_sub.head())\n",
    "    return ref_clean_sub\n",
    "\n",
    "\n",
    "ref_clean_sub_poolabcd = add_element_coords(ref_clean_sub_poolabcd, sgrna_index_merged)\n",
    "#print(ref_clean_sub_poolabcd[ref_clean_sub_poolabcd['spacer'] == 'CGGCGACCCTAGGAGAGGT'])\n",
    "\n",
    "ref_clean_sub_poolabcd.head()\n",
    "\n",
    "# Columns are already correctly labeled for pool F\n",
    "ref_clean_sub_poolf = pd.merge(\n",
    "    ref_clean_sub_poolf,\n",
    "    sgrna_index_poolf[['protospacer', 'intended_target_chr', 'intended_target_start', 'intended_target_end']],\n",
    "    left_on='spacer',\n",
    "    right_on='protospacer',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   guide_id                spacer  targeting       type guide_chr  \\\n",
      "0  AFF4_sg1  CCAGCGGACGGGGCGGGGAC       True  targeting      chr5   \n",
      "1  AFF4_sg2  CCGCCAGCGGACGGGGCGGC       True  targeting      chr5   \n",
      "2  AFF4_sg3  CGTCCGCTGGCGGCGGCGAC       True  targeting      chr5   \n",
      "3  AFF4_sg4  CTGCGTCAGTCACAGCCCTC       True  targeting      chr5   \n",
      "4  AFF4_sg5  GCGGACGGGGCGGGGATCCC       True  targeting      chr5   \n",
      "\n",
      "   guide_start    guide_end strand  pam intended_target_name  \\\n",
      "0  132299282.0  132299302.0      -  NGG                 AFF4   \n",
      "1  132299282.0  132299302.0      -  NGG                 AFF4   \n",
      "2  132299252.0  132299272.0      -  NGG                 AFF4   \n",
      "3  132299279.0  132299299.0      -  NGG                 AFF4   \n",
      "4  132299279.0  132299299.0      -  NGG                 AFF4   \n",
      "\n",
      "  intended_target_chr  intended_target_start  intended_target_end  \n",
      "0                chr5            132875395.0          132963634.0  \n",
      "1                chr5            132875395.0          132963634.0  \n",
      "2                chr5            132875395.0          132963634.0  \n",
      "3                chr5            132875395.0          132963634.0  \n",
      "4                chr5            132875395.0          132963634.0  \n",
      "                     guide_id               spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  CATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  TTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  TTTTTGTCTTCAAAAATCT       True   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  CTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type guide_chr  guide_start    guide_end strand  pam  \\\n",
      "0         targeting      chr7  116030705.0  116030723.0      +  NGG   \n",
      "1         targeting     chr12   95073493.0   95073511.0      +  NGG   \n",
      "2         targeting     chr12    7789912.0    7789930.0      +  NGG   \n",
      "3  negative control       NaN          NaN          NaN    NaN  NGG   \n",
      "4         targeting     chr16   30395465.0   30395483.0      -  NGG   \n",
      "\n",
      "  intended_target_name intended_target_chr  intended_target_start  \\\n",
      "0                 TFEC                chr7            116030682.0   \n",
      "1                NR2C1               chr12             95073472.0   \n",
      "2                NANOG               chr12              7789786.0   \n",
      "3                OR8B3                 NaN                    NaN   \n",
      "4                ZNF48               chr16             30395465.0   \n",
      "\n",
      "   intended_target_end             label genomic_element  \n",
      "0          116030770.0      tf_targeting        promoter  \n",
      "1           95073659.0      tf_targeting        promoter  \n",
      "2            7789930.0      tf_targeting        promoter  \n",
      "3                  NaN  negative_control        promoter  \n",
      "4           30395994.0      tf_targeting        promoter  \n",
      "       guide_id               spacer  targeting       type guide_chr  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting     chr15   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting      chr5   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting     chr12   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting      chr2   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting      chr4   \n",
      "\n",
      "   guide_start  guide_end strand  pam intended_target_name  \\\n",
      "0     96325764   96325783      -  NGG                NR2F2   \n",
      "1     55994948   55994966      -  NGG                IL6ST   \n",
      "2     69359838   69359856      -  NGG               YEATS4   \n",
      "3    148645155  148645173      +  NGG                 EPC2   \n",
      "4      8580609    8580627      +  NGG                GPR78   \n",
      "\n",
      "  intended_target_chr  intended_target_start  intended_target_end  \\\n",
      "0               chr15               96325677             96326177   \n",
      "1                chr5               55994565             55994997   \n",
      "2               chr12               69359838             69360118   \n",
      "3                chr2              148644731            148645173   \n",
      "4                chr4                8580584              8580844   \n",
      "\n",
      "          label genomic_element  \n",
      "0  tf_targeting        promoter  \n",
      "1  tf_targeting        promoter  \n",
      "2  tf_targeting        promoter  \n",
      "3  tf_targeting        promoter  \n",
      "4  tf_targeting        promoter  \n",
      "0\n",
      "label\n",
      "tf_targeting        16126\n",
      "negative_control      619\n",
      "non_targeting         600\n",
      "positive_control       19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(example_crispr_file.head())\n",
    "\n",
    "# Reorganize columns to match\n",
    "new_order = ['guide_id', 'spacer', 'targeting', 'type', 'guide_chr', 'guide_start', 'guide_end', 'strand', 'pam', 'intended_target_name', 'intended_target_chr', 'intended_target_start', 'intended_target_end', 'label', 'genomic_element']\n",
    "ref_clean_sub_poolabcd = ref_clean_sub_poolabcd[new_order].drop_duplicates()\n",
    "print(ref_clean_sub_poolabcd.head())\n",
    "ref_clean_sub_poolf = ref_clean_sub_poolf[new_order].drop_duplicates()\n",
    "print(ref_clean_sub_poolf.head())\n",
    "\n",
    "controls_in_ref = ref_clean_sub_poolabcd[\n",
    "    ref_clean_sub_poolabcd['spacer'].isin(non_targeting['Photospacer (same for all 3 sets)'])\n",
    "    | ref_clean_sub_poolabcd['spacer'].isin(pos_controls['Photospacer (represent 10 times)'])\n",
    "    | ref_clean_sub_poolabcd['spacer'].isin(neg_spacers)\n",
    "]\n",
    "print(len(controls_in_ref))\n",
    "print(ref_clean_sub_poolabcd['label'].value_counts(dropna=False))\n",
    "#controls_in_ref.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows with non-standard chromosomes (i.e. chr1, chr2, chrX, etc., not chrU) by making sure chr is not followed by a letter other than X or Y\n",
    "control_types = ['non_targeting', 'negative_control', 'positive_control']\n",
    "\n",
    "# Mask for control and targeting guides\n",
    "is_control = ref_clean_sub_poolabcd['label'].str.lower().isin(control_types)\n",
    "is_targeting = ~is_control\n",
    "\n",
    "# Standard chromosome pattern\n",
    "standard_chr_pattern = r'^chr(\\d+|X|Y)$'\n",
    "\n",
    "# Split, filter targeting only\n",
    "controls_df = ref_clean_sub_poolabcd[is_control]\n",
    "targets_df = ref_clean_sub_poolabcd[is_targeting]\n",
    "\n",
    "filtered_targets_df = targets_df[\n",
    "    targets_df['guide_chr'].notna()\n",
    "    & targets_df['intended_target_chr'].notna()\n",
    "    & targets_df['guide_chr'].str.match(standard_chr_pattern)\n",
    "    & targets_df['intended_target_chr'].str.match(standard_chr_pattern)\n",
    "]\n",
    "\n",
    "# Recombine targets + controls\n",
    "ref_clean_sub_poolabcd = pd.concat([filtered_targets_df, controls_df], ignore_index=True)\n",
    "ref_clean_sub_poolf = pd.concat([ref_clean_sub_poolf, controls_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\838438229.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(collapse_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14172, 15)\n",
      "(3862, 15)\n",
      "label\n",
      "tf_targeting        12934\n",
      "negative_control      619\n",
      "non_targeting         600\n",
      "positive_control       19\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seg95\\AppData\\Local\\Temp\\ipykernel_12264\\838438229.py:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(collapse_group)\n"
     ]
    }
   ],
   "source": [
    "# There are certain examples where a target has the same protospacer sequence but multiple local_target_start and local_target_end\n",
    "# values, which throws errors with the pipeline. This takes the min/max of those values (dependent on strand) and collapses into a single row\n",
    "\n",
    "# Collapse groups of targeting guides that have identical metadata but\n",
    "# multiple start/end coordinates. For negative‑strand entries, we take the\n",
    "# max(start) / min(end); for positive‑strand or mixed, min(start) / max(end).\n",
    "# Control or non‑targeting rows are passed through unchanged.\n",
    "def collapse_grouped_targets(df):\n",
    "\n",
    "    def collapse_group(subdf):\n",
    "        # Handle both guide_ and intended_target_ coordinates\n",
    "        if (subdf[\"strand\"] == \"-\").all():\n",
    "            g_start = subdf[\"guide_start\"].max()\n",
    "            g_end   = subdf[\"guide_end\"].min()\n",
    "            t_start = subdf[\"intended_target_start\"].max()\n",
    "            t_end   = subdf[\"intended_target_end\"].min()\n",
    "        else:\n",
    "            g_start = subdf[\"guide_start\"].min()\n",
    "            g_end   = subdf[\"guide_end\"].max()\n",
    "            t_start = subdf[\"intended_target_start\"].min()\n",
    "            t_end   = subdf[\"intended_target_end\"].max()\n",
    "\n",
    "        row = subdf.iloc[0].copy()\n",
    "        row[\"guide_start\"] = g_start\n",
    "        row[\"guide_end\"] = g_end\n",
    "        row[\"intended_target_start\"] = t_start\n",
    "        row[\"intended_target_end\"] = t_end\n",
    "        return row\n",
    "\n",
    "    # Identify control / non-targeting rows (pass through unchanged)\n",
    "    is_control = (\n",
    "        df[\"type\"].str.contains(\"non\", case=False, na=False)\n",
    "        #| df[\"type\"].str.contains(\"control\", case=False, na=False)\n",
    "    )\n",
    "\n",
    "    controls_df = df[is_control].copy()\n",
    "    targets_df  = df[~is_control].copy()\n",
    "\n",
    "    # Exclude all coordinate columns from grouping\n",
    "    coord_cols = [\n",
    "        \"guide_start\", \"guide_end\",\n",
    "        \"intended_target_start\", \"intended_target_end\"\n",
    "    ]\n",
    "    group_cols = [c for c in targets_df.columns if c not in coord_cols]\n",
    "\n",
    "    collapsed_targets = (\n",
    "        targets_df\n",
    "        .groupby(group_cols, dropna=False)\n",
    "        .apply(collapse_group)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    combined = pd.concat([collapsed_targets, controls_df], ignore_index=True)\n",
    "    return combined\n",
    "\n",
    "ref_clean_sub_poolabcd = collapse_grouped_targets(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf    = collapse_grouped_targets(ref_clean_sub_poolf)\n",
    "print(ref_clean_sub_poolabcd.shape)\n",
    "print(ref_clean_sub_poolf.shape)\n",
    "print(ref_clean_sub_poolabcd['label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also write a version without mostly NA values, duplicate rows\n",
    "#print(ref_clean_sub_poolabcd.shape)\n",
    "#ref_clean_sub_poolabcd_clean = ref_clean_sub_poolabcd.dropna(thresh = (len(ref_clean_sub_poolabcd.columns)/2)).drop_duplicates()\n",
    "#print(ref_clean_sub_poolabcd_clean.shape)\n",
    "#ref_clean_sub_poolabcd_clean.to_csv(local_path + \"harmonized_guide_file_poolabcd_nomissing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacer\n",
      "CGCCGGCGCGCCTGCGAGG    4\n",
      "TCCTGCGATATCCAGGCGA    4\n",
      "CTCCTTGCAGCCACCACGG    4\n",
      "GCTCACGTCATCCCGACCG    4\n",
      "CGACACTACCAGCTGCTGT    4\n",
      "CAAATCCTCCTGTCTTTCG    4\n",
      "CGTGCAAAACCCTGTGCCT    4\n",
      "CAACTTGCCACTCAAACGC    2\n",
      "GCCGGAGCTACCGGCAGCC    2\n",
      "GCTCCGCCGCTCGGCCCCT    2\n",
      "CACGTAACGGGACCACACA    2\n",
      "GACGCCCCCGGCCAGGTGA    2\n",
      "CACTTGCAGGGGCGCGAGG    2\n",
      "GTCCTTCCCGTCGCCTGCA    2\n",
      "AGTGAGGACTAACGGGGCA    2\n",
      "GGAAACCGCCAGACACCAA    2\n",
      "CACGCCAGACCACGACGGA    2\n",
      "GCTCCACCCTTTCCGGGCG    2\n",
      "Name: count, dtype: int64\n",
      "    guide_id               spacer                guide_chr  guide_start  \\\n",
      "654    DGCR6  CGCCGGCGCGCCTGCGAGG                    chr22   18905981.0   \n",
      "655    DGCR6  CGCCGGCGCGCCTGCGAGG                    chr22   18905981.0   \n",
      "656    DGCR6  CGCCGGCGCGCCTGCGAGG  chr22_KI270734v1_random     131252.0   \n",
      "657    DGCR6  CGCCGGCGCGCCTGCGAGG  chr22_KI270734v1_random     131252.0   \n",
      "658  DGCR6.2  TCCTGCGATATCCAGGCGA                    chr22   18906057.0   \n",
      "\n",
      "      guide_end strand intended_target_name      intended_target_chr  \\\n",
      "654  18906000.0      -                DGCR6                    chr22   \n",
      "655  18906000.0      -                DGCR6  chr22_KI270734v1_random   \n",
      "656    131271.0      -                DGCR6                    chr22   \n",
      "657    131271.0      -                DGCR6  chr22_KI270734v1_random   \n",
      "658  18906076.0      +                DGCR6                    chr22   \n",
      "\n",
      "     intended_target_start  intended_target_end  \n",
      "654             18905972.0           18906472.0  \n",
      "655               131243.0             131743.0  \n",
      "656             18905972.0           18906472.0  \n",
      "657               131243.0             131743.0  \n",
      "658             18905972.0           18906472.0  \n",
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "# Interrogate duplicate spacers\n",
    "duplicate_spacers_poolf = ref_clean_sub_poolf[ref_clean_sub_poolf[\"spacer\"].duplicated(keep=False)]\n",
    "print(duplicate_spacers_poolf[\"spacer\"].value_counts())\n",
    "\n",
    "duplicate_spacers_poolf_diff = duplicate_spacers_poolf.loc[:, duplicate_spacers_poolf.nunique() > 1]\n",
    "print(duplicate_spacers_poolf_diff.head())\n",
    "print(duplicate_spacers_poolf_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 21 '_random' contig rows covered by canonical entries.\n",
      "spacer\n",
      "AGTGAGGACTAACGGGGCA    2\n",
      "CAACTTGCCACTCAAACGC    2\n",
      "CACGCCAGACCACGACGGA    2\n",
      "CACGTAACGGGACCACACA    2\n",
      "CACTTGCAGGGGCGCGAGG    2\n",
      "GACGCCCCCGGCCAGGTGA    2\n",
      "GCCGGAGCTACCGGCAGCC    2\n",
      "GCTCCACCCTTTCCGGGCG    2\n",
      "GCTCCGCCGCTCGGCCCCT    2\n",
      "GGAAACCGCCAGACACCAA    2\n",
      "GTCCTTCCCGTCGCCTGCA    2\n",
      "Name: count, dtype: int64\n",
      "           guide_id               spacer  targeting       type guide_chr  \\\n",
      "594         NCF1B.6  AGTGAGGACTAACGGGGCA       True  targeting      chr7   \n",
      "595         NCF1B.6  AGTGAGGACTAACGGGGCA       True  targeting      chr7   \n",
      "750        GATSL2.2  CAACTTGCCACTCAAACGC       True  targeting      chr7   \n",
      "751        GATSL2.2  CAACTTGCCACTCAAACGC       True  targeting      chr7   \n",
      "799       STAG3L2.3  CACGCCAGACCACGACGGA       True  targeting      chr7   \n",
      "800       STAG3L2.3  CACGCCAGACCACGACGGA       True  targeting      chr7   \n",
      "810  LOC100101148.2  CACGTAACGGGACCACACA       True  targeting      chr7   \n",
      "811  LOC100101148.2  CACGTAACGGGACCACACA       True  targeting      chr7   \n",
      "822     LOC541473.2  CACTTGCAGGGGCGCGAGG       True  targeting      chr7   \n",
      "823     LOC541473.2  CACTTGCAGGGGCGCGAGG       True  targeting      chr7   \n",
      "\n",
      "     guide_start   guide_end strand  pam intended_target_name  \\\n",
      "594   73220803.0  73220822.0      +  NGG                NCF1B   \n",
      "595   75171766.0  75171785.0      -  NGG                NCF1B   \n",
      "750   75237704.0  75237723.0      +  NGG               GATSL2   \n",
      "751   74964667.0  74964686.0      -  NGG               GATSL2   \n",
      "799   74890528.0  74890547.0      +  NGG              STAG3L2   \n",
      "800   75359249.0  75359268.0      -  NGG              STAG3L2   \n",
      "810   75395553.0  75395572.0      +  NGG         LOC100101148   \n",
      "811   72969522.0  72969541.0      -  NGG         LOC100101148   \n",
      "822   75395584.0  75395603.0      +  NGG            LOC541473   \n",
      "823   72969491.0  72969510.0      -  NGG            LOC541473   \n",
      "\n",
      "    intended_target_chr  intended_target_start  intended_target_end  \\\n",
      "594                chr7             73220388.0           75172248.0   \n",
      "595                chr7             75171748.0           73220888.0   \n",
      "750                chr7             74964567.0           75237955.0   \n",
      "751                chr7             75237455.0           74965067.0   \n",
      "799                chr7             74890362.0           75359449.0   \n",
      "800                chr7             75358949.0           74890862.0   \n",
      "810                chr7             72969431.0           75395711.0   \n",
      "811                chr7             75395211.0           72969931.0   \n",
      "822                chr7             72969383.0           75395663.0   \n",
      "823                chr7             75395163.0           72969883.0   \n",
      "\n",
      "            label genomic_element  \n",
      "594  tf_targeting        promoter  \n",
      "595  tf_targeting        promoter  \n",
      "750  tf_targeting        promoter  \n",
      "751  tf_targeting        promoter  \n",
      "799  tf_targeting        promoter  \n",
      "800  tf_targeting        promoter  \n",
      "810  tf_targeting        promoter  \n",
      "811  tf_targeting        promoter  \n",
      "822  tf_targeting        promoter  \n",
      "823  tf_targeting        promoter  \n",
      "            guide_id               spacer  guide_start   guide_end strand  \\\n",
      "594          NCF1B.6  AGTGAGGACTAACGGGGCA   73220803.0  73220822.0      +   \n",
      "595          NCF1B.6  AGTGAGGACTAACGGGGCA   75171766.0  75171785.0      -   \n",
      "750         GATSL2.2  CAACTTGCCACTCAAACGC   75237704.0  75237723.0      +   \n",
      "751         GATSL2.2  CAACTTGCCACTCAAACGC   74964667.0  74964686.0      -   \n",
      "799        STAG3L2.3  CACGCCAGACCACGACGGA   74890528.0  74890547.0      +   \n",
      "800        STAG3L2.3  CACGCCAGACCACGACGGA   75359249.0  75359268.0      -   \n",
      "810   LOC100101148.2  CACGTAACGGGACCACACA   75395553.0  75395572.0      +   \n",
      "811   LOC100101148.2  CACGTAACGGGACCACACA   72969522.0  72969541.0      -   \n",
      "822      LOC541473.2  CACTTGCAGGGGCGCGAGG   75395584.0  75395603.0      +   \n",
      "823      LOC541473.2  CACTTGCAGGGGCGCGAGG   72969491.0  72969510.0      -   \n",
      "1939  LOC100101148.6  GACGCCCCCGGCCAGGTGA   72969855.0  72969874.0      +   \n",
      "1940  LOC100101148.6  GACGCCCCCGGCCAGGTGA   75395220.0  75395239.0      -   \n",
      "2290       GTF2IP1.2  GCCGGAGCTACCGGCAGCC   75237842.0  75237861.0      +   \n",
      "2291       GTF2IP1.2  GCCGGAGCTACCGGCAGCC   73154766.0  73154785.0      -   \n",
      "2462       STAG3L3.5  GCTCCACCCTTTCCGGGCG   75359067.0  75359086.0      +   \n",
      "2463       STAG3L3.5  GCTCCACCCTTTCCGGGCG   74890703.0  73006050.0      -   \n",
      "2471       GTF2IP1.9  GCTCCGCCGCTCGGCCCCT   74964737.0  74964756.0      +   \n",
      "2472       GTF2IP1.9  GCTCCGCCGCTCGGCCCCT   75237634.0  75237653.0      -   \n",
      "2528       STAG3L2.2  GGAAACCGCCAGACACCAA   74890450.0  74890469.0      +   \n",
      "2529       STAG3L2.2  GGAAACCGCCAGACACCAA   75359327.0  75359346.0      -   \n",
      "3016           NCF1B  GTCCTTCCCGTCGCCTGCA   75172167.0  75172186.0      +   \n",
      "3017           NCF1B  GTCCTTCCCGTCGCCTGCA   73220402.0  73220421.0      -   \n",
      "\n",
      "     intended_target_name  intended_target_start  intended_target_end  \n",
      "594                 NCF1B             73220388.0           75172248.0  \n",
      "595                 NCF1B             75171748.0           73220888.0  \n",
      "750                GATSL2             74964567.0           75237955.0  \n",
      "751                GATSL2             75237455.0           74965067.0  \n",
      "799               STAG3L2             74890362.0           75359449.0  \n",
      "800               STAG3L2             75358949.0           74890862.0  \n",
      "810          LOC100101148             72969431.0           75395711.0  \n",
      "811          LOC100101148             75395211.0           72969931.0  \n",
      "822             LOC541473             72969383.0           75395663.0  \n",
      "823             LOC541473             75395163.0           72969883.0  \n",
      "1939         LOC100101148             72969431.0           75395711.0  \n",
      "1940         LOC100101148             75395211.0           72969931.0  \n",
      "2290              GTF2IP1             73154678.0           75237955.0  \n",
      "2291              GTF2IP1             75237455.0           73155178.0  \n",
      "2462              STAG3L3             73005693.0           75359449.0  \n",
      "2463              STAG3L3             75358949.0           73006193.0  \n",
      "2471              GTF2IP1             74964567.0           75237955.0  \n",
      "2472              GTF2IP1             75237455.0           74965067.0  \n",
      "2528              STAG3L2             74890362.0           75359449.0  \n",
      "2529              STAG3L2             75358949.0           74890862.0  \n",
      "3016                NCF1B             73220388.0           75172248.0  \n",
      "3017                NCF1B             75171748.0           73220888.0  \n",
      "(22, 8)\n"
     ]
    }
   ],
   "source": [
    "# Drop alternate contigs if a canonical chr exists (e.g. chr22_KI270731v1_random)\n",
    "import re\n",
    "def remove_random_contigs(df):\n",
    "    df = df.copy()\n",
    "    keep_rows = []\n",
    "\n",
    "    canonical_pattern = re.compile(r\"^chr(\\d+|X|Y)$\", re.IGNORECASE)\n",
    "\n",
    "    for spacer, subdf in df.groupby(\"spacer\", group_keys=False):\n",
    "        has_main = (\n",
    "            subdf[\"guide_chr\"].astype(str).str.match(canonical_pattern).any() or\n",
    "            subdf[\"intended_target_chr\"].astype(str).str.match(canonical_pattern).any()\n",
    "        )\n",
    "\n",
    "        if has_main:\n",
    "            mask = (\n",
    "                subdf[\"guide_chr\"].astype(str).str.match(canonical_pattern)\n",
    "                & subdf[\"intended_target_chr\"].astype(str).str.match(canonical_pattern)\n",
    "            )\n",
    "            keep_rows.append(subdf[mask])\n",
    "        else:\n",
    "            # If no canonical version exists, keep all\n",
    "            keep_rows.append(subdf)\n",
    "\n",
    "    cleaned = pd.concat(keep_rows, ignore_index=True)\n",
    "    return cleaned\n",
    "\n",
    "before = len(ref_clean_sub_poolf)\n",
    "ref_clean_sub_poolf = remove_random_contigs(ref_clean_sub_poolf)\n",
    "after = len(ref_clean_sub_poolf)\n",
    "\n",
    "print(f\"Removed {before - after} '_random' contig rows covered by canonical entries.\")\n",
    "\n",
    "duplicate_spacers_poolf = ref_clean_sub_poolf[ref_clean_sub_poolf[\"spacer\"].duplicated(keep=False)]\n",
    "print(duplicate_spacers_poolf[\"spacer\"].value_counts())\n",
    "print(duplicate_spacers_poolf.head(10))\n",
    "\n",
    "duplicate_spacers_poolf_diff = duplicate_spacers_poolf.loc[:, duplicate_spacers_poolf.nunique() > 1]\n",
    "print(duplicate_spacers_poolf_diff)\n",
    "print(duplicate_spacers_poolf_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping AGTGAGGACTAACGGGGCA (+), removing 1 opposite-strand rows\n",
      "Keeping CAACTTGCCACTCAAACGC (+), removing 1 opposite-strand rows\n",
      "Keeping CACGCCAGACCACGACGGA (-), removing 1 opposite-strand rows\n",
      "Keeping CACGTAACGGGACCACACA (+), removing 1 opposite-strand rows\n",
      "Keeping CACTTGCAGGGGCGCGAGG (+), removing 1 opposite-strand rows\n",
      "Keeping GACGCCCCCGGCCAGGTGA (+), removing 1 opposite-strand rows\n",
      "Keeping GCCGGAGCTACCGGCAGCC (-), removing 1 opposite-strand rows\n",
      "Keeping GCTCCACCCTTTCCGGGCG (-), removing 1 opposite-strand rows\n",
      "Keeping GCTCCGCCGCTCGGCCCCT (-), removing 1 opposite-strand rows\n",
      "Keeping GGAAACCGCCAGACACCAA (-), removing 1 opposite-strand rows\n",
      "Keeping GTCCTTCCCGTCGCCTGCA (+), removing 1 opposite-strand rows\n",
      "Removed 11 strand-mismatched rows.\n",
      "0 duplicate spacers remain.\n"
     ]
    }
   ],
   "source": [
    "# Manually remove 11 strand mismatches in Pool F to select the most canonical one\n",
    "canonical_strand_choices = {\n",
    "    \"AGTGAGGACTAACGGGGCA\": \"+\",  # NCF1B.6\n",
    "    \"CAACTTGCCACTCAAACGC\": \"+\",  # GATSL2.3\n",
    "    \"CACGCCAGACCACGACGGA\": \"-\",  # STAG3L2.3\n",
    "    \"CACGTAACGGGACCACACA\": \"+\",  # LOC100101148.2\n",
    "    \"CACTTGCAGGGGCGCGAGG\": \"+\", # LOC541473.2\n",
    "    \"GACGCCCCCGGCCAGGTGA\": \"+\",  # LOC100101148.6\n",
    "    \"GCCGGAGCTACCGGCAGCC\": \"-\",  # GTF2IP1.2\n",
    "    \"GCTCCACCCTTTCCGGGCG\": \"-\",  # STAG3L3.5\n",
    "    \"GCTCCGCCGCTCGGCCCCT\": \"-\",  # GTF2IP1.9\n",
    "    \"GGAAACCGCCAGACACCAA\": \"-\",  # STAG3L2.2\n",
    "    \"GTCCTTCCCGTCGCCTGCA\": \"+\",  # NCF1B\n",
    "}\n",
    "mask_keep = pd.Series(True, index=ref_clean_sub_poolf.index)\n",
    "\n",
    "for spacer, strand in canonical_strand_choices.items():\n",
    "    # Identify all rows for this spacer\n",
    "    idx_all = ref_clean_sub_poolf.index[ref_clean_sub_poolf[\"spacer\"] == spacer]\n",
    "    # Identify those on non-canonical strands\n",
    "    idx_wrong = ref_clean_sub_poolf.index[\n",
    "        (ref_clean_sub_poolf[\"spacer\"] == spacer)\n",
    "        & (ref_clean_sub_poolf[\"strand\"] != strand)\n",
    "    ]\n",
    "    # Mark wrong-strand rows for removal\n",
    "    mask_keep.loc[idx_wrong] = False\n",
    "    print(f\"Keeping {spacer} ({strand}), removing {len(idx_wrong)} opposite-strand rows\")\n",
    "\n",
    "# Apply mask\n",
    "before = len(ref_clean_sub_poolf)\n",
    "ref_clean_sub_poolf = ref_clean_sub_poolf.loc[mask_keep].reset_index(drop=True)\n",
    "after = len(ref_clean_sub_poolf)\n",
    "\n",
    "print(f\"Removed {before - after} strand-mismatched rows.\")\n",
    "print(f\"{ref_clean_sub_poolf['spacer'].duplicated().sum()} duplicate spacers remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          guide_id               spacer  targeting  \\\n",
      "0  AARS#chr16:70289419-70289437(-)  CGGCGACCCTAGGAGAGGT       True   \n",
      "1                           AARS_C  CCGCCCTCGGAGAGCTCTG       True   \n",
      "2  AARS#chr16:70289477-70289495(-)  TCTGCGGGAATAGGTGCAG       True   \n",
      "3  AATF#chr17:36948966-36948984(+)  AGTGGCCGGTCCAGAGCTG       True   \n",
      "4  AATF#chr17:36949026-36949044(+)  GGATCAAGGCGAGAGGATC       True   \n",
      "\n",
      "               type guide_chr  guide_start  guide_end strand  pam  \\\n",
      "0  positive control     chr16     70289419   70289437      -  NGG   \n",
      "1  positive control     chrPC            0          0    NaN  NGG   \n",
      "2  positive control     chr16     70289477   70289495      -  NGG   \n",
      "3         targeting     chr17     36948966   36948984      +  NGG   \n",
      "4         targeting     chr17     36949026   36949044      +  NGG   \n",
      "\n",
      "  intended_target_name intended_target_chr  intended_target_start  \\\n",
      "0                 AARS               chr16             70289409.0   \n",
      "1                 AARS               chrPC                    0.0   \n",
      "2                 AARS               chr16             70289409.0   \n",
      "3                 AATF               chr17             36948966.0   \n",
      "4                 AATF               chr17             36948966.0   \n",
      "\n",
      "   intended_target_end             label genomic_element  \n",
      "0           70289495.0  positive_control        promoter  \n",
      "1                  0.0  positive_control        promoter  \n",
      "2           70289495.0  positive_control        promoter  \n",
      "3           36949088.0      tf_targeting        promoter  \n",
      "4           36949088.0      tf_targeting        promoter  \n",
      "label\n",
      "tf_targeting        12934\n",
      "negative_control      619\n",
      "non_targeting         600\n",
      "positive_control       19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reformat the guide IDs \n",
    "# e.g. ARID1A_+_27022504.23-P1P2-1 --> ARID1A#chr1:26696017-26696035(-)\n",
    "# new format: <target_name>#<guide_chr>:<guide_start>-<guide_end>(<strand>)\n",
    "# Only for targeting guides\n",
    "def reformat_guide_ids(df):\n",
    "    df = df.copy()\n",
    "    required_cols = [\"intended_target_name\", \"guide_chr\", \"guide_start\", \"guide_end\", \"strand\"]\n",
    "\n",
    "    mask = (\n",
    "        ~df[\"guide_id\"].str.contains(\"non-targeting\", case=False, na=False)\n",
    "        & df[required_cols].notna().all(axis=1)\n",
    "    )\n",
    "\n",
    "    # Build new guide_id strings only for masked rows\n",
    "    df[\"guide_start\"] = df[\"guide_start\"].astype(\"Int64\")\n",
    "    df[\"guide_end\"] = df[\"guide_end\"].astype(\"Int64\")\n",
    "    df.loc[mask, \"guide_id\"] = (\n",
    "        df.loc[mask, \"intended_target_name\"].astype(str)\n",
    "        + \"#\" + df.loc[mask, \"guide_chr\"].astype(str)\n",
    "        + \":\" + df.loc[mask, \"guide_start\"].astype(str)\n",
    "        + \"-\" + df.loc[mask, \"guide_end\"].astype(str)\n",
    "        + \"(\" + df.loc[mask, \"strand\"].astype(str) + \")\"\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "ref_clean_sub_poolabcd = reformat_guide_ids(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = reformat_guide_ids(ref_clean_sub_poolf)\n",
    "\n",
    "print(ref_clean_sub_poolabcd.head())\n",
    "print(ref_clean_sub_poolabcd['label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For positive controls, replace '_' with '#' in guide ID\n",
    "mask = ref_clean_sub_poolabcd[\"label\"] == \"positive_control\"\n",
    "ref_clean_sub_poolabcd.loc[mask, \"guide_id\"] = ref_clean_sub_poolabcd.loc[mask, \"guide_id\"].astype(str).str.replace(\"_\", \"#\", regex=False)\n",
    "\n",
    "mask = ref_clean_sub_poolf[\"label\"] == \"positive_control\"\n",
    "ref_clean_sub_poolf.loc[mask, \"guide_id\"] = ref_clean_sub_poolf.loc[mask, \"guide_id\"].astype(str).str.replace(\"_\", \"#\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       guide_id               spacer  targeting       type guide_chr  \\\n",
      "0     CD81#weak  GAGAGCCAGCGCGCAACGG       True  targeting     chr11   \n",
      "1  CD151#strong  CCGGACTCGGACGCGTGGT       True  targeting     chr11   \n",
      "2    CD151#weak  CCGCTCGGCCGAGCTGTCG       True  targeting     chr11   \n",
      "3   CD55#strong  CTGCGACTCGGCGGAGTCC       True  targeting      chr1   \n",
      "4     NGFRAP1#B  GTTGGAGTTTGCCCTCCTC       True  targeting      chrX   \n",
      "\n",
      "   guide_start    guide_end strand  PAM intended_target_name  \\\n",
      "0    2377315.0    2377333.0      +  NGG      ENSG00000110651   \n",
      "1     833006.0     833024.0      +  NGG      ENSG00000177697   \n",
      "2     833006.0     833024.0      +  NGG      ENSG00000177697   \n",
      "3  207321714.0  207321732.0      +  NGG      ENSG00000196352   \n",
      "4  103376258.0  103376279.0      -  NGG      ENSG00000166681   \n",
      "\n",
      "  intended_target_chr  intended_target_start  intended_target_end gene_name  \\\n",
      "0               chr11              2377315.0            2377333.0      CD81   \n",
      "1               chr11               833006.0             833024.0     CD151   \n",
      "2               chr11               833006.0             833024.0     CD151   \n",
      "3                chr1            207321714.0          207321732.0      CD55   \n",
      "4                chrX            103376258.0          103376279.0   NGFRAP1   \n",
      "\n",
      "              label  \n",
      "0  positive_control  \n",
      "1  positive_control  \n",
      "2  positive_control  \n",
      "3  positive_control  \n",
      "4  positive_control  \n"
     ]
    }
   ],
   "source": [
    "# Supplement with coordinates from benchmarking annotation file for controls missing data\n",
    "benchmark_annot = pd.read_csv(local_path + \"benchmark_guide_metadata_v1 - benchmark_guide_metadata_v1.csv\")\n",
    "print(benchmark_annot.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls missing before: 127\n",
      "Matched rows with benchmark: 294\n",
      "Controls missing after : 127\n"
     ]
    }
   ],
   "source": [
    "def fill_controls_from_benchmark(main_df, benchmark_df):\n",
    "    df = main_df.copy()\n",
    "    bench = benchmark_df.copy()\n",
    "\n",
    "    fill_cols = [\"guide_chr\", \"guide_start\", \"guide_end\", \"strand\", \"intended_target_chr\", \"intended_target_start\", \"intended_target_end\"]\n",
    "\n",
    "    # Standardize spacers\n",
    "    df[\"spacer_norm\"] = df[\"spacer\"].str.strip().str.upper()\n",
    "    bench[\"spacer_norm\"] = bench[\"spacer\"].str.strip().str.upper()\n",
    "\n",
    "    # Merge benchmark data\n",
    "    merged = pd.merge(\n",
    "        df,\n",
    "        bench[[\"spacer_norm\"] + fill_cols],\n",
    "        on=\"spacer_norm\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_bench\"),\n",
    "    )\n",
    "\n",
    "    print(\"Matched rows with benchmark:\", merged[\"guide_chr_bench\"].notna().sum())\n",
    "\n",
    "    # Fill only for controls\n",
    "    is_control = merged[\"label\"].isin([\"positive_control\", \"negative_control\"])\n",
    "\n",
    "    for col in fill_cols:\n",
    "        benchcol = f\"{col}_bench\"\n",
    "        # Only fill where original is NaN and benchmark has a real value\n",
    "        merged.loc[is_control & merged[col].isna() & merged[benchcol].notna(), col] = \\\n",
    "            merged.loc[is_control & merged[col].isna() & merged[benchcol].notna(), benchcol]\n",
    "\n",
    "    # Clean up\n",
    "    merged.drop(columns=[f\"{c}_bench\" for c in fill_cols] + [\"spacer_norm\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return merged\n",
    "\n",
    "controls_with_nans = ref_clean_sub_poolabcd[\n",
    "    ref_clean_sub_poolabcd[\"label\"].isin([\"positive_control\", \"negative_control\"])\n",
    "    & (\n",
    "        ref_clean_sub_poolabcd[\"guide_chr\"].isna()\n",
    "        | ref_clean_sub_poolabcd[\"guide_start\"].isna()\n",
    "        | ref_clean_sub_poolabcd[\"guide_end\"].isna()\n",
    "    )\n",
    "]\n",
    "print(\"Controls missing before:\", controls_with_nans.shape[0])\n",
    "ref_clean_sub_poolabcd = fill_controls_from_benchmark(ref_clean_sub_poolabcd, benchmark_annot)\n",
    "\n",
    "controls_with_nans = ref_clean_sub_poolabcd[\n",
    "    ref_clean_sub_poolabcd[\"label\"].isin([\"positive_control\", \"negative_control\"]) &\n",
    "    (\n",
    "        ref_clean_sub_poolabcd[\"guide_chr\"].isna() |\n",
    "        ref_clean_sub_poolabcd[\"guide_start\"].isna() |\n",
    "        ref_clean_sub_poolabcd[\"guide_end\"].isna()\n",
    "    )\n",
    "]\n",
    "print(\"Controls missing after :\", controls_with_nans.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          guide_id               spacer  targeting  \\\n",
      "0  AARS#chr16:70289419-70289437(-)  CGGCGACCCTAGGAGAGGT       True   \n",
      "1                           AARS#C  CCGCCCTCGGAGAGCTCTG       True   \n",
      "2  AARS#chr16:70289477-70289495(-)  TCTGCGGGAATAGGTGCAG       True   \n",
      "3  AATF#chr17:36948966-36948984(+)  AGTGGCCGGTCCAGAGCTG       True   \n",
      "4  AATF#chr17:36949026-36949044(+)  GGATCAAGGCGAGAGGATC       True   \n",
      "\n",
      "               type guide_chr  guide_start  guide_end strand  pam  \\\n",
      "0  positive control     chr16     70289419   70289437      -  NGG   \n",
      "1  positive control     chrPC            0          0    NaN  NGG   \n",
      "2  positive control     chr16     70289477   70289495      -  NGG   \n",
      "3         targeting     chr17     36948966   36948984      +  NGG   \n",
      "4         targeting     chr17     36949026   36949044      +  NGG   \n",
      "\n",
      "  intended_target_name intended_target_chr  intended_target_start  \\\n",
      "0                 AARS               chr16             70289409.0   \n",
      "1                 AARS               chrPC                    0.0   \n",
      "2                 AARS               chr16             70289409.0   \n",
      "3                 AATF               chr17             36948966.0   \n",
      "4                 AATF               chr17             36948966.0   \n",
      "\n",
      "   intended_target_end             label genomic_element  \n",
      "0           70289495.0  positive_control        promoter  \n",
      "1                  0.0  positive_control        promoter  \n",
      "2           70289495.0  positive_control        promoter  \n",
      "3           36949088.0      tf_targeting        promoter  \n",
      "4           36949088.0      tf_targeting        promoter  \n",
      "(14172, 15)\n",
      "label\n",
      "tf_targeting        12934\n",
      "negative_control      619\n",
      "non_targeting         600\n",
      "positive_control       19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a merged Pool ABCD and Pool F file\n",
    "base = ref_clean_sub_poolabcd.copy()\n",
    "targeting_from_f = ref_clean_sub_poolf[ref_clean_sub_poolf[\"label\"] == \"targeting\"]\n",
    "\n",
    "ref_clean_sub_poolabcdf = pd.concat([base, targeting_from_f], ignore_index=True)\n",
    "ref_clean_sub_poolabcdf = ref_clean_sub_poolabcdf.drop_duplicates(subset=[\"spacer\"], keep=\"first\")\n",
    "\n",
    "print(ref_clean_sub_poolabcdf.head())\n",
    "print(ref_clean_sub_poolabcdf.shape)\n",
    "print(ref_clean_sub_poolabcdf['label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another check for duplicates in the concatenated file\n",
    "duplicate_spacers = ref_clean_sub_poolabcdf[ref_clean_sub_poolabcdf.duplicated(subset=['spacer'])]\n",
    "#print(duplicate_spacers.head())\n",
    "#print(duplicate_spacers.shape)\n",
    "\n",
    "# Find the columns that are different between the duplicate spacers\n",
    "duplicate_spacers_diff = duplicate_spacers.loc[:, duplicate_spacers.nunique() > 1]\n",
    "#print(duplicate_spacers_diff.head())\n",
    "#print(duplicate_spacers_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "tf_targeting        12934\n",
      "negative_control      619\n",
      "non_targeting         600\n",
      "positive_control       19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fix any Excel-style gene names converted to dates\n",
    "import re\n",
    "month_gene_map = {\n",
    "    \"JAN\": \"JAN\", \"FEB\": \"FEB\", \"MAR\": \"MARCH\", \"APR\": \"APR\",\n",
    "    \"MAY\": \"MAY\", \"JUN\": \"JUN\", \"JUL\": \"JUL\", \"AUG\": \"AUG\",\n",
    "    \"SEP\": \"SEPT\", \"OCT\": \"OCT\", \"NOV\": \"NOV\", \"DEC\": \"DEC\"\n",
    "}\n",
    "\n",
    "def fix_excel_date_genes(symbol):\n",
    "    if not isinstance(symbol, str):\n",
    "        return symbol  # leave NaN or other types alone\n",
    "\n",
    "    m = re.match(r\"^(\\d{1,2})-([A-Za-z]{3})$\", symbol.strip())\n",
    "    if m:\n",
    "        num, month = m.groups()\n",
    "        month = month.upper()\n",
    "        if month in month_gene_map:\n",
    "            return f\"{month_gene_map[month]}{num}\"\n",
    "    return symbol\n",
    "\n",
    "ref_clean_sub_poolabcdf['intended_target_name'] = ref_clean_sub_poolabcdf['intended_target_name'].apply(fix_excel_date_genes)\n",
    "ref_clean_sub_poolabcd['intended_target_name'] = ref_clean_sub_poolabcd['intended_target_name'].apply(fix_excel_date_genes)\n",
    "ref_clean_sub_poolf['intended_target_name'] = ref_clean_sub_poolf['intended_target_name'].apply(fix_excel_date_genes)\n",
    "\n",
    "print(ref_clean_sub_poolabcd['label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix one-off instances of strange behavior\n",
    "\n",
    "# Fix TBXT, which is mistakenly just 'T' in this data\n",
    "def replace_T_with_TBXT(df):\n",
    "    df = df.copy()\n",
    "    df[\"guide_id\"] = df[\"guide_id\"].str.replace(\n",
    "        r\"^T#\", \"TBXT#\", regex=True\n",
    "    )\n",
    "    return df\n",
    "\n",
    "ref_clean_sub_poolabcdf = replace_T_with_TBXT(ref_clean_sub_poolabcdf)\n",
    "ref_clean_sub_poolabcd = replace_T_with_TBXT(ref_clean_sub_poolabcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "tf_targeting        12934\n",
      "negative_control      619\n",
      "non_targeting         600\n",
      "positive_control       19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sort to put controls at the top of the file\n",
    "control_order = [\"positive_control\", \"negative_control\", \"non_targeting\"]\n",
    "ref_clean_sub_poolabcdf[\"label\"] = pd.Categorical(ref_clean_sub_poolabcdf[\"label\"], categories=control_order + [\"tf_targeting\"], ordered=True)\n",
    "ref_clean_sub_poolabcd[\"label\"] = pd.Categorical(ref_clean_sub_poolabcd[\"label\"], categories=control_order + [\"tf_targeting\"], ordered=True)\n",
    "ref_clean_sub_poolf[\"label\"] = pd.Categorical(ref_clean_sub_poolf[\"label\"], categories=control_order + [\"tf_targeting\"], ordered=True)\n",
    "\n",
    "ref_clean_sub_poolabcdf = ref_clean_sub_poolabcdf.sort_values(by=[\"label\", \"guide_id\"], ascending=[True, True]).reset_index(drop=True)\n",
    "ref_clean_sub_poolabcd = ref_clean_sub_poolabcd.sort_values(by=[\"label\", \"guide_id\"], ascending=[True, True]).reset_index(drop=True)\n",
    "ref_clean_sub_poolf = ref_clean_sub_poolf.sort_values(by=[\"label\", \"guide_id\"], ascending=[True, True]).reset_index(drop=True)\n",
    "print(ref_clean_sub_poolabcd['label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['guide_id', 'spacer', 'targeting', 'type', 'guide_chr', 'guide_start',\n",
      "       'guide_end', 'strand', 'pam', 'intended_target_name',\n",
      "       'intended_target_chr', 'intended_target_start', 'intended_target_end',\n",
      "       'label', 'genomic_element', 'putative_target_genes', 'reporter',\n",
      "       'imperfect'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Add empty columns for putative_target_genes, reporter, and imperfect\n",
    "def add_placeholder_cols(ref_clean_sub):\n",
    "    ref_clean_sub['putative_target_genes'] = np.nan\n",
    "    ref_clean_sub['reporter'] = np.nan\n",
    "    ref_clean_sub['imperfect'] = np.nan\n",
    "    return ref_clean_sub\n",
    "\n",
    "ref_clean_sub_poolabcdf = add_placeholder_cols(ref_clean_sub_poolabcdf)\n",
    "ref_clean_sub_poolabcd = add_placeholder_cols(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = add_placeholder_cols(ref_clean_sub_poolf)\n",
    "print(ref_clean_sub_poolabcdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "ref_clean_sub_poolabcd.to_csv(local_path + \"harmonized_guide_file_poolabcd.csv\", index=False)\n",
    "ref_clean_sub_poolabcd.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcd.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")\n",
    "ref_clean_sub_poolf.to_csv(local_path + \"harmonized_guide_file_poolf.csv\", index=False)\n",
    "ref_clean_sub_poolf.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolf.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_clean_sub_poolabcdf.to_csv(local_path + \"harmonized_guide_file_poolabcdf.csv\", index=False)\n",
    "\n",
    "# Write to tsv file, including header\n",
    "ref_clean_sub_poolabcdf.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcdf.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pybiomart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intended_target_name</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>external_synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>MTTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>TRNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>12S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MOTS-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MTRNR1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intended_target_name  ensembl_gene_id external_synonym\n",
       "0                MT-TF  ENSG00000210049             MTTF\n",
       "1                MT-TF  ENSG00000210049             TRNF\n",
       "2              MT-RNR1  ENSG00000211459              12S\n",
       "3              MT-RNR1  ENSG00000211459           MOTS-C\n",
       "4              MT-RNR1  ENSG00000211459           MTRNR1"
      ]
     },
     "execution_count": 1316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert intended_target_name to Ensembl ID using pyBiomart\n",
    "from pybiomart import Dataset\n",
    "\n",
    "dataset = Dataset(name='hsapiens_gene_ensembl', host='http://www.ensembl.org')\n",
    "\n",
    "# Fetch mapping\n",
    "mapping = dataset.query(attributes=['hgnc_symbol', 'ensembl_gene_id', 'external_synonym'])\n",
    "mapping.columns = ['intended_target_name', 'ensembl_gene_id', 'external_synonym']\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intended_target_name</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>external_synonym</th>\n",
       "      <th>synonym_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>MTTF</td>\n",
       "      <td>MTTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>TRNF</td>\n",
       "      <td>TRNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>12S</td>\n",
       "      <td>12S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MOTS-C</td>\n",
       "      <td>MOTS-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MTRNR1</td>\n",
       "      <td>MTRNR1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intended_target_name  ensembl_gene_id external_synonym synonym_list\n",
       "0                MT-TF  ENSG00000210049             MTTF         MTTF\n",
       "1                MT-TF  ENSG00000210049             TRNF         TRNF\n",
       "2              MT-RNR1  ENSG00000211459              12S          12S\n",
       "3              MT-RNR1  ENSG00000211459           MOTS-C       MOTS-C\n",
       "4              MT-RNR1  ENSG00000211459           MTRNR1       MTRNR1"
      ]
     },
     "execution_count": 1317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine HGNC symbol and synonyms into a single mapping dataframe\n",
    "# Melt external_synonym if it's a comma-separated list\n",
    "mapping_expanded = mapping.copy()\n",
    "mapping_expanded['external_synonym'] = mapping_expanded['external_synonym'].fillna('')\n",
    "mapping_expanded = mapping_expanded.assign(\n",
    "    synonym_list=mapping_expanded['external_synonym'].str.split(',')\n",
    ").explode('synonym_list')\n",
    "mapping_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symbol  ensembl_gene_id\n",
      "0     MTTF  ENSG00000210049\n",
      "2   MTRNR1  ENSG00000211459\n",
      "5     MTTV  ENSG00000210077\n",
      "7   MTRNR2  ENSG00000210082\n",
      "10   MTTL1  ENSG00000209082\n"
     ]
    }
   ],
   "source": [
    "# Combine intended_target_name and synonym_list into one lookup table\n",
    "lookup_biomart = pd.concat([\n",
    "    mapping_expanded[['intended_target_name', 'ensembl_gene_id']].rename(columns={'intended_target_name': 'symbol'}),\n",
    "    mapping_expanded[['synonym_list', 'ensembl_gene_id']].rename(columns={'synonym_list': 'symbol'})\n",
    "]).drop_duplicates()\n",
    "#print(lookup.head())\n",
    "lookup_biomart['symbol'] = lookup_biomart['symbol'].apply(lambda x: str(x).upper().replace('-', '').replace('_',''))\n",
    "lookup_biomart = lookup_biomart.drop_duplicates(subset=[\"symbol\"], keep=\"first\")\n",
    "print(lookup_biomart.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_symbol(s):\n",
    "    s = str(s).upper()\n",
    "    # Remove dashes for relaxed matching\n",
    "    s = s.replace('-', '').replace('_', '')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with data frame and replace intended_target_name with Ensembl IDs\n",
    "def replace_w_ensembl(ref_clean, mapping):\n",
    "    # Make all symbols uppercase for matching\n",
    "    ref_clean = ref_clean.copy()\n",
    "    ref_clean['intended_target_name'] = ref_clean['intended_target_name'].apply(clean_symbol)\n",
    "\n",
    "    mapping = mapping.copy()\n",
    "    mapping['symbol'] = mapping['symbol'].apply(clean_symbol)\n",
    "\n",
    "    # Merge by symbol\n",
    "    ref_clean = ref_clean.merge(mapping, left_on='intended_target_name',\n",
    "                                right_on='symbol', how='left')\n",
    "\n",
    "    # Identify missing mappings\n",
    "    missing_mask = ref_clean['ensembl_gene_id'].isna()\n",
    "    num_missing = missing_mask.sum()\n",
    "    missing_genes = ref_clean.loc[missing_mask, 'intended_target_name'].unique()\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Number of rows with missing Ensembl mapping: {num_missing}\")\n",
    "    print(f\"Gene symbols with no mapping:\\n{missing_genes}\")\n",
    "\n",
    "    mapped = ref_clean['ensembl_gene_id'].notna()\n",
    "    gtf_mapped = (mapped & (ref_clean['source'] == 'gtf')).sum()\n",
    "    biomart_mapped = (mapped & (ref_clean['source'] == 'biomart')).sum()\n",
    "    unmapped = (~mapped).sum()\n",
    "    print(f\"Mapped via GTF: {gtf_mapped}\")\n",
    "    print(f\"Mapped via Biomart only: {biomart_mapped}\")\n",
    "    print(f\"Unmapped: {unmapped}\")\n",
    "\n",
    "    # Keep original gene name in a new column\n",
    "    ref_clean['gene_name'] = ref_clean['intended_target_name']\n",
    "\n",
    "    # Replace intended_target_name with Ensembl ID where available,\n",
    "    # otherwise keep the original gene name\n",
    "    ref_clean['intended_target_name'] = ref_clean.apply(\n",
    "        lambda row: row['ensembl_gene_id'] if pd.notna(row['ensembl_gene_id']) \n",
    "                    else row['intended_target_name'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Identify duplicates of ENSG IDs\n",
    "    grouped = ref_clean.groupby('intended_target_name')['gene_name'].nunique()\n",
    "    duplicate_ensg_distinct = grouped[grouped > 1].index\n",
    "    \n",
    "    # Append gene name only for ENSG IDs with distinct gene names\n",
    "    mask = ref_clean['intended_target_name'].isin(duplicate_ensg_distinct) & pd.notna(ref_clean['intended_target_name'])\n",
    "    ref_clean.loc[mask, 'intended_target_name'] = ref_clean.loc[mask].apply(\n",
    "        lambda row: f\"{row['intended_target_name']}#{row['gene_name']}\", axis=1\n",
    "    )\n",
    "\n",
    "    # Drop temp columns if you don’t need them later\n",
    "    ref_clean.drop(columns=['ensembl_gene_id', 'symbol'], inplace=True, errors='ignore')\n",
    "\n",
    "    desired_order = [\n",
    "        'guide_id','spacer','targeting','type','guide_chr','guide_start','guide_end','strand','pam',\n",
    "        'genomic_element','intended_target_name','intended_target_chr','intended_target_start',\n",
    "        'intended_target_end','putative_target_genes','reporter','imperfect','gene_name','label'\n",
    "    ]\n",
    "    existing_order = [c for c in desired_order if c in ref_clean.columns]\n",
    "    ref_clean = ref_clean[existing_order]\n",
    "\n",
    "    return ref_clean\n",
    "\n",
    "#ref_clean_sub_poolabcdf_ensembl = replace_w_ensembl(ref_clean_sub_poolabcdf, lookup_biomart)\n",
    "#ref_clean_sub_poolabcd_ensembl = replace_w_ensembl(ref_clean_sub_poolabcd, lookup_biomart)\n",
    "#ref_clean_sub_poolf_ensembl = replace_w_ensembl(ref_clean_sub_poolf, lookup_biomart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqname</th>\n",
       "      <th>source</th>\n",
       "      <th>feature</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>frame</th>\n",
       "      <th>attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>gene</td>\n",
       "      <td>11869</td>\n",
       "      <td>14409</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000290825.1\"; gene_type \"lncRNA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>transcript</td>\n",
       "      <td>11869</td>\n",
       "      <td>14409</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000290825.1\"; transcript_id \"EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>11869</td>\n",
       "      <td>12227</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000290825.1\"; transcript_id \"EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>12613</td>\n",
       "      <td>12721</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000290825.1\"; transcript_id \"EN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>exon</td>\n",
       "      <td>13221</td>\n",
       "      <td>14409</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000290825.1\"; transcript_id \"EN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seqname  source     feature  start    end score strand frame  \\\n",
       "0    chr1  HAVANA        gene  11869  14409     .      +     .   \n",
       "1    chr1  HAVANA  transcript  11869  14409     .      +     .   \n",
       "2    chr1  HAVANA        exon  11869  12227     .      +     .   \n",
       "3    chr1  HAVANA        exon  12613  12721     .      +     .   \n",
       "4    chr1  HAVANA        exon  13221  14409     .      +     .   \n",
       "\n",
       "                                           attribute  \n",
       "0  gene_id \"ENSG00000290825.1\"; gene_type \"lncRNA...  \n",
       "1  gene_id \"ENSG00000290825.1\"; transcript_id \"EN...  \n",
       "2  gene_id \"ENSG00000290825.1\"; transcript_id \"EN...  \n",
       "3  gene_id \"ENSG00000290825.1\"; transcript_id \"EN...  \n",
       "4  gene_id \"ENSG00000290825.1\"; transcript_id \"EN...  "
      ]
     },
     "execution_count": 1321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, derive ENSG IDs from IGVF GTF file\n",
    "gtf_cols = [\n",
    "    \"seqname\", \"source\", \"feature\", \"start\", \"end\",\n",
    "    \"score\", \"strand\", \"frame\", \"attribute\"\n",
    "]\n",
    "\n",
    "gtf = pd.read_csv(\n",
    "    local_path + \"gencode.v43.chr_patch_hapl_scaff.annotation.gtf\",\n",
    "    sep=\"\\t\",\n",
    "    comment=\"#\",\n",
    "    names=gtf_cols,\n",
    "    dtype={\"seqname\": str}\n",
    ")\n",
    "gtf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqname</th>\n",
       "      <th>source</th>\n",
       "      <th>feature</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>frame</th>\n",
       "      <th>attribute</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>intended_target_name</th>\n",
       "      <th>external_synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>gene</td>\n",
       "      <td>11869</td>\n",
       "      <td>14409</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000290825.1\"; gene_type \"lncRNA...</td>\n",
       "      <td>ENSG00000290825</td>\n",
       "      <td>DDX11L2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>gene</td>\n",
       "      <td>12010</td>\n",
       "      <td>13670</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000223972.6\"; gene_type \"transc...</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>gene</td>\n",
       "      <td>14404</td>\n",
       "      <td>29570</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000227232.5\"; gene_type \"unproc...</td>\n",
       "      <td>ENSG00000227232</td>\n",
       "      <td>WASH7P</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>chr1</td>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>gene</td>\n",
       "      <td>17369</td>\n",
       "      <td>17436</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000278267.1\"; gene_type \"miRNA\"...</td>\n",
       "      <td>ENSG00000278267</td>\n",
       "      <td>MIR6859-1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>chr1</td>\n",
       "      <td>HAVANA</td>\n",
       "      <td>gene</td>\n",
       "      <td>29554</td>\n",
       "      <td>31109</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>gene_id \"ENSG00000243485.5\"; gene_type \"lncRNA...</td>\n",
       "      <td>ENSG00000243485</td>\n",
       "      <td>MIR1302-2HG</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seqname   source feature  start    end score strand frame  \\\n",
       "0     chr1   HAVANA    gene  11869  14409     .      +     .   \n",
       "5     chr1   HAVANA    gene  12010  13670     .      +     .   \n",
       "13    chr1   HAVANA    gene  14404  29570     .      -     .   \n",
       "26    chr1  ENSEMBL    gene  17369  17436     .      -     .   \n",
       "29    chr1   HAVANA    gene  29554  31109     .      +     .   \n",
       "\n",
       "                                            attribute  ensembl_gene_id  \\\n",
       "0   gene_id \"ENSG00000290825.1\"; gene_type \"lncRNA...  ENSG00000290825   \n",
       "5   gene_id \"ENSG00000223972.6\"; gene_type \"transc...  ENSG00000223972   \n",
       "13  gene_id \"ENSG00000227232.5\"; gene_type \"unproc...  ENSG00000227232   \n",
       "26  gene_id \"ENSG00000278267.1\"; gene_type \"miRNA\"...  ENSG00000278267   \n",
       "29  gene_id \"ENSG00000243485.5\"; gene_type \"lncRNA...  ENSG00000243485   \n",
       "\n",
       "   intended_target_name external_synonym  \n",
       "0               DDX11L2             None  \n",
       "5               DDX11L1             None  \n",
       "13               WASH7P             None  \n",
       "26            MIR6859-1             None  \n",
       "29          MIR1302-2HG             None  "
      ]
     },
     "execution_count": 1322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes = gtf[gtf[\"feature\"] == \"gene\"].copy()\n",
    "\n",
    "def extract_attr(attr, key):\n",
    "    match = re.search(fr'{key} \"([^\"]+)\"', attr)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "genes[\"ensembl_gene_id\"] = genes[\"attribute\"].apply(\n",
    "    lambda x: extract_attr(x, \"gene_id\")\n",
    ")\n",
    "genes[\"intended_target_name\"] = genes[\"attribute\"].apply(\n",
    "    lambda x: extract_attr(x, \"gene_name\")\n",
    ")\n",
    "\n",
    "genes[\"external_synonym\"] = genes[\"attribute\"].apply(\n",
    "    lambda x: extract_attr(x, \"gene_synonym\")\n",
    ")\n",
    "\n",
    "# Strip version numbers from ENSG IDs\n",
    "genes[\"ensembl_gene_id\"] = genes[\"ensembl_gene_id\"].str.split(\".\").str[0]\n",
    "genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDX11L2</td>\n",
       "      <td>ENSG00000290825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DDX11L1</td>\n",
       "      <td>ENSG00000223972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WASH7P</td>\n",
       "      <td>ENSG00000227232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MIR68591</td>\n",
       "      <td>ENSG00000278267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MIR13022HG</td>\n",
       "      <td>ENSG00000243485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        symbol  ensembl_gene_id\n",
       "0      DDX11L2  ENSG00000290825\n",
       "5      DDX11L1  ENSG00000223972\n",
       "13      WASH7P  ENSG00000227232\n",
       "26    MIR68591  ENSG00000278267\n",
       "29  MIR13022HG  ENSG00000243485"
      ]
     },
     "execution_count": 1323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build GTF-based lookup table\n",
    "mapping = genes[[\"intended_target_name\", \"ensembl_gene_id\", \"external_synonym\"]]\n",
    "mapping_expanded = mapping.copy()\n",
    "mapping_expanded[\"external_synonym\"] = mapping_expanded[\"external_synonym\"].fillna(\"\")\n",
    "mapping_expanded = mapping_expanded.assign(\n",
    "    synonym_list=mapping_expanded[\"external_synonym\"].str.split(\",\")\n",
    ").explode(\"synonym_list\")\n",
    "lookup = pd.concat([\n",
    "    mapping_expanded[[\"intended_target_name\", \"ensembl_gene_id\"]]\n",
    "        .rename(columns={\"intended_target_name\": \"symbol\"}),\n",
    "    mapping_expanded[[\"synonym_list\", \"ensembl_gene_id\"]]\n",
    "        .rename(columns={\"synonym_list\": \"symbol\"})\n",
    "]).drop_duplicates()\n",
    "lookup[\"symbol\"] = (\n",
    "    lookup[\"symbol\"]\n",
    "    .astype(str)\n",
    "    .str.upper()\n",
    "    .str.replace(\"-\", \"\", regex=False)\n",
    "    .str.replace(\"_\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "lookup = lookup.drop_duplicates(subset=[\"symbol\"], keep=\"first\")\n",
    "lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total symbols (GTF): 62797\n",
      "Added from Biomart: 53895\n"
     ]
    }
   ],
   "source": [
    "# Add ENSG IDs for missing genes from Biomart\n",
    "def supplement_lookup(lookup_gtf, lookup_biomart):\n",
    "    lookup_gtf = lookup_gtf.copy()\n",
    "    lookup_biomart = lookup_biomart.copy()\n",
    "    \n",
    "    lookup_gtf[\"source\"] = \"gtf\"\n",
    "    lookup_biomart[\"source\"] = \"biomart\"\n",
    "    \n",
    "    # Identify symbols missing from GTF\n",
    "    missing_symbols = (set(lookup_biomart[\"symbol\"]) - set(lookup_gtf[\"symbol\"]))\n",
    "    biomart_missing = lookup_biomart[lookup_biomart[\"symbol\"].isin(missing_symbols)]\n",
    "    print(f\"Added from Biomart: {biomart_missing.shape[0]}\")\n",
    "    \n",
    "    # Combine, prioritizing GTF\n",
    "    combined = pd.concat([lookup_gtf, biomart_missing], ignore_index=True)\n",
    "    \n",
    "    # Final safety de-duplication\n",
    "    combined = combined.drop_duplicates(subset=[\"symbol\"], keep=\"first\")\n",
    "    \n",
    "    return combined\n",
    "\n",
    "print(f\"Total symbols (GTF): {lookup.shape[0]}\")\n",
    "lookup_full = supplement_lookup(lookup, lookup_biomart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing Ensembl mapping: 600\n",
      "Gene symbols with no mapping:\n",
      "['NONTARGETING']\n",
      "Mapped via GTF: 13335\n",
      "Mapped via Biomart only: 237\n",
      "Unmapped: 600\n",
      "Number of rows with missing Ensembl mapping: 600\n",
      "Gene symbols with no mapping:\n",
      "['NONTARGETING']\n",
      "Mapped via GTF: 13335\n",
      "Mapped via Biomart only: 237\n",
      "Unmapped: 600\n",
      "Number of rows with missing Ensembl mapping: 706\n",
      "Gene symbols with no mapping:\n",
      "['NONTARGETING' 'CTD2515O10' 'CTD2574D22' 'GREGOR' 'LOC100101148'\n",
      " 'LOC100133091' 'LOC101926943' 'LOC284865' 'LOC388849' 'LOC541473'\n",
      " 'SEPT5GP1BB' 'XXBACB562F10']\n",
      "Mapped via GTF: 2990\n",
      "Mapped via Biomart only: 134\n",
      "Unmapped: 706\n"
     ]
    }
   ],
   "source": [
    "# Call Ensembl replacement function with new GTF-based lookup table\n",
    "ref_clean_sub_poolabcdf_ensembl = replace_w_ensembl(ref_clean_sub_poolabcdf, lookup_full)\n",
    "ref_clean_sub_poolabcd_ensembl = replace_w_ensembl(ref_clean_sub_poolabcd, lookup_full)\n",
    "ref_clean_sub_poolf_ensembl = replace_w_ensembl(ref_clean_sub_poolf, lookup_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "ref_clean_sub_poolabcd_ensembl.to_csv(local_path + \"harmonized_guide_file_poolabcd_ensg.csv\", index=False)\n",
    "ref_clean_sub_poolabcd_ensembl.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcd_ensg.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")\n",
    "ref_clean_sub_poolf_ensembl.to_csv(local_path + \"harmonized_guide_file_poolf_ensg.csv\", index=False)\n",
    "ref_clean_sub_poolf_ensembl.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolf_ensg.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")\n",
    "ref_clean_sub_poolabcdf_ensembl.to_csv(local_path + \"harmonized_guide_file_poolabcdf_ensg.csv\", index=False)\n",
    "\n",
    "# Write to tsv file, including header\n",
    "ref_clean_sub_poolabcdf_ensembl.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcdf_ensg.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running integrity checks for ABCD\n",
      "Note: 6 rows in guide_chr are labeled 'chrPC' (placeholder coordinates).\n",
      "Note: 6 rows in intended_target_chr are labeled 'chrPC' (placeholder coordinates).\n",
      "All checks passed for ABCD\n",
      "\n",
      "Running integrity checks for F\n",
      "Note: 6 rows in guide_chr are labeled 'chrPC' (placeholder coordinates).\n",
      "Note: 6 rows in intended_target_chr are labeled 'chrPC' (placeholder coordinates).\n",
      "All checks passed for F\n",
      "\n",
      "Running integrity checks for ABCDF\n",
      "Note: 6 rows in guide_chr are labeled 'chrPC' (placeholder coordinates).\n",
      "Note: 6 rows in intended_target_chr are labeled 'chrPC' (placeholder coordinates).\n",
      "All checks passed for ABCDF\n"
     ]
    }
   ],
   "source": [
    "# Quick unit tests to make sure everything is kosher\n",
    "def run_integrity_checks(df, pool_label=\"\"):\n",
    "    print(f\"\\nRunning integrity checks for {pool_label}\")\n",
    "\n",
    "    # Check for duplicate spacers\n",
    "    duplicates = df[df[\"spacer\"].duplicated()]\n",
    "    assert len(duplicates) == 0, f\"{len(duplicates)} duplicate spacers found in {pool_label}\"\n",
    "\n",
    "    # Check NA values are np.nan (not 'NA', 'None', or empty strings)\n",
    "    bad_na = df.isin([\"NA\", \"None\", \"\"]).any().sum()\n",
    "    assert bad_na == 0, f\"{bad_na} non-numeric NA placeholders found in {pool_label}\"\n",
    "\n",
    "    # Check for strange characters in spacer or guide_id\n",
    "    pattern_ok = re.compile(r\"^[ACGTN]+$\", re.IGNORECASE)\n",
    "    bad_spacers = df[~df[\"spacer\"].astype(str).str.match(pattern_ok)]\n",
    "    assert len(bad_spacers) == 0, f\"Unexpected characters in {len(bad_spacers)} spacers\"\n",
    "\n",
    "    # Confirm control guides are present\n",
    "    control_types = [\"non_targeting\", \"positive_control\", \"negative_control\"]\n",
    "    found_controls = {ct: (df[\"label\"].str.lower() == ct).sum() for ct in control_types}\n",
    "    missing_controls = [ct for ct, count in found_controls.items() if count == 0]\n",
    "    assert not missing_controls, f\"Missing control types: {missing_controls}\"\n",
    "\n",
    "    # Confirm coordinate columns are numeric or np.nan\n",
    "    coord_cols = [\"guide_start\", \"guide_end\", \"intended_target_start\", \"intended_target_end\"]\n",
    "    for col in coord_cols:\n",
    "        if col in df.columns:\n",
    "            bad_coords = df[col].dropna().apply(lambda x: isinstance(x, (int, float)))\n",
    "            assert bad_coords.all(), f\"Non-numeric entries in {col}\"\n",
    "\n",
    "    # Confirm chromosome format (allow chr1–22, chrX/Y, and *_random)\n",
    "    chr_cols = [\"guide_chr\", \"intended_target_chr\"]\n",
    "    chr_pattern = re.compile(r\"^chr(\\d+|X|Y)(_.*_random)?$\", re.IGNORECASE)\n",
    "    for col in chr_cols:\n",
    "        if col in df.columns:\n",
    "            # Convert all entries to string once\n",
    "            chr_values = df[col].astype(str)\n",
    "    \n",
    "            # Pick out the 'chrPC' rows\n",
    "            pc_mask = chr_values.str.upper() == \"CHRPC\"\n",
    "            if pc_mask.any():\n",
    "                print(f\"Note: {pc_mask.sum()} rows in {col} are labeled 'chrPC' (placeholder coordinates).\")\n",
    "    \n",
    "            # Normal validity check, ignoring NaNs and chrPC\n",
    "            bad_mask = (\n",
    "                df[col].notna()\n",
    "                & ~pc_mask\n",
    "                & ~chr_values.str.match(chr_pattern)\n",
    "            )\n",
    "    \n",
    "            if bad_mask.any():\n",
    "                print(f\"\\nInvalid chromosome values found in {col} for {pool_label}:\")\n",
    "                print(df.loc[bad_mask, [col, \"guide_id\"]].head(10))\n",
    "                print(df.loc[bad_mask, col].value_counts().head(20))\n",
    "    \n",
    "            assert not bad_mask.any(), f\"Invalid chromosome names in {col}\"\n",
    "\n",
    "    print(f\"All checks passed for {pool_label}\")\n",
    "\n",
    "run_integrity_checks(ref_clean_sub_poolabcd_ensembl, \"ABCD\")\n",
    "run_integrity_checks(ref_clean_sub_poolf_ensembl, \"F\")\n",
    "run_integrity_checks(ref_clean_sub_poolabcdf_ensembl, \"ABCDF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
