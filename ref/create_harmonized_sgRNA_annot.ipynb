{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create harmonized sgRNA guide annotation file for use with the CRISPR pipeline (2025)\n",
    "This notebook describes the creation of a unified annotation file from the guide annotation files provided by the Hon, Huangfu, and Gersbach labs, according to the specification described in: https://github.com/pinellolab/CRISPR_Pipeline/blob/main/example_data/guide_metadata.tsv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install libraries and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "#%pip install matplotlib\n",
    "#%pip install numpy\n",
    "#%pip install seaborn\n",
    "#%pip install biomart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths: TODO update if necessary\n",
    "#local_path = \"/cellar/users/aklie/data/datasets/tf_perturb_seq/ref/\"\n",
    "#local_path = \"C:/Users/seg95/Documents/tf_perturb_seq/\"\n",
    "local_path = \"/hpc/group/gersbachlab/seg95/tf_perturb_seq/ref/\"\n",
    "#local_path = \"D:/tf_perturb_seq/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import merged guide reference file, along with guide index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         id_hon           protospacer       type  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1  GCACAGGACGGCCGAGCTGA  targeting   \n",
      "1     EN2_-_155251011.23-P1P2-1  GCTCCGTGTGCGCCGCGGGA  targeting   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2  GCTCCGTTGCAACCACACAG  targeting   \n",
      "3      KLF6_-_3827130.23-P1P2-2  GCTGGAGGATCGATCGGCGG  targeting   \n",
      "4     ELF1_+_41593362.23-P1P2-2  GTGAGCTGATAAACAGAGGG  targeting   \n",
      "\n",
      "  intended_target_name_hon    reverse_compliment genomic_element  \\\n",
      "0                    FOXN1  TCAGCTCGGCCGTCCTGTGC        promoter   \n",
      "1                      EN2  TCCCGCGGCGCACACGGAGC        promoter   \n",
      "2                   BCLAF1  CTGTGTGGTTGCAACGGAGC        promoter   \n",
      "3                     KLF6  CCGCCGATCGATCCTCCAGC        promoter   \n",
      "4                     ELF1  CCCTCTGTTTATCAGCTCAC        promoter   \n",
      "\n",
      "                    id_gersbach intended_target_name_gersbach id_huangfu  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1                         FOXN1    FOXN1_1   \n",
      "1     EN2_-_155251011.23-P1P2-1                           EN2      EN2_5   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2                        BCLAF1   BCLAF1_6   \n",
      "3      KLF6_-_3827130.23-P1P2-2                          KLF6     KLF6_2   \n",
      "4     ELF1_+_41593362.23-P1P2-2                          ELF1     ELF1_6   \n",
      "\n",
      "  intended_target_name_huangfu   id_engreitz intended_target_name_engreitz  \n",
      "0                        FOXN1     FOXN1_765                         FOXN1  \n",
      "1                          EN2      EN2_9056                           EN2  \n",
      "2                       BCLAF1  BCLAF1_11125                        BCLAF1  \n",
      "3                         KLF6     KLF6_1362                          KLF6  \n",
      "4                         ELF1    ELF1_11255                          ELF1  \n"
     ]
    }
   ],
   "source": [
    "# Merged guide ref file\n",
    "merged_guide_file = pd.read_csv(local_path + \"outer_merged_file.csv\")\n",
    "print(merged_guide_file.head())\n",
    "\n",
    "merged_guide_file_poolabcd = pd.read_csv(local_path + \"outer_merged_file_poolabcd.csv\")\n",
    "merged_guide_file_poolf = pd.read_csv(local_path + \"outer_merged_file_poolf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13188\n"
     ]
    }
   ],
   "source": [
    "# sgRNA index files\n",
    "sgrna_index_poolabcd = pd.read_csv(local_path + \"sgRNA_index_v0.csv\", sep = \"\\t\")\n",
    "sgrna_index_poolf = pd.read_csv(local_path + \"igvf_poolF_annotation.csv\", sep = \"\\t\")\n",
    "\n",
    "sgrna_index_dacc_annot = pd.read_csv(local_path + \"sgRNA_index_dacc_annot_reference.csv\", sep = \"\\t\")\n",
    "print(len(set(sgrna_index_dacc_annot['protospacer']).intersection(set(merged_guide_file_poolabcd['protospacer']))))\n",
    "\n",
    "def adjust_index_file(sgrna_index, name_sgrna_seq = 'sgRNA_seq', add_leading_G = True):\n",
    "    if(name_sgrna_seq == \"sgRNA_seq\"):\n",
    "        sgrna_index['strand'] = sgrna_index['target_loc'].str.extract(r'\\((\\+|\\-)\\)')\n",
    "        sgrna_index['oligo'] = sgrna_index['oligo'].str.upper()\n",
    "    else:\n",
    "        sgrna_index['oligo_sequence'] = sgrna_index['oligo_sequence'].str.upper()\n",
    "    sgrna_index[name_sgrna_seq] = sgrna_index[name_sgrna_seq].str.upper()\n",
    "    # Adjust the index file to add leading Gs if needed\n",
    "    if(add_leading_G):\n",
    "        sgrna_index[name_sgrna_seq] = 'G' + sgrna_index[name_sgrna_seq]\n",
    "    return sgrna_index\n",
    "\n",
    "sgrna_index_poolabcd = adjust_index_file(sgrna_index_poolabcd)\n",
    "sgrna_index_poolf = adjust_index_file(sgrna_index_poolf, name_sgrna_seq= 'protospacer', add_leading_G = False)\n",
    "\n",
    "sgrna_index_dacc_annot['protospacer'] = sgrna_index_dacc_annot['protospacer'].str.upper()\n",
    "sgrna_index_poolf['protospacer'] = sgrna_index_poolf['protospacer'].str.upper()\n",
    "#sgrna_index_dacc_annot['protospacer'] = [s[1:] if len(s) > 0 else s for s in sgrna_index_dacc_annot['protospacer']]\n",
    "#sgrna_index_dacc_annot['reverse_compliment'] = sgrna_index_dacc_annot['reverse_compliment'].str.rstrip('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:\n",
      "                   target_loc              element_seq     target source  \\\n",
      "0  chr17:36948966-36948984(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "1  chr17:36949026-36949044(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "2  chr17:36949013-36949031(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "3  chr17:36949070-36949088(-)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "4  chr17:36949031-36949049(+)  chr17:36948966-36949088  AATF_P1P2     TF   \n",
      "\n",
      "              sgRNA_seq                                              oligo  \\\n",
      "0  GAGTGGCCGGTCCAGAGCTG  GTGGAAAGGACGAAACACCGAGTGGCCGGTCCAGAGCTGGTTTAAG...   \n",
      "1  GGGATCAAGGCGAGAGGATC  GTGGAAAGGACGAAACACCGGGATCAAGGCGAGAGGATCGTTTAAG...   \n",
      "2  GGAGTCGGGGAATCGGATCA  GTGGAAAGGACGAAACACCGGAGTCGGGGAATCGGATCAGTTTAAG...   \n",
      "3  GAAATGTGCGGCCCAACCCC  GTGGAAAGGACGAAACACCGAAATGTGCGGCCCAACCCCGTTTAAG...   \n",
      "4  GAAGGCGAGAGGATCCGGCA  GTGGAAAGGACGAAACACCGAAGGCGAGAGGATCCGGCAGTTTAAG...   \n",
      "\n",
      "  gene_target chr_target  chr_start_target  chr_end_target chr_element  \\\n",
      "0        AATF      chr17          36948966        36948984       chr17   \n",
      "1        AATF      chr17          36949026        36949044       chr17   \n",
      "2        AATF      chr17          36949013        36949031       chr17   \n",
      "3        AATF      chr17          36949070        36949088       chr17   \n",
      "4        AATF      chr17          36949031        36949049       chr17   \n",
      "\n",
      "   chr_start_element  chr_end_element strand    reverse_compliment  \n",
      "0           36948966         36949088      +  CAGCTCTGGACCGGCCACTC  \n",
      "1           36948966         36949088      +  GATCCTCTCGCCTTGATCCC  \n",
      "2           36948966         36949088      +  TGATCCGATTCCCCGACTCC  \n",
      "3           36948966         36949088      -  GGGGTTGGGCCGCACATTTC  \n",
      "4           36948966         36949088      +  TGCCGGATCCTCTCGCCTTC  \n",
      "                     target_loc                element_seq intended_target  \\\n",
      "0  chr10:102055949-102055968(-)  chr10:102055925-102056425        C10orf76   \n",
      "1  chr10:102056011-102056030(-)  chr10:102055925-102056425        C10orf76   \n",
      "2  chr10:102056104-102056123(+)  chr10:102055925-102056425        C10orf76   \n",
      "3  chr10:102056211-102056230(-)  chr10:102055925-102056425        C10orf76   \n",
      "4  chr10:102056276-102056295(-)  chr10:102055925-102056425        C10orf76   \n",
      "\n",
      "  intended_target.1         source          protospacer  \\\n",
      "0          C10orf76  TFPerturbSeq+  GGGACGACGAGGACGCGAG   \n",
      "1          C10orf76  TFPerturbSeq+  GTCCTGCCATACTAGGCCT   \n",
      "2          C10orf76  TFPerturbSeq+  TACCACCCGCGCCGTTCCC   \n",
      "3          C10orf76  TFPerturbSeq+  TAGGACCCGGCGGGGCGCG   \n",
      "4          C10orf76  TFPerturbSeq+  TGGGAATCGTGGTCTGAGC   \n",
      "\n",
      "                                      oligo_sequence   antisense_sequence  \\\n",
      "0  GTGGAAAGGACGAAACACCGGGGACGACGAGGACGCGAGGTTTAAG...  CTCGCGTCCTCGTCGTCCC   \n",
      "1  GTGGAAAGGACGAAACACCGGTCCTGCCATACTAGGCCTGTTTAAG...  AGGCCTAGTATGGCAGGAC   \n",
      "2  GTGGAAAGGACGAAACACCGTACCACCCGCGCCGTTCCCGTTTAAG...  GGGAACGGCGCGGGTGGTA   \n",
      "3  GTGGAAAGGACGAAACACCGTAGGACCCGGCGGGGCGCGGTTTAAG...  CGCGCCCCGCCGGGTCCTA   \n",
      "4  GTGGAAAGGACGAAACACCGTGGGAATCGTGGTCTGAGCGTTTAAG...  GCTCAGACCACGATTCCCA   \n",
      "\n",
      "  intended_target.2 intended_target.3  intended_target_start  \\\n",
      "0          C10orf76          C10orf76              102055925   \n",
      "1          C10orf76          C10orf76              102055925   \n",
      "2          C10orf76          C10orf76              102055925   \n",
      "3          C10orf76          C10orf76              102055925   \n",
      "4          C10orf76          C10orf76              102055925   \n",
      "\n",
      "   intended_target_end intended_target_chr strand  PAM guide_chr  guide_start  \\\n",
      "0            102056425               chr10      -  NGG     chr10    102055949   \n",
      "1            102056425               chr10      -  NGG     chr10    102056011   \n",
      "2            102056425               chr10      +  NGG     chr10    102056104   \n",
      "3            102056425               chr10      -  NGG     chr10    102056211   \n",
      "4            102056425               chr10      -  NGG     chr10    102056276   \n",
      "\n",
      "   guide_end  \n",
      "0  102055968  \n",
      "1  102056030  \n",
      "2  102056123  \n",
      "3  102056230  \n",
      "4  102056295  \n",
      "Annot:\n",
      "             protospacer_ID           protospacer intended_target_name  \\\n",
      "0                DNAJC19_ B  GGGAACTCCTGTAAGGTCAG              DNAJC19   \n",
      "1                 POLR1D_ B  GGGAAGCAAGGACCGACCGA               POLR1D   \n",
      "2                   OR5K2-2  GAAAAAATTGTAGAGGAATA                OR5K2   \n",
      "3  SP1_+_53773993.23-P1P2-1  GAAAAACGCGGACGCTGACG                  SP1   \n",
      "4  SP8_-_20826141.23-P1P2-2  GAAAAAGATCCTCTGAGAGG                  SP8   \n",
      "\n",
      "        type genomic_element    reverse_compliment  \n",
      "0  targeting        promoter  CTGACCTTACAGGAGTTCCC  \n",
      "1  targeting        promoter  TCGGTCGGTCCTTGCTTCCC  \n",
      "2  targeting        promoter  TATTCCTCTACAATTTTTTC  \n",
      "3  targeting        promoter  CGTCAGCGTCCGCGTTTTTC  \n",
      "4  targeting        promoter  CCTCTCAGAGGATCTTTTTC  \n"
     ]
    }
   ],
   "source": [
    "# Add a reverse compliment if needed\n",
    "def reverse_compliment(sequence):\n",
    "    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
    "    return \"\".join(complement.get(base, base) for base in reversed(sequence.upper()))\n",
    "\n",
    "sgrna_index_poolabcd['reverse_compliment'] = sgrna_index_poolabcd['sgRNA_seq'].apply(reverse_compliment)\n",
    "sgrna_index_poolf.rename(columns={\"antisense_sequence\": \"reverse_compliment\"})\n",
    "\n",
    "print(\"Index:\")\n",
    "print(sgrna_index_poolabcd.head())\n",
    "print(sgrna_index_poolf.head())\n",
    "print(\"Annot:\")\n",
    "print(sgrna_index_dacc_annot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13470\n"
     ]
    }
   ],
   "source": [
    "sgrna_index_dacc_annot[\"protospacer_upper\"] = sgrna_index_dacc_annot[\"protospacer\"].str.upper() \n",
    "\n",
    "print(len(set(sgrna_index_poolabcd['sgRNA_seq']).intersection(sgrna_index_dacc_annot['protospacer_upper'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               protospacer_ID           protospacer intended_target_name  \\\n",
      "0                     OR5K2-2  GAAAAAATTGTAGAGGAATA                OR5K2   \n",
      "1    SP1_+_53773993.23-P1P2-1  GAAAAACGCGGACGCTGACG                  SP1   \n",
      "2    SP8_-_20826141.23-P1P2-2  GAAAAAGATCCTCTGAGAGG                  SP8   \n",
      "3    FOXN3_-_89883583.23-P2-1  GAAAAAGGCGACACATGACC                FOXN3   \n",
      "4  ZNF85_+_21106076.23-P1P2-1  GAAAACAAGACCTAGAGCTC                ZNF85   \n",
      "\n",
      "        type genomic_element    reverse_compliment     protospacer_upper  \\\n",
      "0  targeting        promoter  TATTCCTCTACAATTTTTTC  GAAAAAATTGTAGAGGAATA   \n",
      "1  targeting        promoter  CGTCAGCGTCCGCGTTTTTC  GAAAAACGCGGACGCTGACG   \n",
      "2  targeting        promoter  CCTCTCAGAGGATCTTTTTC  GAAAAAGATCCTCTGAGAGG   \n",
      "3  targeting        promoter  GGTCATGTGTCGCCTTTTTC  GAAAAAGGCGACACATGACC   \n",
      "4  targeting        promoter  GAGCTCTAGGTCTTGTTTTC  GAAAACAAGACCTAGAGCTC   \n",
      "\n",
      "                   target_loc              element_seq      target  ...  \\\n",
      "0                         NaN                      NaN         NaN  ...   \n",
      "1  chr12:53380213-53380231(-)  chr12:53380184-53380609    SP1_P1P2  ...   \n",
      "2   chr7:20786818-20786836(-)   chr7:20786502-20786925    SP8_P1P2  ...   \n",
      "3  chr14:89417219-89417237(+)  chr14:89416760-89417237    FOXN3_P2  ...   \n",
      "4  chr19:20923274-20923292(-)  chr19:20923274-20923584  ZNF85_P1P2  ...   \n",
      "\n",
      "              sgRNA_seq                                              oligo  \\\n",
      "0                   NaN                                                NaN   \n",
      "1  GAAAAACGCGGACGCTGACG  GTGGAAAGGACGAAACACCGAAAAACGCGGACGCTGACGGTTTAAG...   \n",
      "2  GAAAAAGATCCTCTGAGAGG  GTGGAAAGGACGAAACACCGAAAAAGATCCTCTGAGAGGGTTTAAG...   \n",
      "3  GAAAAAGGCGACACATGACC  GTGGAAAGGACGAAACACCGAAAAAGGCGACACATGACCGTTTAAG...   \n",
      "4  GAAAACAAGACCTAGAGCTC  GTGGAAAGGACGAAACACCGAAAACAAGACCTAGAGCTCGTTTAAG...   \n",
      "\n",
      "  gene_target chr_target chr_start_target  chr_end_target  chr_element  \\\n",
      "0         NaN        NaN              NaN             NaN          NaN   \n",
      "1         SP1      chr12       53380213.0      53380231.0        chr12   \n",
      "2         SP8       chr7       20786818.0      20786836.0         chr7   \n",
      "3       FOXN3      chr14       89417219.0      89417237.0        chr14   \n",
      "4       ZNF85      chr19       20923274.0      20923292.0        chr19   \n",
      "\n",
      "  chr_start_element  chr_end_element  strand  \n",
      "0               NaN              NaN     NaN  \n",
      "1        53380184.0       53380609.0       -  \n",
      "2        20786502.0       20786925.0       -  \n",
      "3        89416760.0       89417237.0       +  \n",
      "4        20923274.0       20923584.0       -  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(14469, 21)\n"
     ]
    }
   ],
   "source": [
    "# Merge pool A-D index and DACC files into one; pool F file has sufficient info for matching\n",
    "sgrna_index_merged = pd.merge(\n",
    "    sgrna_index_dacc_annot,\n",
    "    sgrna_index_poolabcd,\n",
    "    left_on=['protospacer_upper', 'reverse_compliment'],\n",
    "    right_on=['sgRNA_seq', 'reverse_compliment'],\n",
    "    how=\"outer\"\n",
    ")\n",
    "print(sgrna_index_merged.head())\n",
    "print(sgrna_index_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add positive and negative controls and non-targeting gRNAs, if not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0 Photospacer (same for all 3 sets)\n",
      "0  non-targeting_00642              GGAGTTAAGGCCTCGTCTAG\n",
      "1  non-targeting_00718              GTCCCAGGCTCTCCACTATG\n",
      "2  non-targeting_03631              GGACGCGTCTGCAAGAACGT\n",
      "3  non-targeting_03705              GGGCATGGACCCGCGGCACG\n",
      "4  non-targeting_01469              GCGTCCGAGGTACTGAATAA\n",
      "           Gene Photospacer (represent 10 times)  \\\n",
      "0   CD81 strong             GGAGAGCGAGCGCGCAACGG   \n",
      "1     CD81 weak             GGAGAGCCAGCGCGCAACGG   \n",
      "2  CD151 strong             GCCGGACTCGGACGCGTGGT   \n",
      "3    CD151 weak             GCCGCTCGGCCGAGCTGTCG   \n",
      "4   CD55 strong             GCTGCGACTCGGCGGAGTCC   \n",
      "\n",
      "                                           Reference  \n",
      "0  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "1  Jost et al. 2020 \"Titrating gene expression us...  \n",
      "2  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "3  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "4  Horlbeck et al. 2016 \"Compact and highly activ...  \n",
      "     Gene         Photospacer 1         Photospacer 2         Photospacer 3  \\\n",
      "0   OR1J4  GAGGAGGAGAGTGTGAGACA  GGAAGACTGTCAGCATGAAG  GGATAGTGGTGTAGCGGAGG   \n",
      "1  OR10K1  GCTTCTATAAAGGAGAGTCA  GAGGGACAGAGGTAGAAACC  GAGGGCTCTGTCCAGCACAA   \n",
      "2   OR5L2  GCTGCATAAATTGGAGACAT  GTGGTCACCATGTACAGCAG  GTGCACATGTGGAGTCACTG   \n",
      "3  OR52W1  GCTCCTGACAGGGAAGATAA  GACAACTTGAGGGCTCATGG  GTGTGGTGGGCACAACTTGA   \n",
      "4   OR8K1  GTCACAGTGATAGGCAATCT  GTGTGACCAGATATATGATG  GTGAGGAAGAGTCCAAACAG   \n",
      "\n",
      "          Photospacer 4         Photospacer 5         Photospacer 6  \n",
      "0  GCAGGGCATTGGTACAGGAG  GACACACCCTGCATAAAGAA  GTGAGACAGGGCATTGGTAC  \n",
      "1  GAAGTACATGGGAGTATGAA  GATGGAGAGCACTTCTATAA  GGTCTTATTGACTTGCTCCA  \n",
      "2  GAGTGCAGTCATGCCCAGAT  GATGTCTCAGAAGCTGCGTG  GCTCTTGCTGCTACTTCTGT  \n",
      "3  GACCAGTGTCAGCCAAGTCT  GAGTTGTGCCCACCACAGAA  GGCTAGGAAGTGCCCAGACT  \n",
      "4  GGGCTGCAGGCTCCACTGTT  GAATCACACGGCAGTGACCA  GTTTGATGTATGAGCAATAG  \n"
     ]
    }
   ],
   "source": [
    "neg_controls = pd.read_csv(local_path + \"negative_controls.tsv\", sep = \"\\t\")\n",
    "pos_controls = pd.read_csv(local_path + \"positive_controls.tsv\", sep = \"\\t\")\n",
    "non_targeting = pd.read_csv(local_path + \"non_targeting.tsv\", sep = \"\\t\")\n",
    "\n",
    "print(non_targeting.head())\n",
    "print(pos_controls.head())\n",
    "print(neg_controls.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(set(sgrna_index_merged['protospacer_upper']).intersection(set(non_targeting['Photospacer (same for all 3 sets)']))))\n",
    "print(len(set(sgrna_index_merged['protospacer_upper']).intersection(set(pos_controls['Photospacer (represent 10 times)']))))  \n",
    "cols = [c for c in neg_controls.columns if c.startswith('Photospacer')]\n",
    "neg_spacers = pd.concat([neg_controls[c] for c in cols]).dropna().astype(str)\n",
    "\n",
    "len(set(sgrna_index_merged['protospacer_upper']).intersection(set(neg_spacers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat to resemble input to the CRISPR pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import example file for the CRISPR pipeline\n",
    "example_crispr_file = pd.read_csv(local_path + \"crispr_annot_sample.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guide_id</th>\n",
       "      <th>spacer</th>\n",
       "      <th>targeting</th>\n",
       "      <th>type</th>\n",
       "      <th>guide_chr</th>\n",
       "      <th>guide_start</th>\n",
       "      <th>guide_end</th>\n",
       "      <th>strand</th>\n",
       "      <th>pam</th>\n",
       "      <th>intended_target_name</th>\n",
       "      <th>intended_target_chr</th>\n",
       "      <th>intended_target_start</th>\n",
       "      <th>intended_target_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFF4_sg1</td>\n",
       "      <td>CCAGCGGACGGGGCGGGGAC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299282.0</td>\n",
       "      <td>132299302.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFF4_sg2</td>\n",
       "      <td>CCGCCAGCGGACGGGGCGGC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299282.0</td>\n",
       "      <td>132299302.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFF4_sg3</td>\n",
       "      <td>CGTCCGCTGGCGGCGGCGAC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299252.0</td>\n",
       "      <td>132299272.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFF4_sg4</td>\n",
       "      <td>CTGCGTCAGTCACAGCCCTC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299279.0</td>\n",
       "      <td>132299299.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFF4_sg5</td>\n",
       "      <td>GCGGACGGGGCGGGGATCCC</td>\n",
       "      <td>True</td>\n",
       "      <td>targeting</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132299279.0</td>\n",
       "      <td>132299299.0</td>\n",
       "      <td>-</td>\n",
       "      <td>NGG</td>\n",
       "      <td>AFF4</td>\n",
       "      <td>chr5</td>\n",
       "      <td>132875395.0</td>\n",
       "      <td>132963634.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   guide_id                spacer  targeting       type guide_chr  \\\n",
       "0  AFF4_sg1  CCAGCGGACGGGGCGGGGAC       True  targeting      chr5   \n",
       "1  AFF4_sg2  CCGCCAGCGGACGGGGCGGC       True  targeting      chr5   \n",
       "2  AFF4_sg3  CGTCCGCTGGCGGCGGCGAC       True  targeting      chr5   \n",
       "3  AFF4_sg4  CTGCGTCAGTCACAGCCCTC       True  targeting      chr5   \n",
       "4  AFF4_sg5  GCGGACGGGGCGGGGATCCC       True  targeting      chr5   \n",
       "\n",
       "   guide_start    guide_end strand  pam intended_target_name  \\\n",
       "0  132299282.0  132299302.0      -  NGG                 AFF4   \n",
       "1  132299282.0  132299302.0      -  NGG                 AFF4   \n",
       "2  132299252.0  132299272.0      -  NGG                 AFF4   \n",
       "3  132299279.0  132299299.0      -  NGG                 AFF4   \n",
       "4  132299279.0  132299299.0      -  NGG                 AFF4   \n",
       "\n",
       "  intended_target_chr  intended_target_start  intended_target_end  \n",
       "0                chr5            132875395.0          132963634.0  \n",
       "1                chr5            132875395.0          132963634.0  \n",
       "2                chr5            132875395.0          132963634.0  \n",
       "3                chr5            132875395.0          132963634.0  \n",
       "4                chr5            132875395.0          132963634.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_crispr_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained rows: 19956\n",
      "Retained rows: 17364\n",
      "Retained rows: 2592\n"
     ]
    }
   ],
   "source": [
    "# Keep only necessary columns and reorder them to match \n",
    "def prune_and_rename_cols(merged_guide_file, is_pool_f=False):\n",
    "    # start from full table so you don't drop rows prematurely\n",
    "    df = merged_guide_file.copy()\n",
    "\n",
    "    if is_pool_f:\n",
    "        df[\"guide_id\"] = (\n",
    "            df.get(\"id_gersbach\").combine_first(df.get(\"id_engreitz\"))\n",
    "        )\n",
    "        df[\"intended_target_name\"] = (\n",
    "            df.get(\"intended_target_name_gersbach\")\n",
    "            .combine_first(df.get(\"intended_target_name_engreitz\"))\n",
    "        )\n",
    "    else:\n",
    "        df[\"guide_id\"] = (\n",
    "            df.get(\"id_hon\")\n",
    "            .combine_first(df.get(\"id_gersbach\"))\n",
    "            .combine_first(df.get(\"id_engreitz\"))\n",
    "            .combine_first(df.get(\"id_huangfu\"))\n",
    "        )\n",
    "        df[\"intended_target_name\"] = (\n",
    "            df.get(\"intended_target_name_hon\")\n",
    "            .combine_first(df.get(\"intended_target_name_gersbach\"))\n",
    "            .combine_first(df.get(\"intended_target_name_engreitz\"))\n",
    "            .combine_first(df.get(\"intended_target_name_huangfu\"))\n",
    "        )\n",
    "\n",
    "    # Fallbacks for control / nonâ€‘targeting rows.\n",
    "    df[\"guide_id\"] = df[\"guide_id\"].fillna(df.get(\"id\", df.get(\"protospacer\")))\n",
    "    df[\"intended_target_name\"] = df[\"intended_target_name\"].fillna(df.get(\"type\"))\n",
    "\n",
    "    # Rename after all adjustments\n",
    "    if \"protospacer\" in df.columns:\n",
    "        df = df.rename(columns={\"protospacer\": \"spacer\"})\n",
    "\n",
    "    keep_cols = [c for c in [\"guide_id\", \"spacer\", \"type\", \"intended_target_name\", \"reverse_compliment\"] if c in df.columns]\n",
    "    ref_clean_sub = df[keep_cols].copy()\n",
    "\n",
    "    print(f\"Retained rows: {ref_clean_sub.shape[0]}\")\n",
    "    return ref_clean_sub\n",
    "\n",
    "# Call function\n",
    "ref_clean_sub = prune_and_rename_cols(merged_guide_file)\n",
    "ref_clean_sub_poolabcd = prune_and_rename_cols(merged_guide_file_poolabcd)\n",
    "ref_clean_sub_poolf = prune_and_rename_cols(merged_guide_file_poolf, is_pool_f=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       guide_id                spacer  targeting       type  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1  GCACAGGACGGCCGAGCTGA       True  targeting   \n",
      "1     EN2_-_155251011.23-P1P2-1  GCTCCGTGTGCGCCGCGGGA       True  targeting   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2  GCTCCGTTGCAACCACACAG       True  targeting   \n",
      "3      KLF6_-_3827130.23-P1P2-2  GCTGGAGGATCGATCGGCGG       True  targeting   \n",
      "4     ELF1_+_41593362.23-P1P2-2  GTGAGCTGATAAACAGAGGG       True  targeting   \n",
      "\n",
      "  intended_target_name  \n",
      "0                FOXN1  \n",
      "1                  EN2  \n",
      "2               BCLAF1  \n",
      "3                 KLF6  \n",
      "4                 ELF1  \n",
      "                     guide_id                spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  GCATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GGATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  GTTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  GTTTTTGTCTTCAAAAATCT      False   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  GCTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name  \n",
      "0         targeting                 TFEC  \n",
      "1         targeting                NR2C1  \n",
      "2         targeting                NANOG  \n",
      "3  negative_control                OR8B3  \n",
      "4         targeting                ZNF48  \n",
      "       guide_id               spacer  targeting       type  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting   \n",
      "\n",
      "  intended_target_name  \n",
      "0                NR2F2  \n",
      "1                IL6ST  \n",
      "2               YEATS4  \n",
      "3                 EPC2  \n",
      "4                GPR78  \n"
     ]
    }
   ],
   "source": [
    "# Add 'targeting' column; if type == targeting, set to True, otherwise False\n",
    "def check_targeting(value):\n",
    "    if(value == \"targeting\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def add_targeting_col(ref_clean_sub):\n",
    "    ref_clean_sub['targeting'] = ref_clean_sub['type'].apply(check_targeting)\n",
    "    order = ['guide_id', 'spacer', 'targeting', 'type', 'intended_target_name']\n",
    "    ref_clean_sub = ref_clean_sub[order]\n",
    "    print(ref_clean_sub.head())\n",
    "    return ref_clean_sub\n",
    "\n",
    "ref_clean_sub = add_targeting_col(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = add_targeting_col(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = add_targeting_col(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       guide_id                spacer  targeting       type  \\\n",
      "0    FOXN1_-_26833391.23-P1P2-1  GCACAGGACGGCCGAGCTGA       True  targeting   \n",
      "1     EN2_-_155251011.23-P1P2-1  GCTCCGTGTGCGCCGCGGGA       True  targeting   \n",
      "2  BCLAF1_-_136610510.23-P1P2-2  GCTCCGTTGCAACCACACAG       True  targeting   \n",
      "3      KLF6_-_3827130.23-P1P2-2  GCTGGAGGATCGATCGGCGG       True  targeting   \n",
      "4     ELF1_+_41593362.23-P1P2-2  GTGAGCTGATAAACAGAGGG       True  targeting   \n",
      "\n",
      "  intended_target_name  pam  \n",
      "0                FOXN1  NGG  \n",
      "1                  EN2  NGG  \n",
      "2               BCLAF1  NGG  \n",
      "3                 KLF6  NGG  \n",
      "4                 ELF1  NGG  \n",
      "(19956, 6)\n",
      "                     guide_id                spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  GCATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GGATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  GTTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  GTTTTTGTCTTCAAAAATCT      False   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  GCTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name  pam  \n",
      "0         targeting                 TFEC  NGG  \n",
      "1         targeting                NR2C1  NGG  \n",
      "2         targeting                NANOG  NGG  \n",
      "3  negative_control                OR8B3  NGG  \n",
      "4         targeting                ZNF48  NGG  \n",
      "(17364, 6)\n",
      "       guide_id               spacer  targeting       type  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting   \n",
      "\n",
      "  intended_target_name  pam  \n",
      "0                NR2F2  NGG  \n",
      "1                IL6ST  NGG  \n",
      "2               YEATS4  NGG  \n",
      "3                 EPC2  NGG  \n",
      "4                GPR78  NGG  \n",
      "(2592, 6)\n"
     ]
    }
   ],
   "source": [
    "# Add PAM\n",
    "def add_pam(ref_clean_sub):\n",
    "    ref_clean_sub['pam'] = 'NGG'\n",
    "    print(ref_clean_sub.head())\n",
    "    print(ref_clean_sub.shape)\n",
    "    return ref_clean_sub\n",
    "\n",
    "ref_clean_sub = add_pam(ref_clean_sub)\n",
    "ref_clean_sub_poolabcd = add_pam(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf = add_pam(ref_clean_sub_poolf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               protospacer_ID           protospacer intended_target_name  \\\n",
      "0                     OR5K2-2  GAAAAAATTGTAGAGGAATA                OR5K2   \n",
      "1    SP1_+_53773993.23-P1P2-1  GAAAAACGCGGACGCTGACG                  SP1   \n",
      "2    SP8_-_20826141.23-P1P2-2  GAAAAAGATCCTCTGAGAGG                  SP8   \n",
      "3    FOXN3_-_89883583.23-P2-1  GAAAAAGGCGACACATGACC                FOXN3   \n",
      "4  ZNF85_+_21106076.23-P1P2-1  GAAAACAAGACCTAGAGCTC                ZNF85   \n",
      "\n",
      "        type genomic_element    reverse_compliment     protospacer_upper  \\\n",
      "0  targeting        promoter  TATTCCTCTACAATTTTTTC  GAAAAAATTGTAGAGGAATA   \n",
      "1  targeting        promoter  CGTCAGCGTCCGCGTTTTTC  GAAAAACGCGGACGCTGACG   \n",
      "2  targeting        promoter  CCTCTCAGAGGATCTTTTTC  GAAAAAGATCCTCTGAGAGG   \n",
      "3  targeting        promoter  GGTCATGTGTCGCCTTTTTC  GAAAAAGGCGACACATGACC   \n",
      "4  targeting        promoter  GAGCTCTAGGTCTTGTTTTC  GAAAACAAGACCTAGAGCTC   \n",
      "\n",
      "                   target_loc              element_seq      target  ...  \\\n",
      "0                         NaN                      NaN         NaN  ...   \n",
      "1  chr12:53380213-53380231(-)  chr12:53380184-53380609    SP1_P1P2  ...   \n",
      "2   chr7:20786818-20786836(-)   chr7:20786502-20786925    SP8_P1P2  ...   \n",
      "3  chr14:89417219-89417237(+)  chr14:89416760-89417237    FOXN3_P2  ...   \n",
      "4  chr19:20923274-20923292(-)  chr19:20923274-20923584  ZNF85_P1P2  ...   \n",
      "\n",
      "              sgRNA_seq                                              oligo  \\\n",
      "0                   NaN                                                NaN   \n",
      "1  GAAAAACGCGGACGCTGACG  GTGGAAAGGACGAAACACCGAAAAACGCGGACGCTGACGGTTTAAG...   \n",
      "2  GAAAAAGATCCTCTGAGAGG  GTGGAAAGGACGAAACACCGAAAAAGATCCTCTGAGAGGGTTTAAG...   \n",
      "3  GAAAAAGGCGACACATGACC  GTGGAAAGGACGAAACACCGAAAAAGGCGACACATGACCGTTTAAG...   \n",
      "4  GAAAACAAGACCTAGAGCTC  GTGGAAAGGACGAAACACCGAAAACAAGACCTAGAGCTCGTTTAAG...   \n",
      "\n",
      "  gene_target chr_target chr_start_target  chr_end_target  chr_element  \\\n",
      "0         NaN        NaN              NaN             NaN          NaN   \n",
      "1         SP1      chr12       53380213.0      53380231.0        chr12   \n",
      "2         SP8       chr7       20786818.0      20786836.0         chr7   \n",
      "3       FOXN3      chr14       89417219.0      89417237.0        chr14   \n",
      "4       ZNF85      chr19       20923274.0      20923292.0        chr19   \n",
      "\n",
      "  chr_start_element  chr_end_element  strand  \n",
      "0               NaN              NaN     NaN  \n",
      "1        53380184.0       53380609.0       -  \n",
      "2        20786502.0       20786925.0       -  \n",
      "3        89416760.0       89417237.0       +  \n",
      "4        20923274.0       20923584.0       -  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "14358\n",
      "2592\n"
     ]
    }
   ],
   "source": [
    "print(sgrna_index_merged.head())\n",
    "print(len(set(sgrna_index_merged['protospacer_upper']).intersection(set(ref_clean_sub_poolabcd['spacer']))))\n",
    "print(len(set(sgrna_index_poolf['protospacer']).intersection(set(ref_clean_sub_poolf['spacer']))))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protospacer_upper\n",
      "GCAGCCACGCGAGAGTAGAA    3\n",
      "GGACCGCGGCCGAGCGAACC    2\n",
      "GTGCTGGGAGGCGGTTTCCG    2\n",
      "GGGACCTGCGGGAAATCGGG    2\n",
      "GTGGGGAGGAAGCGGTTCTA    2\n",
      "                       ..\n",
      "GGAGGGGCTACGGTGACCAG    2\n",
      "GGTCTCCGCTCTGATGCCTG    2\n",
      "GCGCTCTGATGCCTGAGGAA    2\n",
      "GCGCTGCGGTGGAGCCACCG    2\n",
      "GGCGACAGAAGCCTGGGTAC    2\n",
      "Name: count, Length: 92, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for repeated spacer sequences in index file\n",
    "print(sgrna_index_merged['protospacer_upper'].value_counts().loc[lambda x: x > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove multiple mappings from sgrna_index_merged\n",
    "def deduplicate_index_file(df):\n",
    "    def chrom_rank(chrom):\n",
    "        if pd.isna(chrom):\n",
    "            return 100\n",
    "        if isinstance(chrom, str) and chrom.startswith(\"chr\"):\n",
    "            c = chrom[3:]\n",
    "            if c.isdigit():\n",
    "                return int(c)\n",
    "            elif c == \"X\":\n",
    "                return 23\n",
    "            elif c == \"Y\":\n",
    "                return 24\n",
    "        return 100  # fallback\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Rank and sorting\n",
    "    df[\"chrom_rank\"] = df[\"chr_target\"].map(chrom_rank)\n",
    "    df[\"sort_key\"] = (\n",
    "        df[\"chrom_rank\"].fillna(100) * 1e12 +\n",
    "        df[\"chr_start_target\"].fillna(0) * 1e6 +\n",
    "        (df[\"chr_end_target\"].fillna(0) - df[\"chr_start_target\"].fillna(0))\n",
    "    )\n",
    "    \n",
    "    # Group by spacer sequence\n",
    "    grouped = df.groupby(\"protospacer_upper\", group_keys=False)\n",
    "    \n",
    "    # Keep only groups where all key columns are the same across rows\n",
    "    key_cols = [\n",
    "        \"chr_target\", \"chr_start_target\", \"chr_end_target\",\n",
    "        \"chr_element\", \"chr_start_element\", \"chr_end_element\"\n",
    "    ]\n",
    "    \n",
    "    def is_consistent(group):\n",
    "        return all(group[col].nunique(dropna=False) == 1 for col in key_cols)\n",
    "    \n",
    "    consistent_df = grouped.filter(is_consistent)\n",
    "    \n",
    "    # Deduplicate remaining consistent rows by keeping best ranked\n",
    "    deduped_df = (\n",
    "        consistent_df.sort_values(\"sort_key\")\n",
    "                     .drop_duplicates(subset=\"protospacer_upper\", keep=\"first\")\n",
    "                     .drop(columns=[\"chrom_rank\", \"sort_key\"])\n",
    "    )\n",
    "    \n",
    "    return deduped_df\n",
    "\n",
    "# Apply deduplication before merging\n",
    "sgrna_index_merged = deduplicate_index_file(sgrna_index_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     guide_id                spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  GCATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GGATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  GTTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  GTTTTTGTCTTCAAAAATCT      False   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  GCTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name  pam guide_chr  guide_start  \\\n",
      "0         targeting                 TFEC  NGG      chr7  116030705.0   \n",
      "1         targeting                NR2C1  NGG     chr12   95073493.0   \n",
      "2         targeting                NANOG  NGG     chr12    7789912.0   \n",
      "3  negative_control                OR8B3  NGG       NaN          NaN   \n",
      "4         targeting                ZNF48  NGG     chr16   30395465.0   \n",
      "\n",
      "     guide_end strand  \n",
      "0  116030723.0      +  \n",
      "1   95073511.0      +  \n",
      "2    7789930.0      +  \n",
      "3          NaN    NaN  \n",
      "4   30395483.0      -  \n",
      "                     guide_id                spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  GCATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GGATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  GTTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  GTTTTTGTCTTCAAAAATCT      False   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  GCTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name  pam guide_chr  guide_start  \\\n",
      "0         targeting                 TFEC  NGG      chr7  116030705.0   \n",
      "1         targeting                NR2C1  NGG     chr12   95073493.0   \n",
      "2         targeting                NANOG  NGG     chr12    7789912.0   \n",
      "3  negative_control                OR8B3  NGG       NaN          NaN   \n",
      "4         targeting                ZNF48  NGG     chr16   30395465.0   \n",
      "\n",
      "     guide_end strand  \n",
      "0  116030723.0      +  \n",
      "1   95073511.0      +  \n",
      "2    7789930.0      +  \n",
      "3          NaN    NaN  \n",
      "4   30395483.0      -  \n",
      "       guide_id               spacer  targeting       type  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting   \n",
      "\n",
      "  intended_target_name  pam          protospacer guide_chr  guide_start  \\\n",
      "0                NR2F2  NGG  GAAAACCGCCAACAACTAT     chr15     96325764   \n",
      "1                IL6ST  NGG  GAAGGATCTGACAGTGTTC      chr5     55994948   \n",
      "2               YEATS4  NGG  GAAGGAGGGCGAGTTACTT     chr12     69359838   \n",
      "3                 EPC2  NGG  GAAGGAGGAGGAATCGGTA      chr2    148645155   \n",
      "4                GPR78  NGG  GAAGGAAAGATACAGTGTT      chr4      8580609   \n",
      "\n",
      "   guide_end strand  \n",
      "0   96325783      -  \n",
      "1   55994966      -  \n",
      "2   69359856      -  \n",
      "3  148645173      +  \n",
      "4    8580627      +  \n"
     ]
    }
   ],
   "source": [
    "# Add the 'guide_chr', 'guide_start', and 'guide_end' values, which are given as 'chr_target', 'chr_start_target', 'chr_end_target', and 'strand'\n",
    "def add_guide_coords(ref_clean_sub, sgrna_index_merged):\n",
    "    ref_clean_sub = pd.merge(\n",
    "        ref_clean_sub,\n",
    "        sgrna_index_merged[['protospacer_upper', 'chr_target', 'chr_start_target', 'chr_end_target', 'strand']],\n",
    "        left_on='spacer',\n",
    "        right_on='protospacer_upper',\n",
    "        how='left'\n",
    "    )\n",
    "    # Remove protospacer_upper column\n",
    "    ref_clean_sub = ref_clean_sub.drop(columns=['protospacer_upper'])\n",
    "    # Rename intended guide names\n",
    "    ref_clean_sub.rename(columns={'chr_target': 'guide_chr', \n",
    "                                  'chr_start_target': 'guide_start',\n",
    "                                  'chr_end_target': 'guide_end'},\n",
    "                                  inplace=True)\n",
    "\n",
    "\n",
    "    print(ref_clean_sub.head())\n",
    "    return ref_clean_sub\n",
    "\n",
    "\n",
    "ref_clean_sub_poolabcd = add_guide_coords(ref_clean_sub_poolabcd, sgrna_index_merged)\n",
    "print(ref_clean_sub_poolabcd.head())\n",
    "\n",
    "# Columns are already correctly labeled for pool F\n",
    "ref_clean_sub_poolf = pd.merge(\n",
    "    ref_clean_sub_poolf,\n",
    "    sgrna_index_poolf[['protospacer', 'guide_chr', 'guide_start', 'guide_end', 'strand']],\n",
    "    left_on='spacer',\n",
    "    right_on='protospacer',\n",
    "    how='left'\n",
    ")\n",
    "print(ref_clean_sub_poolf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     guide_id                spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  GCATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GGATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  GTTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  GTTTTTGTCTTCAAAAATCT      False   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  GCTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type intended_target_name  pam guide_chr  guide_start  \\\n",
      "0         targeting                 TFEC  NGG      chr7  116030705.0   \n",
      "1         targeting                NR2C1  NGG     chr12   95073493.0   \n",
      "2         targeting                NANOG  NGG     chr12    7789912.0   \n",
      "3  negative_control                OR8B3  NGG       NaN          NaN   \n",
      "4         targeting                ZNF48  NGG     chr16   30395465.0   \n",
      "\n",
      "     guide_end strand intended_target_chr  intended_target_start  \\\n",
      "0  116030723.0      +                chr7            116030682.0   \n",
      "1   95073511.0      +               chr12             95073472.0   \n",
      "2    7789930.0      +               chr12              7789786.0   \n",
      "3          NaN    NaN                 NaN                    NaN   \n",
      "4   30395483.0      -               chr16             30395465.0   \n",
      "\n",
      "   intended_target_end  \n",
      "0          116030770.0  \n",
      "1           95073659.0  \n",
      "2            7789930.0  \n",
      "3                  NaN  \n",
      "4           30395994.0  \n"
     ]
    }
   ],
   "source": [
    "# Add the intended_target_chr/intended_target_start/intended_target_end values, which are given as 'chr_element', 'chr_start_element', 'chr_end_element'\n",
    "# Note that this refers to the element being targeted, not the gene itself\n",
    "def add_element_coords(ref_clean_sub, sgrna_index_merged):\n",
    "    ref_clean_sub = pd.merge(\n",
    "        ref_clean_sub,\n",
    "        sgrna_index_merged[['protospacer_upper', 'chr_element', 'chr_start_element', 'chr_end_element']],\n",
    "        left_on='spacer',\n",
    "        right_on='protospacer_upper',\n",
    "        how='left'\n",
    "    )\n",
    "    # Remove protospacer_upper column\n",
    "    ref_clean_sub = ref_clean_sub.drop(columns=['protospacer_upper'])\n",
    "    # Rename intended target names\n",
    "    ref_clean_sub.rename(columns={'chr_element': 'intended_target_chr', \n",
    "                                  'chr_start_element': 'intended_target_start',\n",
    "                                  'chr_end_element': 'intended_target_end'},\n",
    "                                  inplace=True)\n",
    "    print(ref_clean_sub.head())\n",
    "    return ref_clean_sub\n",
    "\n",
    "\n",
    "ref_clean_sub_poolabcd = add_element_coords(ref_clean_sub_poolabcd, sgrna_index_merged)\n",
    "ref_clean_sub_poolabcd.head()\n",
    "\n",
    "# Columns are already correctly labeled for pool F\n",
    "ref_clean_sub_poolf = pd.merge(\n",
    "    ref_clean_sub_poolf,\n",
    "    sgrna_index_poolf[['protospacer', 'intended_target_chr', 'intended_target_start', 'intended_target_end']],\n",
    "    left_on='spacer',\n",
    "    right_on='protospacer',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   guide_id                spacer  targeting       type guide_chr  \\\n",
      "0  AFF4_sg1  CCAGCGGACGGGGCGGGGAC       True  targeting      chr5   \n",
      "1  AFF4_sg2  CCGCCAGCGGACGGGGCGGC       True  targeting      chr5   \n",
      "2  AFF4_sg3  CGTCCGCTGGCGGCGGCGAC       True  targeting      chr5   \n",
      "3  AFF4_sg4  CTGCGTCAGTCACAGCCCTC       True  targeting      chr5   \n",
      "4  AFF4_sg5  GCGGACGGGGCGGGGATCCC       True  targeting      chr5   \n",
      "\n",
      "   guide_start    guide_end strand  pam intended_target_name  \\\n",
      "0  132299282.0  132299302.0      -  NGG                 AFF4   \n",
      "1  132299282.0  132299302.0      -  NGG                 AFF4   \n",
      "2  132299252.0  132299272.0      -  NGG                 AFF4   \n",
      "3  132299279.0  132299299.0      -  NGG                 AFF4   \n",
      "4  132299279.0  132299299.0      -  NGG                 AFF4   \n",
      "\n",
      "  intended_target_chr  intended_target_start  intended_target_end  \n",
      "0                chr5            132875395.0          132963634.0  \n",
      "1                chr5            132875395.0          132963634.0  \n",
      "2                chr5            132875395.0          132963634.0  \n",
      "3                chr5            132875395.0          132963634.0  \n",
      "4                chr5            132875395.0          132963634.0  \n",
      "                     guide_id                spacer  targeting  \\\n",
      "0  TFEC_-_115670779.23-P1P2-1  GCATATGCACCATGCCAGAA       True   \n",
      "1  NR2C1_-_95467292.23-P1P2-2  GGATGTGGGATCGAGATTCA       True   \n",
      "2   NANOG_+_7942459.23-P1P2-2  GTTTTTCCATTATAACTTGG       True   \n",
      "3                     OR8B3-5  GTTTTTGTCTTCAAAAATCT      False   \n",
      "4  ZNF48_+_30406782.23-P1P2-1  GCTCCGCGCCAAGCCGGGAG       True   \n",
      "\n",
      "               type guide_chr  guide_start    guide_end strand  pam  \\\n",
      "0         targeting      chr7  116030705.0  116030723.0      +  NGG   \n",
      "1         targeting     chr12   95073493.0   95073511.0      +  NGG   \n",
      "2         targeting     chr12    7789912.0    7789930.0      +  NGG   \n",
      "3  negative_control       NaN          NaN          NaN    NaN  NGG   \n",
      "4         targeting     chr16   30395465.0   30395483.0      -  NGG   \n",
      "\n",
      "  intended_target_name intended_target_chr  intended_target_start  \\\n",
      "0                 TFEC                chr7            116030682.0   \n",
      "1                NR2C1               chr12             95073472.0   \n",
      "2                NANOG               chr12              7789786.0   \n",
      "3                OR8B3                 NaN                    NaN   \n",
      "4                ZNF48               chr16             30395465.0   \n",
      "\n",
      "   intended_target_end  \n",
      "0          116030770.0  \n",
      "1           95073659.0  \n",
      "2            7789930.0  \n",
      "3                  NaN  \n",
      "4           30395994.0  \n",
      "       guide_id               spacer  targeting       type guide_chr  \\\n",
      "0       NR2F2.2  GAAAACCGCCAACAACTAT       True  targeting     chr15   \n",
      "1  IL6ST_P1P2.3  GAAGGATCTGACAGTGTTC       True  targeting      chr5   \n",
      "2   YEATS4_P1P2  GAAGGAGGGCGAGTTACTT       True  targeting     chr12   \n",
      "3   EPC2_P1P2.5  GAAGGAGGAGGAATCGGTA       True  targeting      chr2   \n",
      "4  GPR78_P1P2.2  GAAGGAAAGATACAGTGTT       True  targeting      chr4   \n",
      "\n",
      "   guide_start  guide_end strand  pam intended_target_name  \\\n",
      "0     96325764   96325783      -  NGG                NR2F2   \n",
      "1     55994948   55994966      -  NGG                IL6ST   \n",
      "2     69359838   69359856      -  NGG               YEATS4   \n",
      "3    148645155  148645173      +  NGG                 EPC2   \n",
      "4      8580609    8580627      +  NGG                GPR78   \n",
      "\n",
      "  intended_target_chr  intended_target_start  intended_target_end  \n",
      "0               chr15               96325677             96326177  \n",
      "1                chr5               55994565             55994997  \n",
      "2               chr12               69359838             69360118  \n",
      "3                chr2              148644731            148645173  \n",
      "4                chr4                8580584              8580844  \n",
      "1196\n",
      "type\n",
      "targeting           16126\n",
      "negative_control      619\n",
      "non_targeting         600\n",
      "positive_control       19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(example_crispr_file.head())\n",
    "\n",
    "# Reorganize columns to match\n",
    "new_order = ['guide_id', 'spacer', 'targeting', 'type', 'guide_chr', 'guide_start', 'guide_end', 'strand', 'pam', 'intended_target_name', 'intended_target_chr', 'intended_target_start', 'intended_target_end']\n",
    "ref_clean_sub_poolabcd = ref_clean_sub_poolabcd[new_order].drop_duplicates()\n",
    "print(ref_clean_sub_poolabcd.head())\n",
    "ref_clean_sub_poolf = ref_clean_sub_poolf[new_order].drop_duplicates()\n",
    "print(ref_clean_sub_poolf.head())\n",
    "\n",
    "controls_in_ref = ref_clean_sub_poolabcd[\n",
    "    ref_clean_sub_poolabcd['spacer'].isin(non_targeting['Photospacer (same for all 3 sets)'])\n",
    "    | ref_clean_sub_poolabcd['spacer'].isin(pos_controls['Photospacer (represent 10 times)'])\n",
    "    | ref_clean_sub_poolabcd['spacer'].isin(neg_spacers)\n",
    "]\n",
    "print(len(controls_in_ref))\n",
    "print(ref_clean_sub_poolabcd['type'].value_counts(dropna=False))\n",
    "#controls_in_ref.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows with non-standard chromosomes (i.e. chr1, chr2, chrX, etc., not chrU) by making sure chr is not followed by a letter other than X or Y\n",
    "control_types = ['non_targeting', 'negative_control', 'positive_control']\n",
    "\n",
    "# Mask for control and targeting guides\n",
    "is_control = ref_clean_sub_poolabcd['type'].str.lower().isin(control_types)\n",
    "is_targeting = ~is_control\n",
    "\n",
    "# Standard chromosome pattern\n",
    "standard_chr_pattern = r'^chr(\\d+|X|Y)$'\n",
    "\n",
    "# Split, filter targeting only\n",
    "controls_df = ref_clean_sub_poolabcd[is_control]\n",
    "targets_df = ref_clean_sub_poolabcd[is_targeting]\n",
    "\n",
    "filtered_targets_df = targets_df[\n",
    "    targets_df['guide_chr'].notna()\n",
    "    & targets_df['intended_target_chr'].notna()\n",
    "    & targets_df['guide_chr'].str.match(standard_chr_pattern)\n",
    "    & targets_df['intended_target_chr'].str.match(standard_chr_pattern)\n",
    "]\n",
    "\n",
    "# Recombine targets + controls\n",
    "ref_clean_sub_poolabcd = pd.concat([filtered_targets_df, controls_df], ignore_index=True)\n",
    "ref_clean_sub_poolf = pd.concat([ref_clean_sub_poolf, controls_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2963810/1879577626.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  targets_df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14172, 13)\n",
      "(3862, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2963810/1879577626.py:47: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  targets_df\n"
     ]
    }
   ],
   "source": [
    "# There are certain examples where a target has the same protospacer sequence but multiple local_target_start and local_target_end\n",
    "# values, which throws errors with the pipeline. This takes the min/max of those values (dependent on strand) and collapses into a single row\n",
    "\n",
    "# Collapse groups of targeting guides that have identical metadata but\n",
    "# multiple start/end coordinates. For negativeâ€‘strand entries, we take the\n",
    "# max(start) / min(end); for positiveâ€‘strand or mixed, min(start) / max(end).\n",
    "# Control or nonâ€‘targeting rows are passed through unchanged.\n",
    "def collapse_grouped_targets(df):\n",
    "\n",
    "    def collapse_group(subdf):\n",
    "        # Handle both guide_ and intended_target_ coordinates\n",
    "        if (subdf[\"strand\"] == \"-\").all():\n",
    "            g_start = subdf[\"guide_start\"].max()\n",
    "            g_end   = subdf[\"guide_end\"].min()\n",
    "            t_start = subdf[\"intended_target_start\"].max()\n",
    "            t_end   = subdf[\"intended_target_end\"].min()\n",
    "        else:\n",
    "            g_start = subdf[\"guide_start\"].min()\n",
    "            g_end   = subdf[\"guide_end\"].max()\n",
    "            t_start = subdf[\"intended_target_start\"].min()\n",
    "            t_end   = subdf[\"intended_target_end\"].max()\n",
    "\n",
    "        row = subdf.iloc[0].copy()\n",
    "        row[\"guide_start\"] = g_start\n",
    "        row[\"guide_end\"] = g_end\n",
    "        row[\"intended_target_start\"] = t_start\n",
    "        row[\"intended_target_end\"] = t_end\n",
    "        return row\n",
    "\n",
    "    # Identify control / non-targeting rows (pass through unchanged)\n",
    "    is_control = (\n",
    "        df[\"type\"].str.contains(\"control\", case=False, na=False)\n",
    "        | df[\"type\"].str.contains(\"non\", case=False, na=False)\n",
    "    )\n",
    "\n",
    "    controls_df = df[is_control].copy()\n",
    "    targets_df  = df[~is_control].copy()\n",
    "\n",
    "    # Exclude all coordinate columns from grouping\n",
    "    coord_cols = [\n",
    "        \"guide_start\", \"guide_end\",\n",
    "        \"intended_target_start\", \"intended_target_end\"\n",
    "    ]\n",
    "    group_cols = [c for c in targets_df.columns if c not in coord_cols]\n",
    "\n",
    "    collapsed_targets = (\n",
    "        targets_df\n",
    "        .groupby(group_cols, dropna=False)\n",
    "        .apply(collapse_group)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    combined = pd.concat([collapsed_targets, controls_df], ignore_index=True)\n",
    "    return combined\n",
    "\n",
    "ref_clean_sub_poolabcd = collapse_grouped_targets(ref_clean_sub_poolabcd)\n",
    "ref_clean_sub_poolf    = collapse_grouped_targets(ref_clean_sub_poolf)\n",
    "print(ref_clean_sub_poolabcd.shape)\n",
    "print(ref_clean_sub_poolf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also write a version without mostly NA values, duplicate rows\n",
    "#print(ref_clean_sub_poolabcd.shape)\n",
    "#ref_clean_sub_poolabcd_clean = ref_clean_sub_poolabcd.dropna(thresh = (len(ref_clean_sub_poolabcd.columns)/2)).drop_duplicates()\n",
    "#print(ref_clean_sub_poolabcd_clean.shape)\n",
    "#ref_clean_sub_poolabcd_clean.to_csv(local_path + \"harmonized_guide_file_poolabcd_nomissing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacer\n",
      "CGCCGGCGCGCCTGCGAGG    4\n",
      "TCCTGCGATATCCAGGCGA    4\n",
      "CTCCTTGCAGCCACCACGG    4\n",
      "GCTCACGTCATCCCGACCG    4\n",
      "CGACACTACCAGCTGCTGT    4\n",
      "CAAATCCTCCTGTCTTTCG    4\n",
      "CGTGCAAAACCCTGTGCCT    4\n",
      "CAACTTGCCACTCAAACGC    2\n",
      "GCCGGAGCTACCGGCAGCC    2\n",
      "GCTCCGCCGCTCGGCCCCT    2\n",
      "CACGTAACGGGACCACACA    2\n",
      "GACGCCCCCGGCCAGGTGA    2\n",
      "CACTTGCAGGGGCGCGAGG    2\n",
      "GTCCTTCCCGTCGCCTGCA    2\n",
      "AGTGAGGACTAACGGGGCA    2\n",
      "GGAAACCGCCAGACACCAA    2\n",
      "CACGCCAGACCACGACGGA    2\n",
      "GCTCCACCCTTTCCGGGCG    2\n",
      "Name: count, dtype: int64\n",
      "    guide_id               spacer                guide_chr  guide_start  \\\n",
      "644    DGCR6  CGCCGGCGCGCCTGCGAGG                    chr22   18905981.0   \n",
      "645    DGCR6  CGCCGGCGCGCCTGCGAGG                    chr22   18905981.0   \n",
      "646    DGCR6  CGCCGGCGCGCCTGCGAGG  chr22_KI270734v1_random     131252.0   \n",
      "647    DGCR6  CGCCGGCGCGCCTGCGAGG  chr22_KI270734v1_random     131252.0   \n",
      "648  DGCR6.2  TCCTGCGATATCCAGGCGA                    chr22   18906057.0   \n",
      "\n",
      "      guide_end strand intended_target_name      intended_target_chr  \\\n",
      "644  18906000.0      -                DGCR6                    chr22   \n",
      "645  18906000.0      -                DGCR6  chr22_KI270734v1_random   \n",
      "646    131271.0      -                DGCR6                    chr22   \n",
      "647    131271.0      -                DGCR6  chr22_KI270734v1_random   \n",
      "648  18906076.0      +                DGCR6                    chr22   \n",
      "\n",
      "     intended_target_start  intended_target_end  \n",
      "644             18905972.0           18906472.0  \n",
      "645               131243.0             131743.0  \n",
      "646             18905972.0           18906472.0  \n",
      "647               131243.0             131743.0  \n",
      "648             18905972.0           18906472.0  \n",
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "# Interrogate duplicate spacers\n",
    "duplicate_spacers_poolf = ref_clean_sub_poolf[ref_clean_sub_poolf[\"spacer\"].duplicated(keep=False)]\n",
    "print(duplicate_spacers_poolf[\"spacer\"].value_counts())\n",
    "\n",
    "duplicate_spacers_poolf_diff = duplicate_spacers_poolf.loc[:, duplicate_spacers_poolf.nunique() > 1]\n",
    "print(duplicate_spacers_poolf_diff.head())\n",
    "print(duplicate_spacers_poolf_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 21 '_random' contig rows covered by canonical entries.\n",
      "spacer\n",
      "AGTGAGGACTAACGGGGCA    2\n",
      "CAACTTGCCACTCAAACGC    2\n",
      "CACGCCAGACCACGACGGA    2\n",
      "CACGTAACGGGACCACACA    2\n",
      "CACTTGCAGGGGCGCGAGG    2\n",
      "GACGCCCCCGGCCAGGTGA    2\n",
      "GCCGGAGCTACCGGCAGCC    2\n",
      "GCTCCACCCTTTCCGGGCG    2\n",
      "GCTCCGCCGCTCGGCCCCT    2\n",
      "GGAAACCGCCAGACACCAA    2\n",
      "GTCCTTCCCGTCGCCTGCA    2\n",
      "Name: count, dtype: int64\n",
      "           guide_id               spacer  targeting       type guide_chr  \\\n",
      "375         NCF1B.6  AGTGAGGACTAACGGGGCA       True  targeting      chr7   \n",
      "376         NCF1B.6  AGTGAGGACTAACGGGGCA       True  targeting      chr7   \n",
      "458        GATSL2.2  CAACTTGCCACTCAAACGC       True  targeting      chr7   \n",
      "459        GATSL2.2  CAACTTGCCACTCAAACGC       True  targeting      chr7   \n",
      "488       STAG3L2.3  CACGCCAGACCACGACGGA       True  targeting      chr7   \n",
      "489       STAG3L2.3  CACGCCAGACCACGACGGA       True  targeting      chr7   \n",
      "494  LOC100101148.2  CACGTAACGGGACCACACA       True  targeting      chr7   \n",
      "495  LOC100101148.2  CACGTAACGGGACCACACA       True  targeting      chr7   \n",
      "501     LOC541473.2  CACTTGCAGGGGCGCGAGG       True  targeting      chr7   \n",
      "502     LOC541473.2  CACTTGCAGGGGCGCGAGG       True  targeting      chr7   \n",
      "\n",
      "     guide_start   guide_end strand  pam intended_target_name  \\\n",
      "375   73220803.0  73220822.0      +  NGG                NCF1B   \n",
      "376   75171766.0  75171785.0      -  NGG                NCF1B   \n",
      "458   75237704.0  75237723.0      +  NGG               GATSL2   \n",
      "459   74964667.0  74964686.0      -  NGG               GATSL2   \n",
      "488   74890528.0  74890547.0      +  NGG              STAG3L2   \n",
      "489   75359249.0  75359268.0      -  NGG              STAG3L2   \n",
      "494   75395553.0  75395572.0      +  NGG         LOC100101148   \n",
      "495   72969522.0  72969541.0      -  NGG         LOC100101148   \n",
      "501   75395584.0  75395603.0      +  NGG            LOC541473   \n",
      "502   72969491.0  72969510.0      -  NGG            LOC541473   \n",
      "\n",
      "    intended_target_chr  intended_target_start  intended_target_end  \n",
      "375                chr7             73220388.0           75172248.0  \n",
      "376                chr7             75171748.0           73220888.0  \n",
      "458                chr7             74964567.0           75237955.0  \n",
      "459                chr7             75237455.0           74965067.0  \n",
      "488                chr7             74890362.0           75359449.0  \n",
      "489                chr7             75358949.0           74890862.0  \n",
      "494                chr7             72969431.0           75395711.0  \n",
      "495                chr7             75395211.0           72969931.0  \n",
      "501                chr7             72969383.0           75395663.0  \n",
      "502                chr7             75395163.0           72969883.0  \n",
      "            guide_id               spacer  guide_start   guide_end strand  \\\n",
      "375          NCF1B.6  AGTGAGGACTAACGGGGCA   73220803.0  73220822.0      +   \n",
      "376          NCF1B.6  AGTGAGGACTAACGGGGCA   75171766.0  75171785.0      -   \n",
      "458         GATSL2.2  CAACTTGCCACTCAAACGC   75237704.0  75237723.0      +   \n",
      "459         GATSL2.2  CAACTTGCCACTCAAACGC   74964667.0  74964686.0      -   \n",
      "488        STAG3L2.3  CACGCCAGACCACGACGGA   74890528.0  74890547.0      +   \n",
      "489        STAG3L2.3  CACGCCAGACCACGACGGA   75359249.0  75359268.0      -   \n",
      "494   LOC100101148.2  CACGTAACGGGACCACACA   75395553.0  75395572.0      +   \n",
      "495   LOC100101148.2  CACGTAACGGGACCACACA   72969522.0  72969541.0      -   \n",
      "501      LOC541473.2  CACTTGCAGGGGCGCGAGG   75395584.0  75395603.0      +   \n",
      "502      LOC541473.2  CACTTGCAGGGGCGCGAGG   72969491.0  72969510.0      -   \n",
      "1423  LOC100101148.6  GACGCCCCCGGCCAGGTGA   72969855.0  72969874.0      +   \n",
      "1424  LOC100101148.6  GACGCCCCCGGCCAGGTGA   75395220.0  75395239.0      -   \n",
      "1983       GTF2IP1.2  GCCGGAGCTACCGGCAGCC   75237842.0  75237861.0      +   \n",
      "1984       GTF2IP1.2  GCCGGAGCTACCGGCAGCC   73154766.0  73154785.0      -   \n",
      "2239       STAG3L3.5  GCTCCACCCTTTCCGGGCG   75359067.0  75359086.0      +   \n",
      "2240       STAG3L3.5  GCTCCACCCTTTCCGGGCG   74890703.0  73006050.0      -   \n",
      "2247       GTF2IP1.9  GCTCCGCCGCTCGGCCCCT   74964737.0  74964756.0      +   \n",
      "2248       GTF2IP1.9  GCTCCGCCGCTCGGCCCCT   75237634.0  75237653.0      -   \n",
      "2346       STAG3L2.2  GGAAACCGCCAGACACCAA   74890450.0  74890469.0      +   \n",
      "2347       STAG3L2.2  GGAAACCGCCAGACACCAA   75359327.0  75359346.0      -   \n",
      "3170           NCF1B  GTCCTTCCCGTCGCCTGCA   75172167.0  75172186.0      +   \n",
      "3171           NCF1B  GTCCTTCCCGTCGCCTGCA   73220402.0  73220421.0      -   \n",
      "\n",
      "     intended_target_name  intended_target_start  intended_target_end  \n",
      "375                 NCF1B             73220388.0           75172248.0  \n",
      "376                 NCF1B             75171748.0           73220888.0  \n",
      "458                GATSL2             74964567.0           75237955.0  \n",
      "459                GATSL2             75237455.0           74965067.0  \n",
      "488               STAG3L2             74890362.0           75359449.0  \n",
      "489               STAG3L2             75358949.0           74890862.0  \n",
      "494          LOC100101148             72969431.0           75395711.0  \n",
      "495          LOC100101148             75395211.0           72969931.0  \n",
      "501             LOC541473             72969383.0           75395663.0  \n",
      "502             LOC541473             75395163.0           72969883.0  \n",
      "1423         LOC100101148             72969431.0           75395711.0  \n",
      "1424         LOC100101148             75395211.0           72969931.0  \n",
      "1983              GTF2IP1             73154678.0           75237955.0  \n",
      "1984              GTF2IP1             75237455.0           73155178.0  \n",
      "2239              STAG3L3             73005693.0           75359449.0  \n",
      "2240              STAG3L3             75358949.0           73006193.0  \n",
      "2247              GTF2IP1             74964567.0           75237955.0  \n",
      "2248              GTF2IP1             75237455.0           74965067.0  \n",
      "2346              STAG3L2             74890362.0           75359449.0  \n",
      "2347              STAG3L2             75358949.0           74890862.0  \n",
      "3170                NCF1B             73220388.0           75172248.0  \n",
      "3171                NCF1B             75171748.0           73220888.0  \n",
      "(22, 8)\n"
     ]
    }
   ],
   "source": [
    "# Drop alternate contigs if a canonical chr exists (e.g. chr22_KI270731v1_random)\n",
    "import re\n",
    "def remove_random_contigs(df):\n",
    "    df = df.copy()\n",
    "    keep_rows = []\n",
    "\n",
    "    canonical_pattern = re.compile(r\"^chr(\\d+|X|Y)$\", re.IGNORECASE)\n",
    "\n",
    "    for spacer, subdf in df.groupby(\"spacer\", group_keys=False):\n",
    "        has_main = (\n",
    "            subdf[\"guide_chr\"].astype(str).str.match(canonical_pattern).any() or\n",
    "            subdf[\"intended_target_chr\"].astype(str).str.match(canonical_pattern).any()\n",
    "        )\n",
    "\n",
    "        if has_main:\n",
    "            mask = (\n",
    "                subdf[\"guide_chr\"].astype(str).str.match(canonical_pattern)\n",
    "                & subdf[\"intended_target_chr\"].astype(str).str.match(canonical_pattern)\n",
    "            )\n",
    "            keep_rows.append(subdf[mask])\n",
    "        else:\n",
    "            # If no canonical version exists, keep all\n",
    "            keep_rows.append(subdf)\n",
    "\n",
    "    cleaned = pd.concat(keep_rows, ignore_index=True)\n",
    "    return cleaned\n",
    "\n",
    "before = len(ref_clean_sub_poolf)\n",
    "ref_clean_sub_poolf = remove_random_contigs(ref_clean_sub_poolf)\n",
    "after = len(ref_clean_sub_poolf)\n",
    "\n",
    "print(f\"Removed {before - after} '_random' contig rows covered by canonical entries.\")\n",
    "\n",
    "duplicate_spacers_poolf = ref_clean_sub_poolf[ref_clean_sub_poolf[\"spacer\"].duplicated(keep=False)]\n",
    "print(duplicate_spacers_poolf[\"spacer\"].value_counts())\n",
    "print(duplicate_spacers_poolf.head(10))\n",
    "\n",
    "duplicate_spacers_poolf_diff = duplicate_spacers_poolf.loc[:, duplicate_spacers_poolf.nunique() > 1]\n",
    "print(duplicate_spacers_poolf_diff)\n",
    "print(duplicate_spacers_poolf_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping AGTGAGGACTAACGGGGCA (+), removing 0 opposite-strand rows\n",
      "Keeping CAACTTGCCACTCAAACGC (+), removing 0 opposite-strand rows\n",
      "Keeping CACGCCAGACCACGACGGA (-), removing 0 opposite-strand rows\n",
      "Keeping CACGTAACGGGACCACACA (+), removing 0 opposite-strand rows\n",
      "Keeping CACTTGCAGGGGCGCGAGG (+), removing 0 opposite-strand rows\n",
      "Keeping GACGCCCCCGGCCAGGTGA (+), removing 0 opposite-strand rows\n",
      "Keeping GCCGGAGCTACCGGCAGCC (-), removing 0 opposite-strand rows\n",
      "Keeping GCTCCACCCTTTCCGGGCG (-), removing 0 opposite-strand rows\n",
      "Keeping GCTCCGCCGCTCGGCCCCT (-), removing 0 opposite-strand rows\n",
      "Keeping GGAAACCGCCAGACACCAA (-), removing 0 opposite-strand rows\n",
      "Keeping GTCCTTCCCGTCGCCTGCA (+), removing 0 opposite-strand rows\n",
      "Removed 0 strand-mismatched rows.\n",
      "0 duplicate spacers remain.\n"
     ]
    }
   ],
   "source": [
    "# Manually remove 11 strand mismatches in Pool F to select the most canonical one\n",
    "canonical_strand_choices = {\n",
    "    \"AGTGAGGACTAACGGGGCA\": \"+\",  # NCF1B.6\n",
    "    \"CAACTTGCCACTCAAACGC\": \"+\",  # GATSL2.3\n",
    "    \"CACGCCAGACCACGACGGA\": \"-\",  # STAG3L2.3\n",
    "    \"CACGTAACGGGACCACACA\": \"+\",  # LOC100101148.2\n",
    "    \"CACTTGCAGGGGCGCGAGG\": \"+\", # LOC541473.2\n",
    "    \"GACGCCCCCGGCCAGGTGA\": \"+\",  # LOC100101148.6\n",
    "    \"GCCGGAGCTACCGGCAGCC\": \"-\",  # GTF2IP1.2\n",
    "    \"GCTCCACCCTTTCCGGGCG\": \"-\",  # STAG3L3.5\n",
    "    \"GCTCCGCCGCTCGGCCCCT\": \"-\",  # GTF2IP1.9\n",
    "    \"GGAAACCGCCAGACACCAA\": \"-\",  # STAG3L2.2\n",
    "    \"GTCCTTCCCGTCGCCTGCA\": \"+\",  # NCF1B\n",
    "}\n",
    "mask_keep = pd.Series(True, index=ref_clean_sub_poolf.index)\n",
    "\n",
    "for spacer, strand in canonical_strand_choices.items():\n",
    "    # Identify all rows for this spacer\n",
    "    idx_all = ref_clean_sub_poolf.index[ref_clean_sub_poolf[\"spacer\"] == spacer]\n",
    "    # Identify those on non-canonical strands\n",
    "    idx_wrong = ref_clean_sub_poolf.index[\n",
    "        (ref_clean_sub_poolf[\"spacer\"] == spacer)\n",
    "        & (ref_clean_sub_poolf[\"strand\"] != strand)\n",
    "    ]\n",
    "    # Mark wrong-strand rows for removal\n",
    "    mask_keep.loc[idx_wrong] = False\n",
    "    print(f\"Keeping {spacer} ({strand}), removing {len(idx_wrong)} opposite-strand rows\")\n",
    "\n",
    "# Apply mask\n",
    "before = len(ref_clean_sub_poolf)\n",
    "ref_clean_sub_poolf = ref_clean_sub_poolf.loc[mask_keep].reset_index(drop=True)\n",
    "after = len(ref_clean_sub_poolf)\n",
    "\n",
    "print(f\"Removed {before - after} strand-mismatched rows.\")\n",
    "print(f\"{ref_clean_sub_poolf['spacer'].duplicated().sum()} duplicate spacers remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    guide_id                spacer  targeting       type  \\\n",
      "0  AATF_-_35306286.23-P1P2-1  GAGTGGCCGGTCCAGAGCTG       True  targeting   \n",
      "1  AATF_-_35306286.23-P1P2-2  GGGATCAAGGCGAGAGGATC       True  targeting   \n",
      "2  AATF_-_35306333.23-P1P2-1  GGAGTCGGGGAATCGGATCA       True  targeting   \n",
      "3  AATF_-_35306333.23-P1P2-2  GAAATGTGCGGCCCAACCCC       True  targeting   \n",
      "4  AATF_-_35306351.23-P1P2-1  GAAGGCGAGAGGATCCGGCA       True  targeting   \n",
      "\n",
      "  guide_chr  guide_start   guide_end strand  pam intended_target_name  \\\n",
      "0     chr17   36948966.0  36948984.0      +  NGG                 AATF   \n",
      "1     chr17   36949026.0  36949044.0      +  NGG                 AATF   \n",
      "2     chr17   36949013.0  36949031.0      +  NGG                 AATF   \n",
      "3     chr17   36949070.0  36949088.0      -  NGG                 AATF   \n",
      "4     chr17   36949031.0  36949049.0      +  NGG                 AATF   \n",
      "\n",
      "  intended_target_chr  intended_target_start  intended_target_end  \n",
      "0               chr17             36948966.0           36949088.0  \n",
      "1               chr17             36948966.0           36949088.0  \n",
      "2               chr17             36948966.0           36949088.0  \n",
      "3               chr17             36948966.0           36949088.0  \n",
      "4               chr17             36948966.0           36949088.0  \n",
      "(16764, 13)\n"
     ]
    }
   ],
   "source": [
    "# Create a merged Pool ABCD and Pool F file\n",
    "ref_clean_sub_poolabcdf = pd.concat(\n",
    "    [ref_clean_sub_poolabcd, ref_clean_sub_poolf], ignore_index=True\n",
    ").drop_duplicates(subset=[\"spacer\"], keep=\"first\")\n",
    "print(ref_clean_sub_poolabcdf.head())\n",
    "print(ref_clean_sub_poolabcdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another check for duplicates in the concatenated file\n",
    "duplicate_spacers = ref_clean_sub_poolabcdf[ref_clean_sub_poolabcdf.duplicated(subset=['spacer'])]\n",
    "#print(duplicate_spacers.head())\n",
    "#print(duplicate_spacers.shape)\n",
    "\n",
    "# Find the columns that are different between the duplicate spacers\n",
    "duplicate_spacers_diff = duplicate_spacers.loc[:, duplicate_spacers.nunique() > 1]\n",
    "#print(duplicate_spacers_diff.head())\n",
    "#print(duplicate_spacers_diff.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix any Excel-style gene names converted to dates\n",
    "import re\n",
    "month_gene_map = {\n",
    "    \"JAN\": \"JAN\",\n",
    "    \"FEB\": \"FEB\",\n",
    "    \"MAR\": \"MARCH\",\n",
    "    \"APR\": \"APR\",\n",
    "    \"MAY\": \"MAY\",\n",
    "    \"JUN\": \"JUN\",\n",
    "    \"JUL\": \"JUL\",\n",
    "    \"AUG\": \"AUG\",\n",
    "    \"SEP\": \"SEPT\",\n",
    "    \"OCT\": \"OCT\",\n",
    "    \"NOV\": \"NOV\",\n",
    "    \"DEC\": \"DEC\"\n",
    "}\n",
    "\n",
    "def fix_excel_date_genes(symbol):\n",
    "    # Convert Excel-mangled gene symbols like 5-SEP to SEPT5\n",
    "    m = re.match(r\"^(\\d{1,2})-([A-Z]{3})$\", symbol)\n",
    "    if m and m.group(2) in month_gene_map:\n",
    "        num, month = m.groups()\n",
    "        return f\"{month_gene_map[month]}{num}\"\n",
    "    return symbol\n",
    "\n",
    "ref_clean_sub_poolabcdf['intended_target_name'] = ref_clean_sub_poolabcdf['intended_target_name'].apply(fix_excel_date_genes)\n",
    "ref_clean_sub_poolabcd['intended_target_name'] = ref_clean_sub_poolabcd['intended_target_name'].apply(fix_excel_date_genes)\n",
    "ref_clean_sub_poolf['intended_target_name'] = ref_clean_sub_poolf['intended_target_name'].apply(fix_excel_date_genes)\n",
    "\n",
    "print(len(set(ref_clean_sub_poolabcdf['spacer']).intersection(set(non_targeting['Photospacer (same for all 3 sets)']))))\n",
    "print(len(set(ref_clean_sub_poolabcdf['spacer']).intersection(set(pos_controls['Photospacer (represent 10 times)']))))  \n",
    "len(set(ref_clean_sub_poolabcdf['spacer']).intersection(set(neg_spacers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "ref_clean_sub_poolabcd.to_csv(local_path + \"harmonized_guide_file_poolabcd.csv\")\n",
    "ref_clean_sub_poolabcd.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcd.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")\n",
    "ref_clean_sub_poolf.to_csv(local_path + \"harmonized_guide_file_poolf.csv\")\n",
    "ref_clean_sub_poolf.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolf.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_clean_sub_poolabcdf.to_csv(local_path + \"harmonized_guide_file_poolabcdf.csv\")\n",
    "\n",
    "# Write to tsv file, including header\n",
    "ref_clean_sub_poolabcdf.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcdf.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pybiomart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intended_target_name</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>external_synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>MTTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>TRNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>12S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MOTS-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MTRNR1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intended_target_name  ensembl_gene_id external_synonym\n",
       "0                MT-TF  ENSG00000210049             MTTF\n",
       "1                MT-TF  ENSG00000210049             TRNF\n",
       "2              MT-RNR1  ENSG00000211459              12S\n",
       "3              MT-RNR1  ENSG00000211459           MOTS-C\n",
       "4              MT-RNR1  ENSG00000211459           MTRNR1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert intended_target_name to Ensembl ID using pyBiomart\n",
    "from pybiomart import Dataset\n",
    "\n",
    "dataset = Dataset(name='hsapiens_gene_ensembl', host='http://www.ensembl.org')\n",
    "\n",
    "# Fetch mapping\n",
    "mapping = dataset.query(attributes=['hgnc_symbol', 'ensembl_gene_id', 'external_synonym'])\n",
    "mapping.columns = ['intended_target_name', 'ensembl_gene_id', 'external_synonym']\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intended_target_name</th>\n",
       "      <th>ensembl_gene_id</th>\n",
       "      <th>external_synonym</th>\n",
       "      <th>synonym_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>MTTF</td>\n",
       "      <td>MTTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>ENSG00000210049</td>\n",
       "      <td>TRNF</td>\n",
       "      <td>TRNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>12S</td>\n",
       "      <td>12S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MOTS-C</td>\n",
       "      <td>MOTS-C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT-RNR1</td>\n",
       "      <td>ENSG00000211459</td>\n",
       "      <td>MTRNR1</td>\n",
       "      <td>MTRNR1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  intended_target_name  ensembl_gene_id external_synonym synonym_list\n",
       "0                MT-TF  ENSG00000210049             MTTF         MTTF\n",
       "1                MT-TF  ENSG00000210049             TRNF         TRNF\n",
       "2              MT-RNR1  ENSG00000211459              12S          12S\n",
       "3              MT-RNR1  ENSG00000211459           MOTS-C       MOTS-C\n",
       "4              MT-RNR1  ENSG00000211459           MTRNR1       MTRNR1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine HGNC symbol and synonyms into a single mapping dataframe\n",
    "# Melt external_synonym if it's a comma-separated list\n",
    "mapping_expanded = mapping.copy()\n",
    "mapping_expanded['external_synonym'] = mapping_expanded['external_synonym'].fillna('')\n",
    "mapping_expanded = mapping_expanded.assign(\n",
    "    synonym_list=mapping_expanded['external_synonym'].str.split(',')\n",
    ").explode('synonym_list')\n",
    "mapping_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symbol  ensembl_gene_id\n",
      "0     MTTF  ENSG00000210049\n",
      "2   MTRNR1  ENSG00000211459\n",
      "5     MTTV  ENSG00000210077\n",
      "7   MTRNR2  ENSG00000210082\n",
      "10   MTTL1  ENSG00000209082\n"
     ]
    }
   ],
   "source": [
    "# Combine intended_target_name and synonym_list into one lookup table\n",
    "lookup = pd.concat([\n",
    "    mapping_expanded[['intended_target_name', 'ensembl_gene_id']].rename(columns={'intended_target_name': 'symbol'}),\n",
    "    mapping_expanded[['synonym_list', 'ensembl_gene_id']].rename(columns={'synonym_list': 'symbol'})\n",
    "]).drop_duplicates()\n",
    "#print(lookup.head())\n",
    "lookup['symbol'] = lookup['symbol'].apply(lambda x: str(x).upper().replace('-', '').replace('_',''))\n",
    "print(lookup.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_symbol(s):\n",
    "    s = str(s).upper()\n",
    "    # Remove dashes for relaxed matching\n",
    "    s = s.replace('-', '').replace('_', '')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing Ensembl mapping: 739\n",
      "Gene symbols with no mapping:\n",
      "['NONTARGETING' 'OR2C36' 'OR56A44' 'OR11H61' 'OR2W15' 'OR9Q15' 'OR1N25'\n",
      " 'OR9Q11' 'OR2C32' 'OR2H11' 'OR2C33' 'OR56A43' 'OR2W12' 'OR9Q16' 'OR9Q13'\n",
      " 'OR2C35' 'OR11H65' 'OR9Q12' 'OR2W11' 'OR2C34' 'OR56A42' 'OR2C31'\n",
      " 'SEPT5GP1BB' 'CTD2574D22' 'LOC100101148' 'XXBACB562F10' '5SEP'\n",
      " 'LOC101926943' 'GREGOR' 'LOC100133091' 'CTD2515O10' 'LOC388849'\n",
      " 'LOC541473' 'LOC284865']\n",
      "Number of rows with missing Ensembl mapping: 621\n",
      "Gene symbols with no mapping:\n",
      "['NONTARGETING' 'OR2C36' 'OR56A44' 'OR11H61' 'OR2W15' 'OR9Q15' 'OR1N25'\n",
      " 'OR9Q11' 'OR2C32' 'OR2H11' 'OR2C33' 'OR56A43' 'OR2W12' 'OR9Q16' 'OR9Q13'\n",
      " 'OR2C35' 'OR11H65' 'OR9Q12' 'OR2W11' 'OR2C34' 'OR56A42' 'OR2C31']\n",
      "Number of rows with missing Ensembl mapping: 739\n",
      "Gene symbols with no mapping:\n",
      "['SEPT5GP1BB' 'CTD2574D22' 'LOC100101148' 'XXBACB562F10' '5SEP'\n",
      " 'LOC101926943' 'GREGOR' 'LOC100133091' 'CTD2515O10' 'LOC388849'\n",
      " 'LOC541473' 'LOC284865' 'NONTARGETING' 'OR9Q11' 'OR2C32' 'OR2H11'\n",
      " 'OR2C33' 'OR2W12' 'OR9Q16' 'OR2C34' 'OR2C31' 'OR56A44' 'OR2W15' 'OR9Q15'\n",
      " 'OR11H61' 'OR9Q13' 'OR2C35' 'OR2C36' 'OR1N25' 'OR11H65' 'OR9Q12' 'OR2W11'\n",
      " 'OR56A42' 'OR56A43']\n"
     ]
    }
   ],
   "source": [
    "# Merge with data frame and replace intended_target_name with Ensembl IDs\n",
    "def replace_w_ensembl(ref_clean, mapping):\n",
    "    # Make all symbols uppercase for matching\n",
    "    ref_clean = ref_clean.copy()\n",
    "    ref_clean['intended_target_name'] = ref_clean['intended_target_name'].apply(clean_symbol)\n",
    "\n",
    "    mapping = mapping.copy()\n",
    "    mapping['symbol'] = mapping['symbol'].apply(clean_symbol)\n",
    "\n",
    "    # Merge by symbol\n",
    "    ref_clean = ref_clean.merge(mapping, left_on='intended_target_name',\n",
    "                                right_on='symbol', how='left')\n",
    "\n",
    "    # Identify missing mappings\n",
    "    missing_mask = ref_clean['ensembl_gene_id'].isna()\n",
    "    num_missing = missing_mask.sum()\n",
    "    missing_genes = ref_clean.loc[missing_mask, 'intended_target_name'].unique()\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Number of rows with missing Ensembl mapping: {num_missing}\")\n",
    "    print(f\"Gene symbols with no mapping:\\n{missing_genes}\")\n",
    "\n",
    "    # Replace intended_target_name with Ensembl ID where available,\n",
    "    # otherwise keep the original gene name\n",
    "    ref_clean['intended_target_name'] = ref_clean.apply(\n",
    "        lambda row: row['ensembl_gene_id'] if pd.notna(row['ensembl_gene_id']) \n",
    "                    else row['intended_target_name'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Drop temp columns if you donâ€™t need them later\n",
    "    ref_clean.drop(columns=['ensembl_gene_id', 'symbol'], inplace=True, errors='ignore')\n",
    "\n",
    "    return ref_clean\n",
    "\n",
    "ref_clean_sub_poolabcdf_ensembl = replace_w_ensembl(ref_clean_sub_poolabcdf, lookup)\n",
    "ref_clean_sub_poolabcd_ensembl = replace_w_ensembl(ref_clean_sub_poolabcd, lookup)\n",
    "ref_clean_sub_poolf_ensembl = replace_w_ensembl(ref_clean_sub_poolf, lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "ref_clean_sub_poolabcd.to_csv(local_path + \"harmonized_guide_file_poolabcd_ensg.csv\")\n",
    "ref_clean_sub_poolabcd.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcd_ensg.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")\n",
    "ref_clean_sub_poolf.to_csv(local_path + \"harmonized_guide_file_poolf_ensg.csv\")\n",
    "ref_clean_sub_poolf.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolf_ensg.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")\n",
    "ref_clean_sub_poolabcdf.to_csv(local_path + \"harmonized_guide_file_poolabcdf_ensg.csv\")\n",
    "\n",
    "# Write to tsv file, including header\n",
    "ref_clean_sub_poolabcdf.to_csv(\n",
    "    local_path + \"harmonized_guide_file_poolabcdf_ensg.tsv\",\n",
    "    sep='\\t',\n",
    "    index=False,\n",
    "    lineterminator='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running integrity checks for ABCD\n",
      "All checks passed for ABCD\n",
      "\n",
      "Running integrity checks for F\n",
      "All checks passed for F\n",
      "\n",
      "Running integrity checks for ABCDF\n",
      "All checks passed for ABCDF\n"
     ]
    }
   ],
   "source": [
    "# Quick unit tests to make sure everything is kosher\n",
    "def run_integrity_checks(df, pool_label=\"\"):\n",
    "    print(f\"\\nRunning integrity checks for {pool_label}\")\n",
    "\n",
    "    # Check for duplicate spacers\n",
    "    duplicates = df[df[\"spacer\"].duplicated()]\n",
    "    assert len(duplicates) == 0, f\"{len(duplicates)} duplicate spacers found in {pool_label}\"\n",
    "\n",
    "    # Check NA values are np.nan (not 'NA', 'None', or empty strings)\n",
    "    bad_na = df.isin([\"NA\", \"None\", \"\"]).any().sum()\n",
    "    assert bad_na == 0, f\"{bad_na} non-numeric NA placeholders found in {pool_label}\"\n",
    "\n",
    "    # Check for strange characters in spacer or guide_id\n",
    "    pattern_ok = re.compile(r\"^[ACGTN]+$\", re.IGNORECASE)\n",
    "    bad_spacers = df[~df[\"spacer\"].astype(str).str.match(pattern_ok)]\n",
    "    assert len(bad_spacers) == 0, f\"Unexpected characters in {len(bad_spacers)} spacers\"\n",
    "\n",
    "    # Confirm control guides are present\n",
    "    control_types = [\"non_targeting\", \"positive_control\", \"negative_control\"]\n",
    "    found_controls = {ct: (df[\"type\"].str.lower() == ct).sum() for ct in control_types}\n",
    "    missing_controls = [ct for ct, count in found_controls.items() if count == 0]\n",
    "    assert not missing_controls, f\"Missing control types: {missing_controls}\"\n",
    "\n",
    "    # Confirm coordinate columns are numeric or np.nan\n",
    "    coord_cols = [\"guide_start\", \"guide_end\", \"intended_target_start\", \"intended_target_end\"]\n",
    "    for col in coord_cols:\n",
    "        if col in df.columns:\n",
    "            bad_coords = df[col].dropna().apply(lambda x: isinstance(x, (int, float)))\n",
    "            assert bad_coords.all(), f\"Non-numeric entries in {col}\"\n",
    "\n",
    "    # Confirm chromosome format (allow chr1â€“22, chrX/Y, and *_random)\n",
    "    chr_cols = [\"guide_chr\", \"intended_target_chr\"]\n",
    "    chr_pattern = re.compile(r\"^chr(\\d+|X|Y)(_.*_random)?$\", re.IGNORECASE)\n",
    "    for col in chr_cols:\n",
    "        if col in df.columns:\n",
    "            # Only check non-NaN entries\n",
    "            bad_chr = df[col].dropna().astype(str).apply(lambda x: not chr_pattern.match(x))\n",
    "            assert not bad_chr.any(), f\"Invalid chromosome names in {col}\"\n",
    "\n",
    "    print(f\"All checks passed for {pool_label}\")\n",
    "\n",
    "run_integrity_checks(ref_clean_sub_poolabcd, \"ABCD\")\n",
    "run_integrity_checks(ref_clean_sub_poolf, \"F\")\n",
    "run_integrity_checks(ref_clean_sub_poolabcdf, \"ABCDF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cNMF",
   "language": "python",
   "name": "torch-cnmf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
